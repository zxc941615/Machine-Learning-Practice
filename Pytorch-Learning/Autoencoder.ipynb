{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "from torch.autograd import Variable\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler() # define min max scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file\n",
    "stock_path = \"C:/Users/acer/Desktop/LAB/lab_2.csv\"\n",
    "stock_df = pd.read_csv(stock_path)\n",
    "stock_df=stock_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2200, 12)\n",
      "(238, 12)\n"
     ]
    }
   ],
   "source": [
    "train_set = stock_df[:2200]\n",
    "test_set = stock_df[2200:]\n",
    "print(train_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K value</th>\n",
       "      <th>D value</th>\n",
       "      <th>MACD</th>\n",
       "      <th>William</th>\n",
       "      <th>SMA</th>\n",
       "      <th>WMA</th>\n",
       "      <th>Momentum</th>\n",
       "      <th>RSI</th>\n",
       "      <th>A/D 0</th>\n",
       "      <th>CCI</th>\n",
       "      <th>Close r/f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2200.000000</td>\n",
       "      <td>2200.000000</td>\n",
       "      <td>2200.000000</td>\n",
       "      <td>2200.000000</td>\n",
       "      <td>2200.000000</td>\n",
       "      <td>2200.000000</td>\n",
       "      <td>2200.000000</td>\n",
       "      <td>2200.000000</td>\n",
       "      <td>2200.000000</td>\n",
       "      <td>2200.000000</td>\n",
       "      <td>2200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.478459</td>\n",
       "      <td>0.494744</td>\n",
       "      <td>0.515782</td>\n",
       "      <td>0.515950</td>\n",
       "      <td>0.425581</td>\n",
       "      <td>0.426475</td>\n",
       "      <td>0.464374</td>\n",
       "      <td>0.492458</td>\n",
       "      <td>0.445859</td>\n",
       "      <td>0.463808</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.242761</td>\n",
       "      <td>0.231248</td>\n",
       "      <td>0.128572</td>\n",
       "      <td>0.292113</td>\n",
       "      <td>0.297391</td>\n",
       "      <td>0.296803</td>\n",
       "      <td>0.101128</td>\n",
       "      <td>0.251304</td>\n",
       "      <td>0.278231</td>\n",
       "      <td>0.159410</td>\n",
       "      <td>0.964113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.004943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.272646</td>\n",
       "      <td>0.306148</td>\n",
       "      <td>0.453617</td>\n",
       "      <td>0.258398</td>\n",
       "      <td>0.180373</td>\n",
       "      <td>0.181665</td>\n",
       "      <td>0.419330</td>\n",
       "      <td>0.292431</td>\n",
       "      <td>0.208334</td>\n",
       "      <td>0.351748</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.469031</td>\n",
       "      <td>0.482729</td>\n",
       "      <td>0.512733</td>\n",
       "      <td>0.520003</td>\n",
       "      <td>0.364709</td>\n",
       "      <td>0.364416</td>\n",
       "      <td>0.461561</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.415185</td>\n",
       "      <td>0.467025</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.691137</td>\n",
       "      <td>0.682273</td>\n",
       "      <td>0.585561</td>\n",
       "      <td>0.777773</td>\n",
       "      <td>0.712705</td>\n",
       "      <td>0.712135</td>\n",
       "      <td>0.514771</td>\n",
       "      <td>0.687486</td>\n",
       "      <td>0.687456</td>\n",
       "      <td>0.572115</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          K value       D value         MACD      William          SMA  \\\n",
       "count  2200.000000  2200.000000  2200.000000  2200.000000  2200.000000   \n",
       "mean      0.478459     0.494744     0.515782     0.515950     0.425581   \n",
       "std       0.242761     0.231248     0.128572     0.292113     0.297391   \n",
       "min       0.004943     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.272646     0.306148     0.453617     0.258398     0.180373   \n",
       "50%       0.469031     0.482729     0.512733     0.520003     0.364709   \n",
       "75%       0.691137     0.682273     0.585561     0.777773     0.712705   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               WMA     Momentum          RSI        A/D 0          CCI  \\\n",
       "count  2200.000000  2200.000000  2200.000000  2200.000000  2200.000000   \n",
       "mean      0.426475     0.464374     0.492458     0.445859     0.463808   \n",
       "std       0.296803     0.101128     0.251304     0.278231     0.159410   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.181665     0.419330     0.292431     0.208334     0.351748   \n",
       "50%       0.364416     0.461561     0.500000     0.415185     0.467025   \n",
       "75%       0.712135     0.514771     0.687486     0.687456     0.572115   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "         Close r/f  \n",
       "count  2200.000000  \n",
       "mean      1.000000  \n",
       "std       0.964113  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       1.000000  \n",
       "75%       2.000000  \n",
       "max       2.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# every features in range(0 , 1)\n",
    "train_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Rise: 46.4545\n",
      "Train set Flat: 7.0909\n",
      "Train set Fall: 46.4545\n",
      "Test set Rise: 49.5798\n",
      "Test set Flat: 2.5210\n",
      "Test set Fall: 47.8992\n"
     ]
    }
   ],
   "source": [
    "# print the number of rise , flat , fall data\n",
    "print(\"Train set Rise: %.4f\"%(len(train_set[train_set[\"Close r/f\"] == 2])*100 / len(train_set)))\n",
    "print(\"Train set Flat: %.4f\"%(len(train_set[train_set[\"Close r/f\"] == 1])*100 / len(train_set)))\n",
    "print(\"Train set Fall: %.4f\"%(len(train_set[train_set[\"Close r/f\"] == 0])*100 / len(train_set)))\n",
    "print(\"Test set Rise: %.4f\"%(len(test_set[test_set[\"Close r/f\"] == 2])*100 / len(test_set)))\n",
    "print(\"Test set Flat: %.4f\"%(len(test_set[test_set[\"Close r/f\"] == 1])*100 / len(test_set)))\n",
    "print(\"Test set Fall: %.4f\"%(len(test_set[test_set[\"Close r/f\"] == 0])*100 / len(test_set)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2170, 30, 10])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declear training features data\n",
    "features = []\n",
    "for i in range(30,len(train_set)):\n",
    "    x = train_set[i-30:i][[\"K value \",\"D value\",\"William\",\"MACD\",\"SMA\",\"WMA\",\"Momentum\",\"RSI\",\"A/D 0\",\"CCI\"]].values\n",
    "    features.append(x.tolist())\n",
    "features = torch.FloatTensor(features)\n",
    "features.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2170])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declear trainging labels data\n",
    "labels = []\n",
    "for i in range(31,len(train_set)+1):\n",
    "    x = train_set[i-1:i][\"Close r/f\"]\n",
    "    labels.append(x.tolist())\n",
    "labels = torch.LongTensor(labels).view(-1)\n",
    "labels.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hy parameter\n",
    "torch.manual_seed(1)\n",
    "EPOCH = 10\n",
    "BATCH_SIZE = 64\n",
    "TIME_STEP = 30\n",
    "INPUT_SIZE = 10\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Mini-Batch\n",
    "\n",
    "torch_dataset = Data.TensorDataset(features,labels)\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset = torch_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    num_workers = 2,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "             torch.nn.Linear(TIME_STEP * INPUT_SIZE, 64),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Linear(64, 12), \n",
    "            torch.nn.ReLU(True), \n",
    "            torch.nn.Linear(12, 3))\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(3, 12),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Linear(12, 64),\n",
    "            torch.nn.ReLU(True), \n",
    "            torch.nn.Linear(64, TIME_STEP * INPUT_SIZE), \n",
    "            torch.nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder = self.encoder(x)\n",
    "        decoder = self.decoder(encoder)\n",
    "        return encoder,decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=300, out_features=64, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=64, out_features=12, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Linear(in_features=12, out_features=3, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=12, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=12, out_features=64, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Linear(in_features=64, out_features=300, bias=True)\n",
      "    (5): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = autoencoder()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer and loss function \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR,weight_decay=0.0005)\n",
    "# adject learning rate . when loss don't fall , lr = lr * factor  , min lr = 0.0001\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,factor = 0.9,min_lr=0.0001)\n",
    "# crossentroy loss \n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#delcear testing features and labels\n",
    "\n",
    "test_features = []\n",
    "for i in range(30,len(test_set)):\n",
    "    x = test_set[i-30:i][[\"K value \",\"D value\",\"William\",\"MACD\",\"SMA\",\"WMA\",\"Momentum\",\"RSI\",\"A/D 0\",\"CCI\"]].values\n",
    "    test_features.append(x.tolist())\n",
    "test_features = torch.FloatTensor(test_features)\n",
    "test_labels = []\n",
    "for i in range(31,len(test_set)+1):\n",
    "    x = test_set[i-1:i][\"Close r/f\"]\n",
    "    test_labels.append(x.tolist())\n",
    "test_labels = torch.FloatTensor(test_labels).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    1|steps:   10|Train Avg Loss: 0.2610 |Test Loss: 0.207577\n",
      "Epoch:    1|steps:   20|Train Avg Loss: 0.2040 |Test Loss: 0.151431\n",
      "Epoch:    1|steps:   30|Train Avg Loss: 0.1419 |Test Loss: 0.084279\n",
      "Epoch:    2|steps:   10|Train Avg Loss: 0.0726 |Test Loss: 0.049082\n",
      "Epoch:    2|steps:   20|Train Avg Loss: 0.0614 |Test Loss: 0.042721\n",
      "Epoch:    2|steps:   30|Train Avg Loss: 0.0571 |Test Loss: 0.041195\n",
      "Epoch:    3|steps:   10|Train Avg Loss: 0.0551 |Test Loss: 0.041090\n",
      "Epoch:    3|steps:   20|Train Avg Loss: 0.0571 |Test Loss: 0.040880\n",
      "Epoch:    3|steps:   30|Train Avg Loss: 0.0557 |Test Loss: 0.040825\n",
      "Epoch:    4|steps:   10|Train Avg Loss: 0.0551 |Test Loss: 0.040797\n",
      "Epoch:    4|steps:   20|Train Avg Loss: 0.0565 |Test Loss: 0.040781\n",
      "Epoch:    4|steps:   30|Train Avg Loss: 0.0544 |Test Loss: 0.040727\n",
      "Epoch:    5|steps:   10|Train Avg Loss: 0.0549 |Test Loss: 0.040693\n",
      "Epoch:    5|steps:   20|Train Avg Loss: 0.0547 |Test Loss: 0.040699\n",
      "Epoch:    5|steps:   30|Train Avg Loss: 0.0547 |Test Loss: 0.040834\n",
      "Epoch:    6|steps:   10|Train Avg Loss: 0.0552 |Test Loss: 0.040808\n",
      "Epoch:    6|steps:   20|Train Avg Loss: 0.0534 |Test Loss: 0.040826\n",
      "Epoch:    6|steps:   30|Train Avg Loss: 0.0533 |Test Loss: 0.042402\n",
      "Epoch:    7|steps:   10|Train Avg Loss: 0.0536 |Test Loss: 0.040741\n",
      "Epoch:    7|steps:   20|Train Avg Loss: 0.0533 |Test Loss: 0.041834\n",
      "Epoch:    7|steps:   30|Train Avg Loss: 0.0533 |Test Loss: 0.041261\n",
      "Epoch:    8|steps:   10|Train Avg Loss: 0.0529 |Test Loss: 0.040705\n",
      "Epoch:    8|steps:   20|Train Avg Loss: 0.0527 |Test Loss: 0.042421\n",
      "Epoch:    8|steps:   30|Train Avg Loss: 0.0511 |Test Loss: 0.041378\n",
      "Epoch:    9|steps:   10|Train Avg Loss: 0.0506 |Test Loss: 0.043140\n",
      "Epoch:    9|steps:   20|Train Avg Loss: 0.0502 |Test Loss: 0.043217\n",
      "Epoch:    9|steps:   30|Train Avg Loss: 0.0512 |Test Loss: 0.043261\n",
      "Epoch:   10|steps:   10|Train Avg Loss: 0.0492 |Test Loss: 0.040947\n",
      "Epoch:   10|steps:   20|Train Avg Loss: 0.0494 |Test Loss: 0.042768\n",
      "Epoch:   10|steps:   30|Train Avg Loss: 0.0481 |Test Loss: 0.040568\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Training \n",
    "'''\n",
    "LOSS = []\n",
    "TEST_LOSS = []\n",
    "for epoch in range(EPOCH):\n",
    "    loss_total = 0\n",
    "    for step,(inputs,targets) in enumerate(train_loader):\n",
    "        inputs = inputs.view(-1,TIME_STEP * INPUT_SIZE)\n",
    "        #reshape the features to (batch,time_step*input_size)\n",
    "        inputs_n = inputs.view(-1,TIME_STEP * INPUT_SIZE)\n",
    "       \n",
    "    \n",
    "        inputs_n =  inputs_n + torch.randn(TIME_STEP * INPUT_SIZE)\n",
    "        # Clip the images to be between 0 and 1\n",
    "        inputs_n = np.clip( inputs_n, 0., 1.)\n",
    "\n",
    "        \n",
    "        # start trainnig \n",
    "        _,output = model(inputs_n)\n",
    "        # calculate loss  (cross entroy)\n",
    "        loss = loss_func(output,inputs)\n",
    "        # clear the gradients of all optimized variables(from last training)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # back propagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # sum of loss\n",
    "        loss_total = loss_total + loss\n",
    "        \n",
    "        # print training info every 10 steps\n",
    "        if((step+1) %10 == 0):\n",
    "            # average of loss in 10 steps\n",
    "            avg = loss_total / 10\n",
    "            LOSS.append(avg.tolist())\n",
    "            \n",
    "            # test data\n",
    "            test_features = torch.Tensor(test_features).view(-1,30*10)\n",
    "            _,out = model(test_features)\n",
    "            \n",
    "            test_loss = loss_func(out,test_features)\n",
    "            TEST_LOSS.append(test_loss.tolist())\n",
    "            # print the epoch , steps , average loss , accuracy \n",
    "            print(\"Epoch: %4d|steps: %4d|Train Avg Loss: %.4f |Test Loss: %4f\"\n",
    "                  %(epoch+1,step+1,avg,test_loss))\n",
    "            \n",
    "            # inital variable\n",
    "            loss_total = 0\n",
    "    # updata learning rate\n",
    "    #scheduler.step(loss)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(1,30,30)\n",
    "y = np.array(LOSS)\n",
    "plt.plot(x,y)\n",
    "y = np.array(TEST_LOSS)\n",
    "plt.plot(x,y)\n",
    "plt.title(\"DAE Loss\")\n",
    "plt.xlabel(\"EPOCH\")\n",
    "plt.ylabel(\"LOSS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.view(-1,TIME_STEP*INPUT_SIZE)\n",
    "en_features,de_features = model(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2764, 0.2203, 0.5556,  ..., 0.2500, 0.5000, 0.5966],\n",
      "        [0.1141, 0.1559, 0.8290,  ..., 0.5439, 0.2084, 0.4440],\n",
      "        [0.1465, 0.2494, 0.9643,  ..., 0.9412, 0.1429, 0.1975],\n",
      "        ...,\n",
      "        [0.8497, 0.8721, 0.0769,  ..., 0.4444, 0.8571, 0.5215],\n",
      "        [0.6793, 0.6162, 0.3548,  ..., 0.7308, 0.1429, 0.2995],\n",
      "        [0.2268, 0.3103, 0.7000,  ..., 0.7083, 0.2813, 0.4525]])\n"
     ]
    }
   ],
   "source": [
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.4928],\n",
      "        [1.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.3402],\n",
      "        [1.0000, 0.0000, 1.0000,  ..., 0.3196, 0.0000, 0.0937],\n",
      "        ...,\n",
      "        [1.0000, 0.5529, 0.6971,  ..., 0.0000, 0.0000, 0.4178],\n",
      "        [1.0000, 0.2970, 0.9750,  ..., 0.1092, 0.0000, 0.1957],\n",
      "        [1.0000, 0.0000, 1.0000,  ..., 0.0868, 0.0000, 0.3487]])\n"
     ]
    }
   ],
   "source": [
    "print(inputs_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4764, 0.5008, 0.5407,  ..., 0.5106, 0.4221, 0.4603],\n",
      "        [0.4181, 0.4387, 0.4974,  ..., 0.4499, 0.4027, 0.4212],\n",
      "        [0.4135, 0.4338, 0.4941,  ..., 0.4452, 0.4012, 0.4182],\n",
      "        ...,\n",
      "        [0.4857, 0.5106, 0.5475,  ..., 0.5201, 0.4253, 0.4666],\n",
      "        [0.4796, 0.5042, 0.5434,  ..., 0.5141, 0.4234, 0.4626],\n",
      "        [0.4890, 0.5141, 0.5498,  ..., 0.5233, 0.4263, 0.4688]],\n",
      "       grad_fn=<TanhBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2170, 300])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_features.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
