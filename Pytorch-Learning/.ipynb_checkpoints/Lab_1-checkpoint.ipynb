{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_path = \"C:/Users/acer/Desktop/LAB/3450Inf.csv\"\n",
    "stock_df = pd.read_csv(stock_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Change(%)</th>\n",
       "      <th>market_Change(%)</th>\n",
       "      <th>Beta_7D</th>\n",
       "      <th>Beta_30D</th>\n",
       "      <th>K value</th>\n",
       "      <th>D value</th>\n",
       "      <th>EMA 12</th>\n",
       "      <th>EMA 26</th>\n",
       "      <th>DIF</th>\n",
       "      <th>DEA</th>\n",
       "      <th>MACD</th>\n",
       "      <th>William</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010/1/4</td>\n",
       "      <td>24.568600</td>\n",
       "      <td>25.515600</td>\n",
       "      <td>23.937300</td>\n",
       "      <td>25.515600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.503366</td>\n",
       "      <td>28.833012</td>\n",
       "      <td>-0.329645</td>\n",
       "      <td>-0.743299</td>\n",
       "      <td>0.827308</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010/1/5</td>\n",
       "      <td>25.936399</td>\n",
       "      <td>25.962700</td>\n",
       "      <td>23.753201</td>\n",
       "      <td>23.937300</td>\n",
       "      <td>-6.185628</td>\n",
       "      <td>0.043261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.800895</td>\n",
       "      <td>28.470366</td>\n",
       "      <td>-0.669472</td>\n",
       "      <td>-0.728534</td>\n",
       "      <td>0.118124</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010/1/6</td>\n",
       "      <td>23.989901</td>\n",
       "      <td>24.989500</td>\n",
       "      <td>23.937300</td>\n",
       "      <td>24.253000</td>\n",
       "      <td>1.318862</td>\n",
       "      <td>1.415346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.255065</td>\n",
       "      <td>28.157969</td>\n",
       "      <td>-0.902904</td>\n",
       "      <td>-0.763408</td>\n",
       "      <td>-0.278993</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010/1/7</td>\n",
       "      <td>24.936899</td>\n",
       "      <td>24.989500</td>\n",
       "      <td>23.779499</td>\n",
       "      <td>23.858400</td>\n",
       "      <td>-1.627015</td>\n",
       "      <td>-1.083145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.732501</td>\n",
       "      <td>27.839482</td>\n",
       "      <td>-1.106981</td>\n",
       "      <td>-0.832122</td>\n",
       "      <td>-0.549718</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010/1/8</td>\n",
       "      <td>24.568600</td>\n",
       "      <td>25.515600</td>\n",
       "      <td>24.463400</td>\n",
       "      <td>25.515600</td>\n",
       "      <td>6.945981</td>\n",
       "      <td>0.527841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.545285</td>\n",
       "      <td>27.667343</td>\n",
       "      <td>-1.122057</td>\n",
       "      <td>-0.890109</td>\n",
       "      <td>-0.463896</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>2019/12/25</td>\n",
       "      <td>56.599998</td>\n",
       "      <td>57.400002</td>\n",
       "      <td>56.299999</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>0.706717</td>\n",
       "      <td>0.265105</td>\n",
       "      <td>-0.680702</td>\n",
       "      <td>0.016331</td>\n",
       "      <td>83.063237</td>\n",
       "      <td>79.814951</td>\n",
       "      <td>54.882798</td>\n",
       "      <td>54.107796</td>\n",
       "      <td>0.775002</td>\n",
       "      <td>0.256175</td>\n",
       "      <td>1.037653</td>\n",
       "      <td>1.525427e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>2019/12/26</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>59.200001</td>\n",
       "      <td>57.599998</td>\n",
       "      <td>58.299999</td>\n",
       "      <td>2.280700</td>\n",
       "      <td>-0.059294</td>\n",
       "      <td>-0.530902</td>\n",
       "      <td>-0.133854</td>\n",
       "      <td>84.231204</td>\n",
       "      <td>81.287035</td>\n",
       "      <td>55.408521</td>\n",
       "      <td>54.418330</td>\n",
       "      <td>0.990191</td>\n",
       "      <td>0.402978</td>\n",
       "      <td>1.174426</td>\n",
       "      <td>1.343286e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>2019/12/27</td>\n",
       "      <td>58.599998</td>\n",
       "      <td>59.599998</td>\n",
       "      <td>58.400002</td>\n",
       "      <td>59.400002</td>\n",
       "      <td>1.886798</td>\n",
       "      <td>0.754770</td>\n",
       "      <td>-0.093267</td>\n",
       "      <td>-0.056504</td>\n",
       "      <td>88.492463</td>\n",
       "      <td>83.688844</td>\n",
       "      <td>56.022595</td>\n",
       "      <td>54.787342</td>\n",
       "      <td>1.235253</td>\n",
       "      <td>0.569433</td>\n",
       "      <td>1.331639</td>\n",
       "      <td>2.985017e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2449</th>\n",
       "      <td>2019/12/30</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>65.300003</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>65.300003</td>\n",
       "      <td>9.932661</td>\n",
       "      <td>-0.316085</td>\n",
       "      <td>-2.971407</td>\n",
       "      <td>-0.560891</td>\n",
       "      <td>92.328309</td>\n",
       "      <td>86.568666</td>\n",
       "      <td>57.449889</td>\n",
       "      <td>55.566058</td>\n",
       "      <td>1.883831</td>\n",
       "      <td>0.832313</td>\n",
       "      <td>2.103036</td>\n",
       "      <td>-1.420000e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2450</th>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>65.300003</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>3.369061</td>\n",
       "      <td>-0.466512</td>\n",
       "      <td>-2.898839</td>\n",
       "      <td>-0.690776</td>\n",
       "      <td>94.885539</td>\n",
       "      <td>89.340957</td>\n",
       "      <td>58.996060</td>\n",
       "      <td>56.450054</td>\n",
       "      <td>2.546006</td>\n",
       "      <td>1.175051</td>\n",
       "      <td>2.741909</td>\n",
       "      <td>-1.420000e-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2451 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date       Open       High        Low      Close  Change(%)  \\\n",
       "0       2010/1/4  24.568600  25.515600  23.937300  25.515600   0.000000   \n",
       "1       2010/1/5  25.936399  25.962700  23.753201  23.937300  -6.185628   \n",
       "2       2010/1/6  23.989901  24.989500  23.937300  24.253000   1.318862   \n",
       "3       2010/1/7  24.936899  24.989500  23.779499  23.858400  -1.627015   \n",
       "4       2010/1/8  24.568600  25.515600  24.463400  25.515600   6.945981   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "2446  2019/12/25  56.599998  57.400002  56.299999  57.000000   0.706717   \n",
       "2447  2019/12/26  58.000000  59.200001  57.599998  58.299999   2.280700   \n",
       "2448  2019/12/27  58.599998  59.599998  58.400002  59.400002   1.886798   \n",
       "2449  2019/12/30  61.799999  65.300003  61.799999  65.300003   9.932661   \n",
       "2450  2019/12/31  65.300003  67.500000  64.500000  67.500000   3.369061   \n",
       "\n",
       "      market_Change(%)   Beta_7D  Beta_30D    K value    D value     EMA 12  \\\n",
       "0             0.000000  0.000000  0.000000   0.000000   0.000000  28.503366   \n",
       "1             0.043261  0.000000  0.000000   0.000000   0.000000  27.800895   \n",
       "2             1.415346  0.000000  0.000000   0.000000   0.000000  27.255065   \n",
       "3            -1.083145  0.000000  0.000000   0.000000   0.000000  26.732501   \n",
       "4             0.527841  0.000000  0.000000   0.000000   0.000000  26.545285   \n",
       "...                ...       ...       ...        ...        ...        ...   \n",
       "2446          0.265105 -0.680702  0.016331  83.063237  79.814951  54.882798   \n",
       "2447         -0.059294 -0.530902 -0.133854  84.231204  81.287035  55.408521   \n",
       "2448          0.754770 -0.093267 -0.056504  88.492463  83.688844  56.022595   \n",
       "2449         -0.316085 -2.971407 -0.560891  92.328309  86.568666  57.449889   \n",
       "2450         -0.466512 -2.898839 -0.690776  94.885539  89.340957  58.996060   \n",
       "\n",
       "         EMA 26       DIF       DEA      MACD       William  \n",
       "0     28.833012 -0.329645 -0.743299  0.827308  0.000000e+00  \n",
       "1     28.470366 -0.669472 -0.728534  0.118124  0.000000e+00  \n",
       "2     28.157969 -0.902904 -0.763408 -0.278993  0.000000e+00  \n",
       "3     27.839482 -1.106981 -0.832122 -0.549718  0.000000e+00  \n",
       "4     27.667343 -1.122057 -0.890109 -0.463896  0.000000e+00  \n",
       "...         ...       ...       ...       ...           ...  \n",
       "2446  54.107796  0.775002  0.256175  1.037653  1.525427e+01  \n",
       "2447  54.418330  0.990191  0.402978  1.174426  1.343286e+01  \n",
       "2448  54.787342  1.235253  0.569433  1.331639  2.985017e+00  \n",
       "2449  55.566058  1.883831  0.832313  2.103036 -1.420000e-14  \n",
       "2450  56.450054  2.546006  1.175051  2.741909 -1.420000e-14  \n",
       "\n",
       "[2451 rows x 17 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = [0]\n",
    "D = [0]\n",
    "W = [0]\n",
    "M = [0]\n",
    "MK = [0]\n",
    "B = [0]\n",
    "C = [0]\n",
    "for i in range(1,len(stock_df)):\n",
    "    if(stock_df[i-1:i][\"Close\"].values<stock_df[i:i+1][\"Close\"].values):\n",
    "        C.append(2)\n",
    "    elif(stock_df[i-1:i][\"Close\"].values > stock_df[i:i+1][\"Close\"].values):\n",
    "        C.append(0)\n",
    "    else:\n",
    "        C.append(1)\n",
    "    \n",
    "    if(stock_df[i-1:i][\"K value\"].values<stock_df[i:i+1][\"K value\"].values):\n",
    "        K.append(1)\n",
    "    elif(stock_df[i-1:i][\"K value\"].values > stock_df[i:i+1][\"K value\"].values):\n",
    "        K.append(-1)\n",
    "    else:\n",
    "        K.append(0)\n",
    "    \n",
    "    if(stock_df[i-1:i][\"D value\"].values<stock_df[i:i+1][\"D value\"].values):\n",
    "        D.append(1)\n",
    "    elif(stock_df[i-1:i][\"D value\"].values > stock_df[i:i+1][\"D value\"].values):\n",
    "        D.append(-1)\n",
    "    else:\n",
    "        D.append(0)\n",
    "    \n",
    "    if(stock_df[i-1:i][\"William\"].values<stock_df[i:i+1][\"William\"].values):\n",
    "        W.append(1)\n",
    "    elif(stock_df[i-1:i][\"William\"].values > stock_df[i:i+1][\"William\"].values):\n",
    "        W.append(-1)\n",
    "    else:\n",
    "        W.append(0)\n",
    "    \n",
    "    if(stock_df[i-1:i][\"MACD\"].values<stock_df[i:i+1][\"MACD\"].values):\n",
    "        M.append(1)\n",
    "    elif(stock_df[i-1:i][\"MACD\"].values > stock_df[i:i+1][\"MACD\"].values):\n",
    "        M.append(-1)\n",
    "    else:\n",
    "        M.append(0)\n",
    "    \n",
    "    if(stock_df[i:i+1][\"market_Change(%)\"].values>0):\n",
    "        MK.append(1)\n",
    "    elif(stock_df[i:i+1][\"market_Change(%)\"].values<0):\n",
    "        MK.append(-1)\n",
    "    else:\n",
    "        MK.append(0)\n",
    "    \n",
    "    if(stock_df[i:i+1][\"Beta_7D\"].values>0):\n",
    "        B.append(1)\n",
    "    elif(stock_df[i:i+1][\"Beta_7D\"].values<0):\n",
    "        B.append(-1)\n",
    "    else:\n",
    "        B.append(0)\n",
    "\n",
    "stock_df[\"Close r/f\"] = C\n",
    "stock_df[\"K r/f\"] =  K\n",
    "stock_df[\"D r/f\"] =  D\n",
    "stock_df[\"William r/f\"] = W\n",
    "stock_df[\"MACD r/f\"] =  M\n",
    "stock_df[\"Market r/f\"] = MK\n",
    "stock_df[\"Beta r/f\"] = B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Change(%)</th>\n",
       "      <th>market_Change(%)</th>\n",
       "      <th>Beta_7D</th>\n",
       "      <th>Beta_30D</th>\n",
       "      <th>K value</th>\n",
       "      <th>...</th>\n",
       "      <th>DEA</th>\n",
       "      <th>MACD</th>\n",
       "      <th>William</th>\n",
       "      <th>Close r/f</th>\n",
       "      <th>K r/f</th>\n",
       "      <th>D r/f</th>\n",
       "      <th>William r/f</th>\n",
       "      <th>MACD r/f</th>\n",
       "      <th>Market r/f</th>\n",
       "      <th>Beta r/f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010/1/4</td>\n",
       "      <td>24.568600</td>\n",
       "      <td>25.515600</td>\n",
       "      <td>23.937300</td>\n",
       "      <td>25.515600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.743299</td>\n",
       "      <td>0.827308</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010/1/5</td>\n",
       "      <td>25.936399</td>\n",
       "      <td>25.962700</td>\n",
       "      <td>23.753201</td>\n",
       "      <td>23.937300</td>\n",
       "      <td>-6.185628</td>\n",
       "      <td>0.043261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.728534</td>\n",
       "      <td>0.118124</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010/1/6</td>\n",
       "      <td>23.989901</td>\n",
       "      <td>24.989500</td>\n",
       "      <td>23.937300</td>\n",
       "      <td>24.253000</td>\n",
       "      <td>1.318862</td>\n",
       "      <td>1.415346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.763408</td>\n",
       "      <td>-0.278993</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010/1/7</td>\n",
       "      <td>24.936899</td>\n",
       "      <td>24.989500</td>\n",
       "      <td>23.779499</td>\n",
       "      <td>23.858400</td>\n",
       "      <td>-1.627015</td>\n",
       "      <td>-1.083145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.832122</td>\n",
       "      <td>-0.549718</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010/1/8</td>\n",
       "      <td>24.568600</td>\n",
       "      <td>25.515600</td>\n",
       "      <td>24.463400</td>\n",
       "      <td>25.515600</td>\n",
       "      <td>6.945981</td>\n",
       "      <td>0.527841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.890109</td>\n",
       "      <td>-0.463896</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>2019/12/25</td>\n",
       "      <td>56.599998</td>\n",
       "      <td>57.400002</td>\n",
       "      <td>56.299999</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>0.706717</td>\n",
       "      <td>0.265105</td>\n",
       "      <td>-0.680702</td>\n",
       "      <td>0.016331</td>\n",
       "      <td>83.063237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256175</td>\n",
       "      <td>1.037653</td>\n",
       "      <td>1.525427e+01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>2019/12/26</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>59.200001</td>\n",
       "      <td>57.599998</td>\n",
       "      <td>58.299999</td>\n",
       "      <td>2.280700</td>\n",
       "      <td>-0.059294</td>\n",
       "      <td>-0.530902</td>\n",
       "      <td>-0.133854</td>\n",
       "      <td>84.231204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402978</td>\n",
       "      <td>1.174426</td>\n",
       "      <td>1.343286e+01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>2019/12/27</td>\n",
       "      <td>58.599998</td>\n",
       "      <td>59.599998</td>\n",
       "      <td>58.400002</td>\n",
       "      <td>59.400002</td>\n",
       "      <td>1.886798</td>\n",
       "      <td>0.754770</td>\n",
       "      <td>-0.093267</td>\n",
       "      <td>-0.056504</td>\n",
       "      <td>88.492463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.569433</td>\n",
       "      <td>1.331639</td>\n",
       "      <td>2.985017e+00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2449</th>\n",
       "      <td>2019/12/30</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>65.300003</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>65.300003</td>\n",
       "      <td>9.932661</td>\n",
       "      <td>-0.316085</td>\n",
       "      <td>-2.971407</td>\n",
       "      <td>-0.560891</td>\n",
       "      <td>92.328309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832313</td>\n",
       "      <td>2.103036</td>\n",
       "      <td>-1.420000e-14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2450</th>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>65.300003</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>3.369061</td>\n",
       "      <td>-0.466512</td>\n",
       "      <td>-2.898839</td>\n",
       "      <td>-0.690776</td>\n",
       "      <td>94.885539</td>\n",
       "      <td>...</td>\n",
       "      <td>1.175051</td>\n",
       "      <td>2.741909</td>\n",
       "      <td>-1.420000e-14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2451 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date       Open       High        Low      Close  Change(%)  \\\n",
       "0       2010/1/4  24.568600  25.515600  23.937300  25.515600   0.000000   \n",
       "1       2010/1/5  25.936399  25.962700  23.753201  23.937300  -6.185628   \n",
       "2       2010/1/6  23.989901  24.989500  23.937300  24.253000   1.318862   \n",
       "3       2010/1/7  24.936899  24.989500  23.779499  23.858400  -1.627015   \n",
       "4       2010/1/8  24.568600  25.515600  24.463400  25.515600   6.945981   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "2446  2019/12/25  56.599998  57.400002  56.299999  57.000000   0.706717   \n",
       "2447  2019/12/26  58.000000  59.200001  57.599998  58.299999   2.280700   \n",
       "2448  2019/12/27  58.599998  59.599998  58.400002  59.400002   1.886798   \n",
       "2449  2019/12/30  61.799999  65.300003  61.799999  65.300003   9.932661   \n",
       "2450  2019/12/31  65.300003  67.500000  64.500000  67.500000   3.369061   \n",
       "\n",
       "      market_Change(%)   Beta_7D  Beta_30D    K value  ...       DEA  \\\n",
       "0             0.000000  0.000000  0.000000   0.000000  ... -0.743299   \n",
       "1             0.043261  0.000000  0.000000   0.000000  ... -0.728534   \n",
       "2             1.415346  0.000000  0.000000   0.000000  ... -0.763408   \n",
       "3            -1.083145  0.000000  0.000000   0.000000  ... -0.832122   \n",
       "4             0.527841  0.000000  0.000000   0.000000  ... -0.890109   \n",
       "...                ...       ...       ...        ...  ...       ...   \n",
       "2446          0.265105 -0.680702  0.016331  83.063237  ...  0.256175   \n",
       "2447         -0.059294 -0.530902 -0.133854  84.231204  ...  0.402978   \n",
       "2448          0.754770 -0.093267 -0.056504  88.492463  ...  0.569433   \n",
       "2449         -0.316085 -2.971407 -0.560891  92.328309  ...  0.832313   \n",
       "2450         -0.466512 -2.898839 -0.690776  94.885539  ...  1.175051   \n",
       "\n",
       "          MACD       William  Close r/f  K r/f  D r/f  William r/f  MACD r/f  \\\n",
       "0     0.827308  0.000000e+00          0      0      0            0         0   \n",
       "1     0.118124  0.000000e+00          0      0      0            0        -1   \n",
       "2    -0.278993  0.000000e+00          2      0      0            0        -1   \n",
       "3    -0.549718  0.000000e+00          0      0      0            0        -1   \n",
       "4    -0.463896  0.000000e+00          2      0      0            0         1   \n",
       "...        ...           ...        ...    ...    ...          ...       ...   \n",
       "2446  1.037653  1.525427e+01          2      1      1           -1         1   \n",
       "2447  1.174426  1.343286e+01          2      1      1           -1         1   \n",
       "2448  1.331639  2.985017e+00          2      1      1           -1         1   \n",
       "2449  2.103036 -1.420000e-14          2      1      1           -1         1   \n",
       "2450  2.741909 -1.420000e-14          2      1      1            0         1   \n",
       "\n",
       "      Market r/f  Beta r/f  \n",
       "0              0         0  \n",
       "1              1         0  \n",
       "2              1         0  \n",
       "3             -1         0  \n",
       "4              1         0  \n",
       "...          ...       ...  \n",
       "2446           1        -1  \n",
       "2447          -1        -1  \n",
       "2448           1        -1  \n",
       "2449          -1        -1  \n",
       "2450          -1        -1  \n",
       "\n",
       "[2451 rows x 24 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Change(%)</th>\n",
       "      <th>market_Change(%)</th>\n",
       "      <th>Beta_7D</th>\n",
       "      <th>Beta_30D</th>\n",
       "      <th>K value</th>\n",
       "      <th>...</th>\n",
       "      <th>DEA</th>\n",
       "      <th>MACD</th>\n",
       "      <th>William</th>\n",
       "      <th>Close r/f</th>\n",
       "      <th>K r/f</th>\n",
       "      <th>D r/f</th>\n",
       "      <th>William r/f</th>\n",
       "      <th>MACD r/f</th>\n",
       "      <th>Market r/f</th>\n",
       "      <th>Beta r/f</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>24.568600</td>\n",
       "      <td>25.515600</td>\n",
       "      <td>23.937300</td>\n",
       "      <td>25.515600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.743299</td>\n",
       "      <td>0.827308</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>25.936399</td>\n",
       "      <td>25.962700</td>\n",
       "      <td>23.753201</td>\n",
       "      <td>23.937300</td>\n",
       "      <td>-6.185628</td>\n",
       "      <td>0.043261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.728534</td>\n",
       "      <td>0.118124</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>23.989901</td>\n",
       "      <td>24.989500</td>\n",
       "      <td>23.937300</td>\n",
       "      <td>24.253000</td>\n",
       "      <td>1.318862</td>\n",
       "      <td>1.415346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.763408</td>\n",
       "      <td>-0.278993</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>24.936899</td>\n",
       "      <td>24.989500</td>\n",
       "      <td>23.779499</td>\n",
       "      <td>23.858400</td>\n",
       "      <td>-1.627015</td>\n",
       "      <td>-1.083145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.832122</td>\n",
       "      <td>-0.549718</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>24.568600</td>\n",
       "      <td>25.515600</td>\n",
       "      <td>24.463400</td>\n",
       "      <td>25.515600</td>\n",
       "      <td>6.945981</td>\n",
       "      <td>0.527841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.890109</td>\n",
       "      <td>-0.463896</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25</th>\n",
       "      <td>2019-12-25</td>\n",
       "      <td>56.599998</td>\n",
       "      <td>57.400002</td>\n",
       "      <td>56.299999</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>0.706717</td>\n",
       "      <td>0.265105</td>\n",
       "      <td>-0.680702</td>\n",
       "      <td>0.016331</td>\n",
       "      <td>83.063237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256175</td>\n",
       "      <td>1.037653</td>\n",
       "      <td>1.525427e+01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>59.200001</td>\n",
       "      <td>57.599998</td>\n",
       "      <td>58.299999</td>\n",
       "      <td>2.280700</td>\n",
       "      <td>-0.059294</td>\n",
       "      <td>-0.530902</td>\n",
       "      <td>-0.133854</td>\n",
       "      <td>84.231204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402978</td>\n",
       "      <td>1.174426</td>\n",
       "      <td>1.343286e+01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>58.599998</td>\n",
       "      <td>59.599998</td>\n",
       "      <td>58.400002</td>\n",
       "      <td>59.400002</td>\n",
       "      <td>1.886798</td>\n",
       "      <td>0.754770</td>\n",
       "      <td>-0.093267</td>\n",
       "      <td>-0.056504</td>\n",
       "      <td>88.492463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.569433</td>\n",
       "      <td>1.331639</td>\n",
       "      <td>2.985017e+00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>65.300003</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>65.300003</td>\n",
       "      <td>9.932661</td>\n",
       "      <td>-0.316085</td>\n",
       "      <td>-2.971407</td>\n",
       "      <td>-0.560891</td>\n",
       "      <td>92.328309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832313</td>\n",
       "      <td>2.103036</td>\n",
       "      <td>-1.420000e-14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>65.300003</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>3.369061</td>\n",
       "      <td>-0.466512</td>\n",
       "      <td>-2.898839</td>\n",
       "      <td>-0.690776</td>\n",
       "      <td>94.885539</td>\n",
       "      <td>...</td>\n",
       "      <td>1.175051</td>\n",
       "      <td>2.741909</td>\n",
       "      <td>-1.420000e-14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2451 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date       Open       High        Low      Close  Change(%)  \\\n",
       "Date                                                                           \n",
       "2010-01-04 2010-01-04  24.568600  25.515600  23.937300  25.515600   0.000000   \n",
       "2010-01-05 2010-01-05  25.936399  25.962700  23.753201  23.937300  -6.185628   \n",
       "2010-01-06 2010-01-06  23.989901  24.989500  23.937300  24.253000   1.318862   \n",
       "2010-01-07 2010-01-07  24.936899  24.989500  23.779499  23.858400  -1.627015   \n",
       "2010-01-08 2010-01-08  24.568600  25.515600  24.463400  25.515600   6.945981   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2019-12-25 2019-12-25  56.599998  57.400002  56.299999  57.000000   0.706717   \n",
       "2019-12-26 2019-12-26  58.000000  59.200001  57.599998  58.299999   2.280700   \n",
       "2019-12-27 2019-12-27  58.599998  59.599998  58.400002  59.400002   1.886798   \n",
       "2019-12-30 2019-12-30  61.799999  65.300003  61.799999  65.300003   9.932661   \n",
       "2019-12-31 2019-12-31  65.300003  67.500000  64.500000  67.500000   3.369061   \n",
       "\n",
       "            market_Change(%)   Beta_7D  Beta_30D    K value  ...       DEA  \\\n",
       "Date                                                         ...             \n",
       "2010-01-04          0.000000  0.000000  0.000000   0.000000  ... -0.743299   \n",
       "2010-01-05          0.043261  0.000000  0.000000   0.000000  ... -0.728534   \n",
       "2010-01-06          1.415346  0.000000  0.000000   0.000000  ... -0.763408   \n",
       "2010-01-07         -1.083145  0.000000  0.000000   0.000000  ... -0.832122   \n",
       "2010-01-08          0.527841  0.000000  0.000000   0.000000  ... -0.890109   \n",
       "...                      ...       ...       ...        ...  ...       ...   \n",
       "2019-12-25          0.265105 -0.680702  0.016331  83.063237  ...  0.256175   \n",
       "2019-12-26         -0.059294 -0.530902 -0.133854  84.231204  ...  0.402978   \n",
       "2019-12-27          0.754770 -0.093267 -0.056504  88.492463  ...  0.569433   \n",
       "2019-12-30         -0.316085 -2.971407 -0.560891  92.328309  ...  0.832313   \n",
       "2019-12-31         -0.466512 -2.898839 -0.690776  94.885539  ...  1.175051   \n",
       "\n",
       "                MACD       William  Close r/f  K r/f  D r/f  William r/f  \\\n",
       "Date                                                                       \n",
       "2010-01-04  0.827308  0.000000e+00          0      0      0            0   \n",
       "2010-01-05  0.118124  0.000000e+00          0      0      0            0   \n",
       "2010-01-06 -0.278993  0.000000e+00          2      0      0            0   \n",
       "2010-01-07 -0.549718  0.000000e+00          0      0      0            0   \n",
       "2010-01-08 -0.463896  0.000000e+00          2      0      0            0   \n",
       "...              ...           ...        ...    ...    ...          ...   \n",
       "2019-12-25  1.037653  1.525427e+01          2      1      1           -1   \n",
       "2019-12-26  1.174426  1.343286e+01          2      1      1           -1   \n",
       "2019-12-27  1.331639  2.985017e+00          2      1      1           -1   \n",
       "2019-12-30  2.103036 -1.420000e-14          2      1      1           -1   \n",
       "2019-12-31  2.741909 -1.420000e-14          2      1      1            0   \n",
       "\n",
       "            MACD r/f  Market r/f  Beta r/f  \n",
       "Date                                        \n",
       "2010-01-04         0           0         0  \n",
       "2010-01-05        -1           1         0  \n",
       "2010-01-06        -1           1         0  \n",
       "2010-01-07        -1          -1         0  \n",
       "2010-01-08         1           1         0  \n",
       "...              ...         ...       ...  \n",
       "2019-12-25         1           1        -1  \n",
       "2019-12-26         1          -1        -1  \n",
       "2019-12-27         1           1        -1  \n",
       "2019-12-30         1          -1        -1  \n",
       "2019-12-31         1          -1        -1  \n",
       "\n",
       "[2451 rows x 24 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_df['Date'] = pd.to_datetime(stock_df['Date'])\n",
    "stock_df.index = stock_df[\"Date\"]\n",
    "stock_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 7)\n",
      "(400, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K value</th>\n",
       "      <th>D value</th>\n",
       "      <th>William</th>\n",
       "      <th>MACD</th>\n",
       "      <th>market_Change(%)</th>\n",
       "      <th>Beta_7D</th>\n",
       "      <th>Close r/f</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-18</th>\n",
       "      <td>64.141634</td>\n",
       "      <td>56.734509</td>\n",
       "      <td>23.524842</td>\n",
       "      <td>0.144544</td>\n",
       "      <td>0.606740</td>\n",
       "      <td>1.499831</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-19</th>\n",
       "      <td>60.406886</td>\n",
       "      <td>57.958635</td>\n",
       "      <td>47.062612</td>\n",
       "      <td>-0.075469</td>\n",
       "      <td>0.716062</td>\n",
       "      <td>0.097482</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-22</th>\n",
       "      <td>55.958794</td>\n",
       "      <td>57.292021</td>\n",
       "      <td>52.937388</td>\n",
       "      <td>-0.291910</td>\n",
       "      <td>0.722908</td>\n",
       "      <td>1.635038</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-23</th>\n",
       "      <td>49.804125</td>\n",
       "      <td>54.796056</td>\n",
       "      <td>62.505213</td>\n",
       "      <td>-0.494229</td>\n",
       "      <td>0.192766</td>\n",
       "      <td>1.211308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-24</th>\n",
       "      <td>45.322750</td>\n",
       "      <td>51.638287</td>\n",
       "      <td>63.640000</td>\n",
       "      <td>-0.443795</td>\n",
       "      <td>-0.897087</td>\n",
       "      <td>-0.827763</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-25</th>\n",
       "      <td>30.215167</td>\n",
       "      <td>44.497247</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-0.642707</td>\n",
       "      <td>0.123654</td>\n",
       "      <td>-0.772062</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-26</th>\n",
       "      <td>24.904618</td>\n",
       "      <td>37.966371</td>\n",
       "      <td>85.716481</td>\n",
       "      <td>-0.812047</td>\n",
       "      <td>-0.168822</td>\n",
       "      <td>-0.756520</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-29</th>\n",
       "      <td>21.730869</td>\n",
       "      <td>32.554537</td>\n",
       "      <td>84.616629</td>\n",
       "      <td>-0.894050</td>\n",
       "      <td>0.670219</td>\n",
       "      <td>-0.952245</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-30</th>\n",
       "      <td>14.487246</td>\n",
       "      <td>26.532106</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-1.030995</td>\n",
       "      <td>-1.292388</td>\n",
       "      <td>-0.207973</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-31</th>\n",
       "      <td>23.547575</td>\n",
       "      <td>25.537263</td>\n",
       "      <td>58.331766</td>\n",
       "      <td>-0.902733</td>\n",
       "      <td>0.243841</td>\n",
       "      <td>-0.022147</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>45.998370</td>\n",
       "      <td>32.357632</td>\n",
       "      <td>9.100040</td>\n",
       "      <td>-0.497017</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>0.406782</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-02</th>\n",
       "      <td>41.778334</td>\n",
       "      <td>35.497866</td>\n",
       "      <td>66.661739</td>\n",
       "      <td>-0.517510</td>\n",
       "      <td>-0.304828</td>\n",
       "      <td>1.046761</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05</th>\n",
       "      <td>32.612129</td>\n",
       "      <td>34.535954</td>\n",
       "      <td>85.720280</td>\n",
       "      <td>-0.977110</td>\n",
       "      <td>-1.617623</td>\n",
       "      <td>1.531233</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-06</th>\n",
       "      <td>23.291681</td>\n",
       "      <td>30.787863</td>\n",
       "      <td>95.349214</td>\n",
       "      <td>-2.555704</td>\n",
       "      <td>-4.953751</td>\n",
       "      <td>1.811964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-07</th>\n",
       "      <td>23.279128</td>\n",
       "      <td>28.284951</td>\n",
       "      <td>76.745979</td>\n",
       "      <td>-2.948703</td>\n",
       "      <td>1.418109</td>\n",
       "      <td>1.964682</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-08</th>\n",
       "      <td>17.843967</td>\n",
       "      <td>24.804623</td>\n",
       "      <td>93.026354</td>\n",
       "      <td>-3.441488</td>\n",
       "      <td>-0.218172</td>\n",
       "      <td>1.936829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-09</th>\n",
       "      <td>25.689669</td>\n",
       "      <td>25.099638</td>\n",
       "      <td>58.618929</td>\n",
       "      <td>-3.208818</td>\n",
       "      <td>-1.488999</td>\n",
       "      <td>1.777378</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-12</th>\n",
       "      <td>29.770825</td>\n",
       "      <td>26.656701</td>\n",
       "      <td>62.066862</td>\n",
       "      <td>-2.990537</td>\n",
       "      <td>0.475714</td>\n",
       "      <td>1.622243</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-21</th>\n",
       "      <td>39.387487</td>\n",
       "      <td>30.900296</td>\n",
       "      <td>41.379190</td>\n",
       "      <td>-1.973761</td>\n",
       "      <td>2.814970</td>\n",
       "      <td>1.695295</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-22</th>\n",
       "      <td>46.373886</td>\n",
       "      <td>36.058159</td>\n",
       "      <td>39.653315</td>\n",
       "      <td>-1.143353</td>\n",
       "      <td>-0.485891</td>\n",
       "      <td>1.672551</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-23</th>\n",
       "      <td>56.498117</td>\n",
       "      <td>42.871479</td>\n",
       "      <td>23.253422</td>\n",
       "      <td>-0.644777</td>\n",
       "      <td>1.239591</td>\n",
       "      <td>0.891800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-26</th>\n",
       "      <td>70.166391</td>\n",
       "      <td>51.969783</td>\n",
       "      <td>2.497060</td>\n",
       "      <td>0.085228</td>\n",
       "      <td>0.390478</td>\n",
       "      <td>0.734604</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-27</th>\n",
       "      <td>76.045426</td>\n",
       "      <td>59.994997</td>\n",
       "      <td>12.196504</td>\n",
       "      <td>0.399670</td>\n",
       "      <td>-0.195913</td>\n",
       "      <td>0.635921</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01</th>\n",
       "      <td>82.404436</td>\n",
       "      <td>67.464810</td>\n",
       "      <td>4.877545</td>\n",
       "      <td>0.784439</td>\n",
       "      <td>-0.274419</td>\n",
       "      <td>1.282072</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-02</th>\n",
       "      <td>83.392091</td>\n",
       "      <td>72.773904</td>\n",
       "      <td>14.632599</td>\n",
       "      <td>0.785195</td>\n",
       "      <td>-0.812366</td>\n",
       "      <td>1.391752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-05</th>\n",
       "      <td>71.468750</td>\n",
       "      <td>72.338852</td>\n",
       "      <td>52.377932</td>\n",
       "      <td>0.485356</td>\n",
       "      <td>-0.516626</td>\n",
       "      <td>0.642716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-06</th>\n",
       "      <td>63.202688</td>\n",
       "      <td>69.293464</td>\n",
       "      <td>53.329437</td>\n",
       "      <td>0.475930</td>\n",
       "      <td>1.328956</td>\n",
       "      <td>0.928400</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-07</th>\n",
       "      <td>48.195105</td>\n",
       "      <td>62.260678</td>\n",
       "      <td>81.820060</td>\n",
       "      <td>0.415771</td>\n",
       "      <td>-0.361817</td>\n",
       "      <td>1.637692</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-08</th>\n",
       "      <td>40.464917</td>\n",
       "      <td>54.995424</td>\n",
       "      <td>74.995458</td>\n",
       "      <td>0.384093</td>\n",
       "      <td>0.725152</td>\n",
       "      <td>1.163752</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-09</th>\n",
       "      <td>35.311459</td>\n",
       "      <td>48.434103</td>\n",
       "      <td>74.995458</td>\n",
       "      <td>0.371052</td>\n",
       "      <td>0.384174</td>\n",
       "      <td>1.113541</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              K value    D value     William      MACD  market_Change(%)  \\\n",
       "Date                                                                       \n",
       "2018-01-18  64.141634  56.734509   23.524842  0.144544          0.606740   \n",
       "2018-01-19  60.406886  57.958635   47.062612 -0.075469          0.716062   \n",
       "2018-01-22  55.958794  57.292021   52.937388 -0.291910          0.722908   \n",
       "2018-01-23  49.804125  54.796056   62.505213 -0.494229          0.192766   \n",
       "2018-01-24  45.322750  51.638287   63.640000 -0.443795         -0.897087   \n",
       "2018-01-25  30.215167  44.497247  100.000000 -0.642707          0.123654   \n",
       "2018-01-26  24.904618  37.966371   85.716481 -0.812047         -0.168822   \n",
       "2018-01-29  21.730869  32.554537   84.616629 -0.894050          0.670219   \n",
       "2018-01-30  14.487246  26.532106  100.000000 -1.030995         -1.292388   \n",
       "2018-01-31  23.547575  25.537263   58.331766 -0.902733          0.243841   \n",
       "2018-02-01  45.998370  32.357632    9.100040 -0.497017          0.508475   \n",
       "2018-02-02  41.778334  35.497866   66.661739 -0.517510         -0.304828   \n",
       "2018-02-05  32.612129  34.535954   85.720280 -0.977110         -1.617623   \n",
       "2018-02-06  23.291681  30.787863   95.349214 -2.555704         -4.953751   \n",
       "2018-02-07  23.279128  28.284951   76.745979 -2.948703          1.418109   \n",
       "2018-02-08  17.843967  24.804623   93.026354 -3.441488         -0.218172   \n",
       "2018-02-09  25.689669  25.099638   58.618929 -3.208818         -1.488999   \n",
       "2018-02-12  29.770825  26.656701   62.066862 -2.990537          0.475714   \n",
       "2018-02-21  39.387487  30.900296   41.379190 -1.973761          2.814970   \n",
       "2018-02-22  46.373886  36.058159   39.653315 -1.143353         -0.485891   \n",
       "2018-02-23  56.498117  42.871479   23.253422 -0.644777          1.239591   \n",
       "2018-02-26  70.166391  51.969783    2.497060  0.085228          0.390478   \n",
       "2018-02-27  76.045426  59.994997   12.196504  0.399670         -0.195913   \n",
       "2018-03-01  82.404436  67.464810    4.877545  0.784439         -0.274419   \n",
       "2018-03-02  83.392091  72.773904   14.632599  0.785195         -0.812366   \n",
       "2018-03-05  71.468750  72.338852   52.377932  0.485356         -0.516626   \n",
       "2018-03-06  63.202688  69.293464   53.329437  0.475930          1.328956   \n",
       "2018-03-07  48.195105  62.260678   81.820060  0.415771         -0.361817   \n",
       "2018-03-08  40.464917  54.995424   74.995458  0.384093          0.725152   \n",
       "2018-03-09  35.311459  48.434103   74.995458  0.371052          0.384174   \n",
       "\n",
       "             Beta_7D  Close r/f  \n",
       "Date                             \n",
       "2018-01-18  1.499831          2  \n",
       "2018-01-19  0.097482          0  \n",
       "2018-01-22  1.635038          0  \n",
       "2018-01-23  1.211308          0  \n",
       "2018-01-24 -0.827763          2  \n",
       "2018-01-25 -0.772062          0  \n",
       "2018-01-26 -0.756520          0  \n",
       "2018-01-29 -0.952245          1  \n",
       "2018-01-30 -0.207973          0  \n",
       "2018-01-31 -0.022147          2  \n",
       "2018-02-01  0.406782          2  \n",
       "2018-02-02  1.046761          0  \n",
       "2018-02-05  1.531233          0  \n",
       "2018-02-06  1.811964          0  \n",
       "2018-02-07  1.964682          2  \n",
       "2018-02-08  1.936829          0  \n",
       "2018-02-09  1.777378          2  \n",
       "2018-02-12  1.622243          0  \n",
       "2018-02-21  1.695295          2  \n",
       "2018-02-22  1.672551          2  \n",
       "2018-02-23  0.891800          0  \n",
       "2018-02-26  0.734604          2  \n",
       "2018-02-27  0.635921          0  \n",
       "2018-03-01  1.282072          2  \n",
       "2018-03-02  1.391752          0  \n",
       "2018-03-05  0.642716          0  \n",
       "2018-03-06  0.928400          2  \n",
       "2018-03-07  1.637692          0  \n",
       "2018-03-08  1.163752          1  \n",
       "2018-03-09  1.113541          1  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = stock_df[7:2407][[\"K value\",\"D value\",\"William\",\"MACD\",\"market_Change(%)\",\"Beta_7D\",\"Close r/f\"]]\n",
    "train_set = df[:2000]\n",
    "test_set = df[2000:]\n",
    "print(train_set.shape)\n",
    "print(test_set.shape)\n",
    "train_set.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for i in range(30,2000):\n",
    "    x = train_set[i-30:i][[\"K value\",\"D value\",\"William\",\"MACD\",\"market_Change(%)\",\"Beta_7D\"]].values\n",
    "    features.append(x.tolist())\n",
    "features = torch.FloatTensor(features)\n",
    "\n",
    "labels = []\n",
    "for i in range(31,2001):\n",
    "    x = train_set[i-1:i][\"Close r/f\"]\n",
    "    labels.append(x.tolist())\n",
    "labels = torch.LongTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1970, 30, 6])\n",
      "torch.Size([1970, 1])\n",
      "torch.Size([1970])\n"
     ]
    }
   ],
   "source": [
    "print(features.size())\n",
    "print(labels.size())\n",
    "labels = labels.view(-1)\n",
    "print(labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 10000\n",
    "#BATCH_SIZE = 100\n",
    "TIME_STEP = 30\n",
    "INPUT_SIZE = 6\n",
    "LR = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntorch_dataset = Data.TensorDataset(features,labels)\\ntrain_loader = Data.DataLoader(\\n    dataset = torch_dataset,\\n    batch_size = BATCH_SIZE,\\n    num_workers = 10\\n)\\n'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "torch_dataset = Data.TensorDataset(features,labels)\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset = torch_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    num_workers = 10\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN,self).__init__()\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=64,         \n",
    "            num_layers=2,\n",
    "            dropout=0.6,\n",
    "            batch_first=True, \n",
    "        )\n",
    "        self.hidden1 = torch.nn.Linear(64, 32)\n",
    "        self.hidden2 = torch.nn.Linear(32, 16)\n",
    "        self.out = torch.nn.Linear(16,3)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        r_out,(h_n,h_c) = self.lstm(x,None)\n",
    "        value = self.hidden1(r_out[:,-1,:])\n",
    "        value2 = self.hidden2(value)\n",
    "        out = self.out(value2)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (lstm): LSTM(6, 64, num_layers=2, batch_first=True, dropout=0.6)\n",
      "  (hidden1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (hidden2): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (out): Linear(in_features=16, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = RNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)   \n",
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370\n"
     ]
    }
   ],
   "source": [
    "test_features = []\n",
    "for i in range(30,400):\n",
    "    x = test_set[i-30:i][[\"K value\",\"D value\",\"William\",\"MACD\",\"market_Change(%)\",\"Beta_7D\"]].values\n",
    "    test_features.append(x.tolist())\n",
    "test_features = torch.FloatTensor(test_features)\n",
    "\n",
    "test_labels = []\n",
    "for i in range(31,401):\n",
    "    x = test_set[i-1:i][\"Close r/f\"]\n",
    "    test_labels.append(x.tolist())\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Train Avg Loss: 0.8998  | Accuracy: 0.4711\n",
      "Epoch: 20 | Train Avg Loss: 0.8990  | Accuracy: 0.4650\n",
      "Epoch: 30 | Train Avg Loss: 0.8981  | Accuracy: 0.4777\n",
      "Epoch: 40 | Train Avg Loss: 0.8977  | Accuracy: 0.4929\n",
      "Epoch: 50 | Train Avg Loss: 0.8965  | Accuracy: 0.4858\n",
      "Epoch: 60 | Train Avg Loss: 0.8954  | Accuracy: 0.4629\n",
      "Epoch: 70 | Train Avg Loss: 0.8941  | Accuracy: 0.4990\n",
      "Epoch: 80 | Train Avg Loss: 0.8925  | Accuracy: 0.4843\n",
      "Epoch: 90 | Train Avg Loss: 0.8908  | Accuracy: 0.4893\n",
      "Epoch: 100 | Train Avg Loss: 0.8887  | Accuracy: 0.5005\n",
      "Epoch: 110 | Train Avg Loss: 0.8852  | Accuracy: 0.5152\n",
      "Epoch: 120 | Train Avg Loss: 0.8829  | Accuracy: 0.4873\n",
      "Epoch: 130 | Train Avg Loss: 0.8790  | Accuracy: 0.5127\n",
      "Epoch: 140 | Train Avg Loss: 0.8777  | Accuracy: 0.5193\n",
      "Epoch: 150 | Train Avg Loss: 0.8751  | Accuracy: 0.5122\n",
      "Epoch: 160 | Train Avg Loss: 0.8738  | Accuracy: 0.5193\n",
      "Epoch: 170 | Train Avg Loss: 0.8730  | Accuracy: 0.5335\n",
      "Epoch: 180 | Train Avg Loss: 0.8648  | Accuracy: 0.5168\n",
      "Epoch: 190 | Train Avg Loss: 0.8615  | Accuracy: 0.5234\n",
      "Epoch: 200 | Train Avg Loss: 0.8582  | Accuracy: 0.5492\n",
      "Epoch: 210 | Train Avg Loss: 0.8565  | Accuracy: 0.5320\n",
      "Epoch: 220 | Train Avg Loss: 0.8486  | Accuracy: 0.5421\n",
      "Epoch: 230 | Train Avg Loss: 0.8415  | Accuracy: 0.5584\n",
      "Epoch: 240 | Train Avg Loss: 0.8416  | Accuracy: 0.5523\n",
      "Epoch: 250 | Train Avg Loss: 0.8336  | Accuracy: 0.5467\n",
      "Epoch: 260 | Train Avg Loss: 0.8248  | Accuracy: 0.5426\n",
      "Epoch: 270 | Train Avg Loss: 0.8205  | Accuracy: 0.5731\n",
      "Epoch: 280 | Train Avg Loss: 0.8105  | Accuracy: 0.5706\n",
      "Epoch: 290 | Train Avg Loss: 0.8032  | Accuracy: 0.5827\n",
      "Epoch: 300 | Train Avg Loss: 0.7939  | Accuracy: 0.5832\n",
      "Epoch: 310 | Train Avg Loss: 0.7921  | Accuracy: 0.5822\n",
      "Epoch: 320 | Train Avg Loss: 0.7826  | Accuracy: 0.5970\n",
      "Epoch: 330 | Train Avg Loss: 0.7681  | Accuracy: 0.6046\n",
      "Epoch: 340 | Train Avg Loss: 0.7582  | Accuracy: 0.6157\n",
      "Epoch: 350 | Train Avg Loss: 0.7546  | Accuracy: 0.6020\n",
      "Epoch: 360 | Train Avg Loss: 0.7470  | Accuracy: 0.6371\n",
      "Epoch: 370 | Train Avg Loss: 0.7307  | Accuracy: 0.6386\n",
      "Epoch: 380 | Train Avg Loss: 0.7212  | Accuracy: 0.6234\n",
      "Epoch: 390 | Train Avg Loss: 0.7093  | Accuracy: 0.6360\n",
      "Epoch: 400 | Train Avg Loss: 0.6947  | Accuracy: 0.6635\n",
      "Epoch: 410 | Train Avg Loss: 0.6903  | Accuracy: 0.6447\n",
      "Epoch: 420 | Train Avg Loss: 0.6733  | Accuracy: 0.6716\n",
      "Epoch: 430 | Train Avg Loss: 0.6513  | Accuracy: 0.6888\n",
      "Epoch: 440 | Train Avg Loss: 0.6548  | Accuracy: 0.6863\n",
      "Epoch: 450 | Train Avg Loss: 0.6401  | Accuracy: 0.6863\n",
      "Epoch: 460 | Train Avg Loss: 0.6312  | Accuracy: 0.6970\n",
      "Epoch: 470 | Train Avg Loss: 0.6039  | Accuracy: 0.7081\n",
      "Epoch: 480 | Train Avg Loss: 0.5909  | Accuracy: 0.7152\n",
      "Epoch: 490 | Train Avg Loss: 0.5813  | Accuracy: 0.7350\n",
      "Epoch: 500 | Train Avg Loss: 0.5637  | Accuracy: 0.7325\n",
      "Epoch: 510 | Train Avg Loss: 0.5647  | Accuracy: 0.7477\n",
      "Epoch: 520 | Train Avg Loss: 0.5496  | Accuracy: 0.7508\n",
      "Epoch: 530 | Train Avg Loss: 0.5338  | Accuracy: 0.7508\n",
      "Epoch: 540 | Train Avg Loss: 0.5202  | Accuracy: 0.7736\n",
      "Epoch: 550 | Train Avg Loss: 0.5076  | Accuracy: 0.7731\n",
      "Epoch: 560 | Train Avg Loss: 0.5017  | Accuracy: 0.7797\n",
      "Epoch: 570 | Train Avg Loss: 0.4687  | Accuracy: 0.7964\n",
      "Epoch: 580 | Train Avg Loss: 0.4731  | Accuracy: 0.7868\n",
      "Epoch: 590 | Train Avg Loss: 0.4594  | Accuracy: 0.8051\n",
      "Epoch: 600 | Train Avg Loss: 0.4605  | Accuracy: 0.7888\n",
      "Epoch: 610 | Train Avg Loss: 0.4525  | Accuracy: 0.8066\n",
      "Epoch: 620 | Train Avg Loss: 0.4204  | Accuracy: 0.8132\n",
      "Epoch: 630 | Train Avg Loss: 0.4267  | Accuracy: 0.8020\n",
      "Epoch: 640 | Train Avg Loss: 0.4336  | Accuracy: 0.8061\n",
      "Epoch: 650 | Train Avg Loss: 0.4163  | Accuracy: 0.8147\n",
      "Epoch: 660 | Train Avg Loss: 0.4054  | Accuracy: 0.8274\n",
      "Epoch: 670 | Train Avg Loss: 0.3851  | Accuracy: 0.8462\n",
      "Epoch: 680 | Train Avg Loss: 0.3800  | Accuracy: 0.8371\n",
      "Epoch: 690 | Train Avg Loss: 0.3858  | Accuracy: 0.8228\n",
      "Epoch: 700 | Train Avg Loss: 0.3759  | Accuracy: 0.8492\n",
      "Epoch: 710 | Train Avg Loss: 0.3544  | Accuracy: 0.8482\n",
      "Epoch: 720 | Train Avg Loss: 0.3554  | Accuracy: 0.8503\n",
      "Epoch: 730 | Train Avg Loss: 0.3662  | Accuracy: 0.8533\n",
      "Epoch: 740 | Train Avg Loss: 0.3543  | Accuracy: 0.8411\n",
      "Epoch: 750 | Train Avg Loss: 0.3373  | Accuracy: 0.8685\n",
      "Epoch: 760 | Train Avg Loss: 0.3364  | Accuracy: 0.8599\n",
      "Epoch: 770 | Train Avg Loss: 0.3203  | Accuracy: 0.8513\n",
      "Epoch: 780 | Train Avg Loss: 0.3262  | Accuracy: 0.8482\n",
      "Epoch: 790 | Train Avg Loss: 0.3168  | Accuracy: 0.8604\n",
      "Epoch: 800 | Train Avg Loss: 0.2974  | Accuracy: 0.8797\n",
      "Epoch: 810 | Train Avg Loss: 0.3023  | Accuracy: 0.8701\n",
      "Epoch: 820 | Train Avg Loss: 0.3002  | Accuracy: 0.8873\n",
      "Epoch: 830 | Train Avg Loss: 0.2923  | Accuracy: 0.8787\n",
      "Epoch: 840 | Train Avg Loss: 0.2830  | Accuracy: 0.8802\n",
      "Epoch: 850 | Train Avg Loss: 0.2794  | Accuracy: 0.8934\n",
      "Epoch: 860 | Train Avg Loss: 0.2760  | Accuracy: 0.8929\n",
      "Epoch: 870 | Train Avg Loss: 0.2853  | Accuracy: 0.8970\n",
      "Epoch: 880 | Train Avg Loss: 0.2879  | Accuracy: 0.8868\n",
      "Epoch: 890 | Train Avg Loss: 0.2596  | Accuracy: 0.9000\n",
      "Epoch: 900 | Train Avg Loss: 0.2715  | Accuracy: 0.8934\n",
      "Epoch: 910 | Train Avg Loss: 0.2616  | Accuracy: 0.8975\n",
      "Epoch: 920 | Train Avg Loss: 0.2493  | Accuracy: 0.9030\n",
      "Epoch: 930 | Train Avg Loss: 0.2447  | Accuracy: 0.8954\n",
      "Epoch: 940 | Train Avg Loss: 0.2364  | Accuracy: 0.9081\n",
      "Epoch: 950 | Train Avg Loss: 0.2431  | Accuracy: 0.9086\n",
      "Epoch: 960 | Train Avg Loss: 0.2408  | Accuracy: 0.8990\n",
      "Epoch: 970 | Train Avg Loss: 0.2381  | Accuracy: 0.9005\n",
      "Epoch: 980 | Train Avg Loss: 0.2307  | Accuracy: 0.9178\n",
      "Epoch: 990 | Train Avg Loss: 0.2251  | Accuracy: 0.9162\n",
      "Epoch: 1000 | Train Avg Loss: 0.2233  | Accuracy: 0.9223\n",
      "Epoch: 1010 | Train Avg Loss: 0.2202  | Accuracy: 0.9223\n",
      "Epoch: 1020 | Train Avg Loss: 0.2139  | Accuracy: 0.9061\n",
      "Epoch: 1030 | Train Avg Loss: 0.2184  | Accuracy: 0.9107\n",
      "Epoch: 1040 | Train Avg Loss: 0.2057  | Accuracy: 0.9223\n",
      "Epoch: 1050 | Train Avg Loss: 0.2127  | Accuracy: 0.9188\n",
      "Epoch: 1060 | Train Avg Loss: 0.1993  | Accuracy: 0.9325\n",
      "Epoch: 1070 | Train Avg Loss: 0.2066  | Accuracy: 0.9198\n",
      "Epoch: 1080 | Train Avg Loss: 0.1953  | Accuracy: 0.9264\n",
      "Epoch: 1090 | Train Avg Loss: 0.1940  | Accuracy: 0.9198\n",
      "Epoch: 1100 | Train Avg Loss: 0.1945  | Accuracy: 0.9228\n",
      "Epoch: 1110 | Train Avg Loss: 0.2002  | Accuracy: 0.9289\n",
      "Epoch: 1120 | Train Avg Loss: 0.1987  | Accuracy: 0.9335\n",
      "Epoch: 1130 | Train Avg Loss: 0.1832  | Accuracy: 0.9299\n",
      "Epoch: 1140 | Train Avg Loss: 0.1870  | Accuracy: 0.9315\n",
      "Epoch: 1150 | Train Avg Loss: 0.1789  | Accuracy: 0.9228\n",
      "Epoch: 1160 | Train Avg Loss: 0.1912  | Accuracy: 0.9315\n",
      "Epoch: 1170 | Train Avg Loss: 0.1774  | Accuracy: 0.9330\n",
      "Epoch: 1180 | Train Avg Loss: 0.1673  | Accuracy: 0.9340\n",
      "Epoch: 1190 | Train Avg Loss: 0.1731  | Accuracy: 0.9305\n",
      "Epoch: 1200 | Train Avg Loss: 0.1814  | Accuracy: 0.9335\n",
      "Epoch: 1210 | Train Avg Loss: 0.1813  | Accuracy: 0.9274\n",
      "Epoch: 1220 | Train Avg Loss: 0.1763  | Accuracy: 0.9259\n",
      "Epoch: 1230 | Train Avg Loss: 0.1617  | Accuracy: 0.9416\n",
      "Epoch: 1240 | Train Avg Loss: 0.1540  | Accuracy: 0.9391\n",
      "Epoch: 1250 | Train Avg Loss: 0.1545  | Accuracy: 0.9360\n",
      "Epoch: 1260 | Train Avg Loss: 0.1519  | Accuracy: 0.9345\n",
      "Epoch: 1270 | Train Avg Loss: 0.1514  | Accuracy: 0.9411\n",
      "Epoch: 1280 | Train Avg Loss: 0.1627  | Accuracy: 0.9279\n",
      "Epoch: 1290 | Train Avg Loss: 0.1691  | Accuracy: 0.9325\n",
      "Epoch: 1300 | Train Avg Loss: 0.1692  | Accuracy: 0.9289\n",
      "Epoch: 1310 | Train Avg Loss: 0.1575  | Accuracy: 0.9442\n",
      "Epoch: 1320 | Train Avg Loss: 0.1530  | Accuracy: 0.9421\n",
      "Epoch: 1330 | Train Avg Loss: 0.1483  | Accuracy: 0.9447\n",
      "Epoch: 1340 | Train Avg Loss: 0.1560  | Accuracy: 0.9426\n",
      "Epoch: 1350 | Train Avg Loss: 0.1529  | Accuracy: 0.9482\n",
      "Epoch: 1360 | Train Avg Loss: 0.1458  | Accuracy: 0.9503\n",
      "Epoch: 1370 | Train Avg Loss: 0.1529  | Accuracy: 0.9411\n",
      "Epoch: 1380 | Train Avg Loss: 0.1494  | Accuracy: 0.9472\n",
      "Epoch: 1390 | Train Avg Loss: 0.1424  | Accuracy: 0.9523\n",
      "Epoch: 1400 | Train Avg Loss: 0.1288  | Accuracy: 0.9533\n",
      "Epoch: 1410 | Train Avg Loss: 0.1369  | Accuracy: 0.9594\n",
      "Epoch: 1420 | Train Avg Loss: 0.1321  | Accuracy: 0.9452\n",
      "Epoch: 1430 | Train Avg Loss: 0.1434  | Accuracy: 0.9442\n",
      "Epoch: 1440 | Train Avg Loss: 0.1415  | Accuracy: 0.9569\n",
      "Epoch: 1450 | Train Avg Loss: 0.1363  | Accuracy: 0.9497\n",
      "Epoch: 1460 | Train Avg Loss: 0.1309  | Accuracy: 0.9462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1470 | Train Avg Loss: 0.1282  | Accuracy: 0.9518\n",
      "Epoch: 1480 | Train Avg Loss: 0.1349  | Accuracy: 0.9472\n",
      "Epoch: 1490 | Train Avg Loss: 0.1310  | Accuracy: 0.9563\n",
      "Epoch: 1500 | Train Avg Loss: 0.1393  | Accuracy: 0.9508\n",
      "Epoch: 1510 | Train Avg Loss: 0.1245  | Accuracy: 0.9482\n",
      "Epoch: 1520 | Train Avg Loss: 0.1301  | Accuracy: 0.9513\n",
      "Epoch: 1530 | Train Avg Loss: 0.1295  | Accuracy: 0.9563\n",
      "Epoch: 1540 | Train Avg Loss: 0.1240  | Accuracy: 0.9599\n",
      "Epoch: 1550 | Train Avg Loss: 0.1221  | Accuracy: 0.9523\n",
      "Epoch: 1560 | Train Avg Loss: 0.1171  | Accuracy: 0.9599\n",
      "Epoch: 1570 | Train Avg Loss: 0.1150  | Accuracy: 0.9609\n",
      "Epoch: 1580 | Train Avg Loss: 0.1173  | Accuracy: 0.9640\n",
      "Epoch: 1590 | Train Avg Loss: 0.1239  | Accuracy: 0.9563\n",
      "Epoch: 1600 | Train Avg Loss: 0.1225  | Accuracy: 0.9513\n",
      "Epoch: 1610 | Train Avg Loss: 0.1266  | Accuracy: 0.9599\n",
      "Epoch: 1620 | Train Avg Loss: 0.1178  | Accuracy: 0.9589\n",
      "Epoch: 1630 | Train Avg Loss: 0.1198  | Accuracy: 0.9599\n",
      "Epoch: 1640 | Train Avg Loss: 0.1176  | Accuracy: 0.9579\n",
      "Epoch: 1650 | Train Avg Loss: 0.1125  | Accuracy: 0.9548\n",
      "Epoch: 1660 | Train Avg Loss: 0.1060  | Accuracy: 0.9604\n",
      "Epoch: 1670 | Train Avg Loss: 0.1125  | Accuracy: 0.9599\n",
      "Epoch: 1680 | Train Avg Loss: 0.1185  | Accuracy: 0.9594\n",
      "Epoch: 1690 | Train Avg Loss: 0.1226  | Accuracy: 0.9538\n",
      "Epoch: 1700 | Train Avg Loss: 0.1184  | Accuracy: 0.9624\n",
      "Epoch: 1710 | Train Avg Loss: 0.1067  | Accuracy: 0.9594\n",
      "Epoch: 1720 | Train Avg Loss: 0.1131  | Accuracy: 0.9594\n",
      "Epoch: 1730 | Train Avg Loss: 0.1082  | Accuracy: 0.9660\n",
      "Epoch: 1740 | Train Avg Loss: 0.1054  | Accuracy: 0.9645\n",
      "Epoch: 1750 | Train Avg Loss: 0.1039  | Accuracy: 0.9579\n",
      "Epoch: 1760 | Train Avg Loss: 0.1058  | Accuracy: 0.9619\n",
      "Epoch: 1770 | Train Avg Loss: 0.1045  | Accuracy: 0.9528\n",
      "Epoch: 1780 | Train Avg Loss: 0.1062  | Accuracy: 0.9599\n",
      "Epoch: 1790 | Train Avg Loss: 0.1078  | Accuracy: 0.9660\n",
      "Epoch: 1800 | Train Avg Loss: 0.1019  | Accuracy: 0.9645\n",
      "Epoch: 1810 | Train Avg Loss: 0.0988  | Accuracy: 0.9609\n",
      "Epoch: 1820 | Train Avg Loss: 0.0962  | Accuracy: 0.9716\n",
      "Epoch: 1830 | Train Avg Loss: 0.0904  | Accuracy: 0.9660\n",
      "Epoch: 1840 | Train Avg Loss: 0.0945  | Accuracy: 0.9706\n",
      "Epoch: 1850 | Train Avg Loss: 0.0947  | Accuracy: 0.9670\n",
      "Epoch: 1860 | Train Avg Loss: 0.1044  | Accuracy: 0.9599\n",
      "Epoch: 1870 | Train Avg Loss: 0.0948  | Accuracy: 0.9614\n",
      "Epoch: 1880 | Train Avg Loss: 0.1038  | Accuracy: 0.9579\n",
      "Epoch: 1890 | Train Avg Loss: 0.0960  | Accuracy: 0.9746\n",
      "Epoch: 1900 | Train Avg Loss: 0.0947  | Accuracy: 0.9594\n",
      "Epoch: 1910 | Train Avg Loss: 0.1033  | Accuracy: 0.9685\n",
      "Epoch: 1920 | Train Avg Loss: 0.0943  | Accuracy: 0.9716\n",
      "Epoch: 1930 | Train Avg Loss: 0.0959  | Accuracy: 0.9640\n",
      "Epoch: 1940 | Train Avg Loss: 0.0962  | Accuracy: 0.9670\n",
      "Epoch: 1950 | Train Avg Loss: 0.0884  | Accuracy: 0.9695\n",
      "Epoch: 1960 | Train Avg Loss: 0.0949  | Accuracy: 0.9716\n",
      "Epoch: 1970 | Train Avg Loss: 0.0892  | Accuracy: 0.9777\n",
      "Epoch: 1980 | Train Avg Loss: 0.0875  | Accuracy: 0.9792\n",
      "Epoch: 1990 | Train Avg Loss: 0.0931  | Accuracy: 0.9655\n",
      "Epoch: 2000 | Train Avg Loss: 0.0898  | Accuracy: 0.9690\n",
      "Epoch: 2010 | Train Avg Loss: 0.0883  | Accuracy: 0.9726\n",
      "Epoch: 2020 | Train Avg Loss: 0.0819  | Accuracy: 0.9766\n",
      "Epoch: 2030 | Train Avg Loss: 0.0830  | Accuracy: 0.9741\n",
      "Epoch: 2040 | Train Avg Loss: 0.0909  | Accuracy: 0.9741\n",
      "Epoch: 2050 | Train Avg Loss: 0.0913  | Accuracy: 0.9695\n",
      "Epoch: 2060 | Train Avg Loss: 0.0835  | Accuracy: 0.9716\n",
      "Epoch: 2070 | Train Avg Loss: 0.0882  | Accuracy: 0.9685\n",
      "Epoch: 2080 | Train Avg Loss: 0.0853  | Accuracy: 0.9650\n",
      "Epoch: 2090 | Train Avg Loss: 0.0917  | Accuracy: 0.9563\n",
      "Epoch: 2100 | Train Avg Loss: 0.0930  | Accuracy: 0.9660\n",
      "Epoch: 2110 | Train Avg Loss: 0.0885  | Accuracy: 0.9731\n",
      "Epoch: 2120 | Train Avg Loss: 0.0850  | Accuracy: 0.9701\n",
      "Epoch: 2130 | Train Avg Loss: 0.0876  | Accuracy: 0.9746\n",
      "Epoch: 2140 | Train Avg Loss: 0.0821  | Accuracy: 0.9726\n",
      "Epoch: 2150 | Train Avg Loss: 0.0813  | Accuracy: 0.9787\n",
      "Epoch: 2160 | Train Avg Loss: 0.0794  | Accuracy: 0.9736\n",
      "Epoch: 2170 | Train Avg Loss: 0.0871  | Accuracy: 0.9726\n",
      "Epoch: 2180 | Train Avg Loss: 0.0764  | Accuracy: 0.9756\n",
      "Epoch: 2190 | Train Avg Loss: 0.0889  | Accuracy: 0.9746\n",
      "Epoch: 2200 | Train Avg Loss: 0.0747  | Accuracy: 0.9680\n",
      "Epoch: 2210 | Train Avg Loss: 0.0741  | Accuracy: 0.9741\n",
      "Epoch: 2220 | Train Avg Loss: 0.0713  | Accuracy: 0.9787\n",
      "Epoch: 2230 | Train Avg Loss: 0.0793  | Accuracy: 0.9690\n",
      "Epoch: 2240 | Train Avg Loss: 0.0749  | Accuracy: 0.9766\n",
      "Epoch: 2250 | Train Avg Loss: 0.0729  | Accuracy: 0.9711\n",
      "Epoch: 2260 | Train Avg Loss: 0.0856  | Accuracy: 0.9706\n",
      "Epoch: 2270 | Train Avg Loss: 0.0801  | Accuracy: 0.9751\n",
      "Epoch: 2280 | Train Avg Loss: 0.0751  | Accuracy: 0.9721\n",
      "Epoch: 2290 | Train Avg Loss: 0.0798  | Accuracy: 0.9690\n",
      "Epoch: 2300 | Train Avg Loss: 0.0854  | Accuracy: 0.9741\n",
      "Epoch: 2310 | Train Avg Loss: 0.0761  | Accuracy: 0.9777\n",
      "Epoch: 2320 | Train Avg Loss: 0.0656  | Accuracy: 0.9787\n",
      "Epoch: 2330 | Train Avg Loss: 0.0788  | Accuracy: 0.9701\n",
      "Epoch: 2340 | Train Avg Loss: 0.0763  | Accuracy: 0.9751\n",
      "Epoch: 2350 | Train Avg Loss: 0.0760  | Accuracy: 0.9766\n",
      "Epoch: 2360 | Train Avg Loss: 0.0740  | Accuracy: 0.9751\n",
      "Epoch: 2370 | Train Avg Loss: 0.0680  | Accuracy: 0.9802\n",
      "Epoch: 2380 | Train Avg Loss: 0.0765  | Accuracy: 0.9741\n",
      "Epoch: 2390 | Train Avg Loss: 0.0698  | Accuracy: 0.9761\n",
      "Epoch: 2400 | Train Avg Loss: 0.0737  | Accuracy: 0.9670\n",
      "Epoch: 2410 | Train Avg Loss: 0.0733  | Accuracy: 0.9782\n",
      "Epoch: 2420 | Train Avg Loss: 0.0683  | Accuracy: 0.9726\n",
      "Epoch: 2430 | Train Avg Loss: 0.0786  | Accuracy: 0.9777\n",
      "Epoch: 2440 | Train Avg Loss: 0.0638  | Accuracy: 0.9777\n",
      "Epoch: 2450 | Train Avg Loss: 0.0687  | Accuracy: 0.9766\n",
      "Epoch: 2460 | Train Avg Loss: 0.0819  | Accuracy: 0.9695\n",
      "Epoch: 2470 | Train Avg Loss: 0.0886  | Accuracy: 0.9751\n",
      "Epoch: 2480 | Train Avg Loss: 0.0802  | Accuracy: 0.9787\n",
      "Epoch: 2490 | Train Avg Loss: 0.0697  | Accuracy: 0.9822\n",
      "Epoch: 2500 | Train Avg Loss: 0.0797  | Accuracy: 0.9761\n",
      "Epoch: 2510 | Train Avg Loss: 0.0667  | Accuracy: 0.9716\n",
      "Epoch: 2520 | Train Avg Loss: 0.0737  | Accuracy: 0.9741\n",
      "Epoch: 2530 | Train Avg Loss: 0.0713  | Accuracy: 0.9726\n",
      "Epoch: 2540 | Train Avg Loss: 0.0703  | Accuracy: 0.9782\n",
      "Epoch: 2550 | Train Avg Loss: 0.0671  | Accuracy: 0.9787\n",
      "Epoch: 2560 | Train Avg Loss: 0.0699  | Accuracy: 0.9797\n",
      "Epoch: 2570 | Train Avg Loss: 0.0644  | Accuracy: 0.9741\n",
      "Epoch: 2580 | Train Avg Loss: 0.0654  | Accuracy: 0.9782\n",
      "Epoch: 2590 | Train Avg Loss: 0.0708  | Accuracy: 0.9746\n",
      "Epoch: 2600 | Train Avg Loss: 0.0679  | Accuracy: 0.9751\n",
      "Epoch: 2610 | Train Avg Loss: 0.0702  | Accuracy: 0.9741\n",
      "Epoch: 2620 | Train Avg Loss: 0.0643  | Accuracy: 0.9756\n",
      "Epoch: 2630 | Train Avg Loss: 0.0631  | Accuracy: 0.9792\n",
      "Epoch: 2640 | Train Avg Loss: 0.0667  | Accuracy: 0.9812\n",
      "Epoch: 2650 | Train Avg Loss: 0.0672  | Accuracy: 0.9772\n",
      "Epoch: 2660 | Train Avg Loss: 0.0719  | Accuracy: 0.9782\n",
      "Epoch: 2670 | Train Avg Loss: 0.0730  | Accuracy: 0.9761\n",
      "Epoch: 2680 | Train Avg Loss: 0.0613  | Accuracy: 0.9787\n",
      "Epoch: 2690 | Train Avg Loss: 0.0594  | Accuracy: 0.9797\n",
      "Epoch: 2700 | Train Avg Loss: 0.0613  | Accuracy: 0.9787\n",
      "Epoch: 2710 | Train Avg Loss: 0.0650  | Accuracy: 0.9787\n",
      "Epoch: 2720 | Train Avg Loss: 0.0633  | Accuracy: 0.9838\n",
      "Epoch: 2730 | Train Avg Loss: 0.0578  | Accuracy: 0.9802\n",
      "Epoch: 2740 | Train Avg Loss: 0.0598  | Accuracy: 0.9797\n",
      "Epoch: 2750 | Train Avg Loss: 0.0633  | Accuracy: 0.9827\n",
      "Epoch: 2760 | Train Avg Loss: 0.0610  | Accuracy: 0.9797\n",
      "Epoch: 2770 | Train Avg Loss: 0.0538  | Accuracy: 0.9838\n",
      "Epoch: 2780 | Train Avg Loss: 0.0647  | Accuracy: 0.9731\n",
      "Epoch: 2790 | Train Avg Loss: 0.0585  | Accuracy: 0.9807\n",
      "Epoch: 2800 | Train Avg Loss: 0.0553  | Accuracy: 0.9817\n",
      "Epoch: 2810 | Train Avg Loss: 0.0597  | Accuracy: 0.9726\n",
      "Epoch: 2820 | Train Avg Loss: 0.0733  | Accuracy: 0.9787\n",
      "Epoch: 2830 | Train Avg Loss: 0.0661  | Accuracy: 0.9822\n",
      "Epoch: 2840 | Train Avg Loss: 0.0625  | Accuracy: 0.9832\n",
      "Epoch: 2850 | Train Avg Loss: 0.0601  | Accuracy: 0.9756\n",
      "Epoch: 2860 | Train Avg Loss: 0.0668  | Accuracy: 0.9772\n",
      "Epoch: 2870 | Train Avg Loss: 0.0645  | Accuracy: 0.9782\n",
      "Epoch: 2880 | Train Avg Loss: 0.0527  | Accuracy: 0.9812\n",
      "Epoch: 2890 | Train Avg Loss: 0.0543  | Accuracy: 0.9848\n",
      "Epoch: 2900 | Train Avg Loss: 0.0618  | Accuracy: 0.9807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2910 | Train Avg Loss: 0.0646  | Accuracy: 0.9787\n",
      "Epoch: 2920 | Train Avg Loss: 0.0574  | Accuracy: 0.9822\n",
      "Epoch: 2930 | Train Avg Loss: 0.0533  | Accuracy: 0.9827\n",
      "Epoch: 2940 | Train Avg Loss: 0.0613  | Accuracy: 0.9756\n",
      "Epoch: 2950 | Train Avg Loss: 0.0601  | Accuracy: 0.9807\n",
      "Epoch: 2960 | Train Avg Loss: 0.0628  | Accuracy: 0.9772\n",
      "Epoch: 2970 | Train Avg Loss: 0.0645  | Accuracy: 0.9797\n",
      "Epoch: 2980 | Train Avg Loss: 0.0629  | Accuracy: 0.9817\n",
      "Epoch: 2990 | Train Avg Loss: 0.0637  | Accuracy: 0.9822\n",
      "Epoch: 3000 | Train Avg Loss: 0.0585  | Accuracy: 0.9736\n",
      "Epoch: 3010 | Train Avg Loss: 0.0582  | Accuracy: 0.9787\n",
      "Epoch: 3020 | Train Avg Loss: 0.0611  | Accuracy: 0.9822\n",
      "Epoch: 3030 | Train Avg Loss: 0.0643  | Accuracy: 0.9741\n",
      "Epoch: 3040 | Train Avg Loss: 0.0531  | Accuracy: 0.9777\n",
      "Epoch: 3050 | Train Avg Loss: 0.0548  | Accuracy: 0.9782\n",
      "Epoch: 3060 | Train Avg Loss: 0.0492  | Accuracy: 0.9863\n",
      "Epoch: 3070 | Train Avg Loss: 0.0510  | Accuracy: 0.9848\n",
      "Epoch: 3080 | Train Avg Loss: 0.0620  | Accuracy: 0.9802\n",
      "Epoch: 3090 | Train Avg Loss: 0.0667  | Accuracy: 0.9766\n",
      "Epoch: 3100 | Train Avg Loss: 0.0664  | Accuracy: 0.9853\n",
      "Epoch: 3110 | Train Avg Loss: 0.0560  | Accuracy: 0.9827\n",
      "Epoch: 3120 | Train Avg Loss: 0.0520  | Accuracy: 0.9751\n",
      "Epoch: 3130 | Train Avg Loss: 0.0549  | Accuracy: 0.9868\n",
      "Epoch: 3140 | Train Avg Loss: 0.0610  | Accuracy: 0.9807\n",
      "Epoch: 3150 | Train Avg Loss: 0.0581  | Accuracy: 0.9838\n",
      "Epoch: 3160 | Train Avg Loss: 0.0596  | Accuracy: 0.9822\n",
      "Epoch: 3170 | Train Avg Loss: 0.0560  | Accuracy: 0.9792\n",
      "Epoch: 3180 | Train Avg Loss: 0.0577  | Accuracy: 0.9843\n",
      "Epoch: 3190 | Train Avg Loss: 0.0564  | Accuracy: 0.9848\n",
      "Epoch: 3200 | Train Avg Loss: 0.0558  | Accuracy: 0.9807\n",
      "Epoch: 3210 | Train Avg Loss: 0.0516  | Accuracy: 0.9832\n",
      "Epoch: 3220 | Train Avg Loss: 0.0526  | Accuracy: 0.9827\n",
      "Epoch: 3230 | Train Avg Loss: 0.0533  | Accuracy: 0.9807\n",
      "Epoch: 3240 | Train Avg Loss: 0.0566  | Accuracy: 0.9873\n",
      "Epoch: 3250 | Train Avg Loss: 0.0552  | Accuracy: 0.9802\n",
      "Epoch: 3260 | Train Avg Loss: 0.0612  | Accuracy: 0.9787\n",
      "Epoch: 3270 | Train Avg Loss: 0.0575  | Accuracy: 0.9807\n",
      "Epoch: 3280 | Train Avg Loss: 0.0530  | Accuracy: 0.9843\n",
      "Epoch: 3290 | Train Avg Loss: 0.0559  | Accuracy: 0.9873\n",
      "Epoch: 3300 | Train Avg Loss: 0.0567  | Accuracy: 0.9807\n",
      "Epoch: 3310 | Train Avg Loss: 0.0666  | Accuracy: 0.9736\n",
      "Epoch: 3320 | Train Avg Loss: 0.0640  | Accuracy: 0.9782\n",
      "Epoch: 3330 | Train Avg Loss: 0.0558  | Accuracy: 0.9772\n",
      "Epoch: 3340 | Train Avg Loss: 0.0606  | Accuracy: 0.9843\n",
      "Epoch: 3350 | Train Avg Loss: 0.0584  | Accuracy: 0.9812\n",
      "Epoch: 3360 | Train Avg Loss: 0.0637  | Accuracy: 0.9873\n",
      "Epoch: 3370 | Train Avg Loss: 0.0537  | Accuracy: 0.9843\n",
      "Epoch: 3380 | Train Avg Loss: 0.0508  | Accuracy: 0.9807\n",
      "Epoch: 3390 | Train Avg Loss: 0.0585  | Accuracy: 0.9832\n",
      "Epoch: 3400 | Train Avg Loss: 0.0543  | Accuracy: 0.9838\n",
      "Epoch: 3410 | Train Avg Loss: 0.0529  | Accuracy: 0.9848\n",
      "Epoch: 3420 | Train Avg Loss: 0.0515  | Accuracy: 0.9863\n",
      "Epoch: 3430 | Train Avg Loss: 0.0523  | Accuracy: 0.9817\n",
      "Epoch: 3440 | Train Avg Loss: 0.0533  | Accuracy: 0.9822\n",
      "Epoch: 3450 | Train Avg Loss: 0.0499  | Accuracy: 0.9822\n",
      "Epoch: 3460 | Train Avg Loss: 0.0518  | Accuracy: 0.9853\n",
      "Epoch: 3470 | Train Avg Loss: 0.0509  | Accuracy: 0.9863\n",
      "Epoch: 3480 | Train Avg Loss: 0.0505  | Accuracy: 0.9848\n",
      "Epoch: 3490 | Train Avg Loss: 0.0464  | Accuracy: 0.9802\n",
      "Epoch: 3500 | Train Avg Loss: 0.0479  | Accuracy: 0.9868\n",
      "Epoch: 3510 | Train Avg Loss: 0.0488  | Accuracy: 0.9838\n",
      "Epoch: 3520 | Train Avg Loss: 0.0482  | Accuracy: 0.9868\n",
      "Epoch: 3530 | Train Avg Loss: 0.0559  | Accuracy: 0.9848\n",
      "Epoch: 3540 | Train Avg Loss: 0.0539  | Accuracy: 0.9858\n",
      "Epoch: 3550 | Train Avg Loss: 0.0571  | Accuracy: 0.9827\n",
      "Epoch: 3560 | Train Avg Loss: 0.0515  | Accuracy: 0.9827\n",
      "Epoch: 3570 | Train Avg Loss: 0.0516  | Accuracy: 0.9863\n",
      "Epoch: 3580 | Train Avg Loss: 0.0493  | Accuracy: 0.9858\n",
      "Epoch: 3590 | Train Avg Loss: 0.0531  | Accuracy: 0.9817\n",
      "Epoch: 3600 | Train Avg Loss: 0.0627  | Accuracy: 0.9782\n",
      "Epoch: 3610 | Train Avg Loss: 0.0548  | Accuracy: 0.9741\n",
      "Epoch: 3620 | Train Avg Loss: 0.0453  | Accuracy: 0.9843\n",
      "Epoch: 3630 | Train Avg Loss: 0.0496  | Accuracy: 0.9802\n",
      "Epoch: 3640 | Train Avg Loss: 0.0491  | Accuracy: 0.9848\n",
      "Epoch: 3650 | Train Avg Loss: 0.0515  | Accuracy: 0.9827\n",
      "Epoch: 3660 | Train Avg Loss: 0.0571  | Accuracy: 0.9817\n",
      "Epoch: 3670 | Train Avg Loss: 0.0511  | Accuracy: 0.9843\n",
      "Epoch: 3680 | Train Avg Loss: 0.0557  | Accuracy: 0.9802\n",
      "Epoch: 3690 | Train Avg Loss: 0.0597  | Accuracy: 0.9853\n",
      "Epoch: 3700 | Train Avg Loss: 0.0488  | Accuracy: 0.9878\n",
      "Epoch: 3710 | Train Avg Loss: 0.0460  | Accuracy: 0.9832\n",
      "Epoch: 3720 | Train Avg Loss: 0.0515  | Accuracy: 0.9772\n",
      "Epoch: 3730 | Train Avg Loss: 0.0549  | Accuracy: 0.9853\n",
      "Epoch: 3740 | Train Avg Loss: 0.0575  | Accuracy: 0.9878\n",
      "Epoch: 3750 | Train Avg Loss: 0.0548  | Accuracy: 0.9792\n",
      "Epoch: 3760 | Train Avg Loss: 0.0509  | Accuracy: 0.9838\n",
      "Epoch: 3770 | Train Avg Loss: 0.0513  | Accuracy: 0.9848\n",
      "Epoch: 3780 | Train Avg Loss: 0.0551  | Accuracy: 0.9858\n",
      "Epoch: 3790 | Train Avg Loss: 0.0528  | Accuracy: 0.9873\n",
      "Epoch: 3800 | Train Avg Loss: 0.0815  | Accuracy: 0.9640\n",
      "Epoch: 3810 | Train Avg Loss: 0.0841  | Accuracy: 0.9721\n",
      "Epoch: 3820 | Train Avg Loss: 0.0616  | Accuracy: 0.9797\n",
      "Epoch: 3830 | Train Avg Loss: 0.0586  | Accuracy: 0.9782\n",
      "Epoch: 3840 | Train Avg Loss: 0.0780  | Accuracy: 0.9812\n",
      "Epoch: 3850 | Train Avg Loss: 0.0760  | Accuracy: 0.9766\n",
      "Epoch: 3860 | Train Avg Loss: 0.0578  | Accuracy: 0.9807\n",
      "Epoch: 3870 | Train Avg Loss: 0.0595  | Accuracy: 0.9782\n",
      "Epoch: 3880 | Train Avg Loss: 0.0599  | Accuracy: 0.9777\n",
      "Epoch: 3890 | Train Avg Loss: 0.0510  | Accuracy: 0.9843\n",
      "Epoch: 3900 | Train Avg Loss: 0.0480  | Accuracy: 0.9853\n",
      "Epoch: 3910 | Train Avg Loss: 0.0569  | Accuracy: 0.9817\n",
      "Epoch: 3920 | Train Avg Loss: 0.0528  | Accuracy: 0.9848\n",
      "Epoch: 3930 | Train Avg Loss: 0.0549  | Accuracy: 0.9832\n",
      "Epoch: 3940 | Train Avg Loss: 0.0504  | Accuracy: 0.9807\n",
      "Epoch: 3950 | Train Avg Loss: 0.0544  | Accuracy: 0.9853\n",
      "Epoch: 3960 | Train Avg Loss: 0.0590  | Accuracy: 0.9797\n",
      "Epoch: 3970 | Train Avg Loss: 0.0526  | Accuracy: 0.9883\n",
      "Epoch: 3980 | Train Avg Loss: 0.0494  | Accuracy: 0.9843\n",
      "Epoch: 3990 | Train Avg Loss: 0.0466  | Accuracy: 0.9848\n",
      "Epoch: 4000 | Train Avg Loss: 0.0483  | Accuracy: 0.9863\n",
      "Epoch: 4010 | Train Avg Loss: 0.0465  | Accuracy: 0.9792\n",
      "Epoch: 4020 | Train Avg Loss: 0.0544  | Accuracy: 0.9736\n",
      "Epoch: 4030 | Train Avg Loss: 0.0460  | Accuracy: 0.9843\n",
      "Epoch: 4040 | Train Avg Loss: 0.0500  | Accuracy: 0.9797\n",
      "Epoch: 4050 | Train Avg Loss: 0.0509  | Accuracy: 0.9812\n",
      "Epoch: 4060 | Train Avg Loss: 0.0446  | Accuracy: 0.9817\n",
      "Epoch: 4070 | Train Avg Loss: 0.0524  | Accuracy: 0.9802\n",
      "Epoch: 4080 | Train Avg Loss: 0.0489  | Accuracy: 0.9827\n",
      "Epoch: 4090 | Train Avg Loss: 0.0493  | Accuracy: 0.9848\n",
      "Epoch: 4100 | Train Avg Loss: 0.0534  | Accuracy: 0.9832\n",
      "Epoch: 4110 | Train Avg Loss: 0.0527  | Accuracy: 0.9802\n",
      "Epoch: 4120 | Train Avg Loss: 0.0472  | Accuracy: 0.9868\n",
      "Epoch: 4130 | Train Avg Loss: 0.0503  | Accuracy: 0.9868\n",
      "Epoch: 4140 | Train Avg Loss: 0.0481  | Accuracy: 0.9873\n",
      "Epoch: 4150 | Train Avg Loss: 0.0398  | Accuracy: 0.9898\n",
      "Epoch: 4160 | Train Avg Loss: 0.0542  | Accuracy: 0.9822\n",
      "Epoch: 4170 | Train Avg Loss: 0.0618  | Accuracy: 0.9807\n",
      "Epoch: 4180 | Train Avg Loss: 0.0498  | Accuracy: 0.9873\n",
      "Epoch: 4190 | Train Avg Loss: 0.0415  | Accuracy: 0.9868\n",
      "Epoch: 4200 | Train Avg Loss: 0.0504  | Accuracy: 0.9848\n",
      "Epoch: 4210 | Train Avg Loss: 0.0552  | Accuracy: 0.9817\n",
      "Epoch: 4220 | Train Avg Loss: 0.0507  | Accuracy: 0.9858\n",
      "Epoch: 4230 | Train Avg Loss: 0.0622  | Accuracy: 0.9756\n",
      "Epoch: 4240 | Train Avg Loss: 0.0507  | Accuracy: 0.9822\n",
      "Epoch: 4250 | Train Avg Loss: 0.0521  | Accuracy: 0.9838\n",
      "Epoch: 4260 | Train Avg Loss: 0.0500  | Accuracy: 0.9878\n",
      "Epoch: 4270 | Train Avg Loss: 0.0458  | Accuracy: 0.9853\n",
      "Epoch: 4280 | Train Avg Loss: 0.0432  | Accuracy: 0.9853\n",
      "Epoch: 4290 | Train Avg Loss: 0.0419  | Accuracy: 0.9914\n",
      "Epoch: 4300 | Train Avg Loss: 0.0432  | Accuracy: 0.9832\n",
      "Epoch: 4310 | Train Avg Loss: 0.0470  | Accuracy: 0.9863\n",
      "Epoch: 4320 | Train Avg Loss: 0.0472  | Accuracy: 0.9802\n",
      "Epoch: 4330 | Train Avg Loss: 0.0471  | Accuracy: 0.9812\n",
      "Epoch: 4340 | Train Avg Loss: 0.0519  | Accuracy: 0.9843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4350 | Train Avg Loss: 0.0492  | Accuracy: 0.9843\n",
      "Epoch: 4360 | Train Avg Loss: 0.0415  | Accuracy: 0.9858\n",
      "Epoch: 4370 | Train Avg Loss: 0.0509  | Accuracy: 0.9802\n",
      "Epoch: 4380 | Train Avg Loss: 0.0556  | Accuracy: 0.9848\n",
      "Epoch: 4390 | Train Avg Loss: 0.0473  | Accuracy: 0.9878\n",
      "Epoch: 4400 | Train Avg Loss: 0.0497  | Accuracy: 0.9858\n",
      "Epoch: 4410 | Train Avg Loss: 0.0475  | Accuracy: 0.9878\n",
      "Epoch: 4420 | Train Avg Loss: 0.0453  | Accuracy: 0.9827\n",
      "Epoch: 4430 | Train Avg Loss: 0.0445  | Accuracy: 0.9848\n",
      "Epoch: 4440 | Train Avg Loss: 0.0482  | Accuracy: 0.9848\n",
      "Epoch: 4450 | Train Avg Loss: 0.0375  | Accuracy: 0.9888\n",
      "Epoch: 4460 | Train Avg Loss: 0.0429  | Accuracy: 0.9868\n",
      "Epoch: 4470 | Train Avg Loss: 0.0427  | Accuracy: 0.9797\n",
      "Epoch: 4480 | Train Avg Loss: 0.0431  | Accuracy: 0.9812\n",
      "Epoch: 4490 | Train Avg Loss: 0.0500  | Accuracy: 0.9777\n",
      "Epoch: 4500 | Train Avg Loss: 0.0445  | Accuracy: 0.9868\n",
      "Epoch: 4510 | Train Avg Loss: 0.0418  | Accuracy: 0.9904\n",
      "Epoch: 4520 | Train Avg Loss: 0.0460  | Accuracy: 0.9858\n",
      "Epoch: 4530 | Train Avg Loss: 0.0484  | Accuracy: 0.9827\n",
      "Epoch: 4540 | Train Avg Loss: 0.0486  | Accuracy: 0.9868\n",
      "Epoch: 4550 | Train Avg Loss: 0.0471  | Accuracy: 0.9832\n",
      "Epoch: 4560 | Train Avg Loss: 0.0414  | Accuracy: 0.9848\n",
      "Epoch: 4570 | Train Avg Loss: 0.0568  | Accuracy: 0.9792\n",
      "Epoch: 4580 | Train Avg Loss: 0.0581  | Accuracy: 0.9883\n",
      "Epoch: 4590 | Train Avg Loss: 0.0496  | Accuracy: 0.9827\n",
      "Epoch: 4600 | Train Avg Loss: 0.0554  | Accuracy: 0.9822\n",
      "Epoch: 4610 | Train Avg Loss: 0.0505  | Accuracy: 0.9838\n",
      "Epoch: 4620 | Train Avg Loss: 0.0509  | Accuracy: 0.9838\n",
      "Epoch: 4630 | Train Avg Loss: 0.0465  | Accuracy: 0.9868\n",
      "Epoch: 4640 | Train Avg Loss: 0.0492  | Accuracy: 0.9863\n",
      "Epoch: 4650 | Train Avg Loss: 0.0503  | Accuracy: 0.9772\n",
      "Epoch: 4660 | Train Avg Loss: 0.0537  | Accuracy: 0.9878\n",
      "Epoch: 4670 | Train Avg Loss: 0.0484  | Accuracy: 0.9853\n",
      "Epoch: 4680 | Train Avg Loss: 0.0554  | Accuracy: 0.9792\n",
      "Epoch: 4690 | Train Avg Loss: 0.0469  | Accuracy: 0.9858\n",
      "Epoch: 4700 | Train Avg Loss: 0.0501  | Accuracy: 0.9832\n",
      "Epoch: 4710 | Train Avg Loss: 0.0459  | Accuracy: 0.9898\n",
      "Epoch: 4720 | Train Avg Loss: 0.0467  | Accuracy: 0.9848\n",
      "Epoch: 4730 | Train Avg Loss: 0.0473  | Accuracy: 0.9832\n",
      "Epoch: 4740 | Train Avg Loss: 0.0495  | Accuracy: 0.9802\n",
      "Epoch: 4750 | Train Avg Loss: 0.0438  | Accuracy: 0.9843\n",
      "Epoch: 4760 | Train Avg Loss: 0.0410  | Accuracy: 0.9843\n",
      "Epoch: 4770 | Train Avg Loss: 0.0442  | Accuracy: 0.9843\n",
      "Epoch: 4780 | Train Avg Loss: 0.0440  | Accuracy: 0.9838\n",
      "Epoch: 4790 | Train Avg Loss: 0.0473  | Accuracy: 0.9822\n",
      "Epoch: 4800 | Train Avg Loss: 0.0568  | Accuracy: 0.9878\n",
      "Epoch: 4810 | Train Avg Loss: 0.0560  | Accuracy: 0.9822\n",
      "Epoch: 4820 | Train Avg Loss: 0.0508  | Accuracy: 0.9853\n",
      "Epoch: 4830 | Train Avg Loss: 0.0438  | Accuracy: 0.9853\n",
      "Epoch: 4840 | Train Avg Loss: 0.0344  | Accuracy: 0.9939\n",
      "Epoch: 4850 | Train Avg Loss: 0.0413  | Accuracy: 0.9832\n",
      "Epoch: 4860 | Train Avg Loss: 0.0446  | Accuracy: 0.9812\n",
      "Epoch: 4870 | Train Avg Loss: 0.0485  | Accuracy: 0.9817\n",
      "Epoch: 4880 | Train Avg Loss: 0.0633  | Accuracy: 0.9853\n",
      "Epoch: 4890 | Train Avg Loss: 0.0604  | Accuracy: 0.9812\n",
      "Epoch: 4900 | Train Avg Loss: 0.0529  | Accuracy: 0.9792\n",
      "Epoch: 4910 | Train Avg Loss: 0.0541  | Accuracy: 0.9843\n",
      "Epoch: 4920 | Train Avg Loss: 0.0586  | Accuracy: 0.9782\n",
      "Epoch: 4930 | Train Avg Loss: 0.0634  | Accuracy: 0.9787\n",
      "Epoch: 4940 | Train Avg Loss: 0.0663  | Accuracy: 0.9817\n",
      "Epoch: 4950 | Train Avg Loss: 0.0578  | Accuracy: 0.9878\n",
      "Epoch: 4960 | Train Avg Loss: 0.0457  | Accuracy: 0.9843\n",
      "Epoch: 4970 | Train Avg Loss: 0.0461  | Accuracy: 0.9873\n",
      "Epoch: 4980 | Train Avg Loss: 0.0585  | Accuracy: 0.9883\n",
      "Epoch: 4990 | Train Avg Loss: 0.0672  | Accuracy: 0.9766\n",
      "Epoch: 5000 | Train Avg Loss: 0.0521  | Accuracy: 0.9817\n",
      "Epoch: 5010 | Train Avg Loss: 0.0469  | Accuracy: 0.9848\n",
      "Epoch: 5020 | Train Avg Loss: 0.0543  | Accuracy: 0.9822\n",
      "Epoch: 5030 | Train Avg Loss: 0.0594  | Accuracy: 0.9812\n",
      "Epoch: 5040 | Train Avg Loss: 0.0653  | Accuracy: 0.9736\n",
      "Epoch: 5050 | Train Avg Loss: 0.0674  | Accuracy: 0.9848\n",
      "Epoch: 5060 | Train Avg Loss: 0.0543  | Accuracy: 0.9812\n",
      "Epoch: 5070 | Train Avg Loss: 0.0476  | Accuracy: 0.9827\n",
      "Epoch: 5080 | Train Avg Loss: 0.0551  | Accuracy: 0.9838\n",
      "Epoch: 5090 | Train Avg Loss: 0.0490  | Accuracy: 0.9807\n",
      "Epoch: 5100 | Train Avg Loss: 0.0536  | Accuracy: 0.9832\n",
      "Epoch: 5110 | Train Avg Loss: 0.0472  | Accuracy: 0.9873\n",
      "Epoch: 5120 | Train Avg Loss: 0.0394  | Accuracy: 0.9868\n",
      "Epoch: 5130 | Train Avg Loss: 0.0482  | Accuracy: 0.9858\n",
      "Epoch: 5140 | Train Avg Loss: 0.0508  | Accuracy: 0.9853\n",
      "Epoch: 5150 | Train Avg Loss: 0.0536  | Accuracy: 0.9817\n",
      "Epoch: 5160 | Train Avg Loss: 0.0617  | Accuracy: 0.9777\n",
      "Epoch: 5170 | Train Avg Loss: 0.0486  | Accuracy: 0.9843\n",
      "Epoch: 5180 | Train Avg Loss: 0.0463  | Accuracy: 0.9838\n",
      "Epoch: 5190 | Train Avg Loss: 0.0533  | Accuracy: 0.9817\n",
      "Epoch: 5200 | Train Avg Loss: 0.0558  | Accuracy: 0.9772\n",
      "Epoch: 5210 | Train Avg Loss: 0.0500  | Accuracy: 0.9848\n",
      "Epoch: 5220 | Train Avg Loss: 0.0478  | Accuracy: 0.9878\n",
      "Epoch: 5230 | Train Avg Loss: 0.0440  | Accuracy: 0.9863\n",
      "Epoch: 5240 | Train Avg Loss: 0.0385  | Accuracy: 0.9858\n",
      "Epoch: 5250 | Train Avg Loss: 0.0457  | Accuracy: 0.9904\n",
      "Epoch: 5260 | Train Avg Loss: 0.0451  | Accuracy: 0.9868\n",
      "Epoch: 5270 | Train Avg Loss: 0.0481  | Accuracy: 0.9701\n",
      "Epoch: 5280 | Train Avg Loss: 0.0505  | Accuracy: 0.9832\n",
      "Epoch: 5290 | Train Avg Loss: 0.0460  | Accuracy: 0.9863\n",
      "Epoch: 5300 | Train Avg Loss: 0.0429  | Accuracy: 0.9817\n",
      "Epoch: 5310 | Train Avg Loss: 0.0555  | Accuracy: 0.9838\n",
      "Epoch: 5320 | Train Avg Loss: 0.0554  | Accuracy: 0.9822\n",
      "Epoch: 5330 | Train Avg Loss: 0.0570  | Accuracy: 0.9827\n",
      "Epoch: 5340 | Train Avg Loss: 0.0489  | Accuracy: 0.9832\n",
      "Epoch: 5350 | Train Avg Loss: 0.0473  | Accuracy: 0.9797\n",
      "Epoch: 5360 | Train Avg Loss: 0.0377  | Accuracy: 0.9898\n",
      "Epoch: 5370 | Train Avg Loss: 0.0402  | Accuracy: 0.9873\n",
      "Epoch: 5380 | Train Avg Loss: 0.0508  | Accuracy: 0.9893\n",
      "Epoch: 5390 | Train Avg Loss: 0.0482  | Accuracy: 0.9873\n",
      "Epoch: 5400 | Train Avg Loss: 0.0435  | Accuracy: 0.9909\n",
      "Epoch: 5410 | Train Avg Loss: 0.0386  | Accuracy: 0.9822\n",
      "Epoch: 5420 | Train Avg Loss: 0.0427  | Accuracy: 0.9838\n",
      "Epoch: 5430 | Train Avg Loss: 0.0443  | Accuracy: 0.9904\n",
      "Epoch: 5440 | Train Avg Loss: 0.0358  | Accuracy: 0.9868\n",
      "Epoch: 5450 | Train Avg Loss: 0.0371  | Accuracy: 0.9868\n",
      "Epoch: 5460 | Train Avg Loss: 0.0491  | Accuracy: 0.9792\n",
      "Epoch: 5470 | Train Avg Loss: 0.0420  | Accuracy: 0.9893\n",
      "Epoch: 5480 | Train Avg Loss: 0.0432  | Accuracy: 0.9858\n",
      "Epoch: 5490 | Train Avg Loss: 0.0455  | Accuracy: 0.9832\n",
      "Epoch: 5500 | Train Avg Loss: 0.0455  | Accuracy: 0.9898\n",
      "Epoch: 5510 | Train Avg Loss: 0.0451  | Accuracy: 0.9868\n",
      "Epoch: 5520 | Train Avg Loss: 0.0458  | Accuracy: 0.9848\n",
      "Epoch: 5530 | Train Avg Loss: 0.0421  | Accuracy: 0.9858\n",
      "Epoch: 5540 | Train Avg Loss: 0.0419  | Accuracy: 0.9883\n",
      "Epoch: 5550 | Train Avg Loss: 0.0436  | Accuracy: 0.9792\n",
      "Epoch: 5560 | Train Avg Loss: 0.0475  | Accuracy: 0.9807\n",
      "Epoch: 5570 | Train Avg Loss: 0.0396  | Accuracy: 0.9904\n",
      "Epoch: 5580 | Train Avg Loss: 0.0350  | Accuracy: 0.9934\n",
      "Epoch: 5590 | Train Avg Loss: 0.0348  | Accuracy: 0.9863\n",
      "Epoch: 5600 | Train Avg Loss: 0.0400  | Accuracy: 0.9888\n",
      "Epoch: 5610 | Train Avg Loss: 0.0401  | Accuracy: 0.9909\n",
      "Epoch: 5620 | Train Avg Loss: 0.0315  | Accuracy: 0.9934\n",
      "Epoch: 5630 | Train Avg Loss: 0.0405  | Accuracy: 0.9843\n",
      "Epoch: 5640 | Train Avg Loss: 0.0432  | Accuracy: 0.9843\n",
      "Epoch: 5650 | Train Avg Loss: 0.0443  | Accuracy: 0.9838\n",
      "Epoch: 5660 | Train Avg Loss: 0.0416  | Accuracy: 0.9858\n",
      "Epoch: 5670 | Train Avg Loss: 0.0449  | Accuracy: 0.9904\n",
      "Epoch: 5680 | Train Avg Loss: 0.0416  | Accuracy: 0.9858\n",
      "Epoch: 5690 | Train Avg Loss: 0.0362  | Accuracy: 0.9883\n",
      "Epoch: 5700 | Train Avg Loss: 0.0455  | Accuracy: 0.9878\n",
      "Epoch: 5710 | Train Avg Loss: 0.0375  | Accuracy: 0.9934\n",
      "Epoch: 5720 | Train Avg Loss: 0.0383  | Accuracy: 0.9863\n",
      "Epoch: 5730 | Train Avg Loss: 0.0353  | Accuracy: 0.9883\n",
      "Epoch: 5740 | Train Avg Loss: 0.0399  | Accuracy: 0.9863\n",
      "Epoch: 5750 | Train Avg Loss: 0.0366  | Accuracy: 0.9893\n",
      "Epoch: 5760 | Train Avg Loss: 0.0450  | Accuracy: 0.9863\n",
      "Epoch: 5770 | Train Avg Loss: 0.0428  | Accuracy: 0.9848\n",
      "Epoch: 5780 | Train Avg Loss: 0.0446  | Accuracy: 0.9893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5790 | Train Avg Loss: 0.0431  | Accuracy: 0.9807\n",
      "Epoch: 5800 | Train Avg Loss: 0.0421  | Accuracy: 0.9858\n",
      "Epoch: 5810 | Train Avg Loss: 0.0407  | Accuracy: 0.9822\n",
      "Epoch: 5820 | Train Avg Loss: 0.0429  | Accuracy: 0.9822\n",
      "Epoch: 5830 | Train Avg Loss: 0.0531  | Accuracy: 0.9853\n",
      "Epoch: 5840 | Train Avg Loss: 0.0442  | Accuracy: 0.9858\n",
      "Epoch: 5850 | Train Avg Loss: 0.0462  | Accuracy: 0.9812\n",
      "Epoch: 5860 | Train Avg Loss: 0.0443  | Accuracy: 0.9822\n",
      "Epoch: 5870 | Train Avg Loss: 0.0608  | Accuracy: 0.9868\n",
      "Epoch: 5880 | Train Avg Loss: 0.0508  | Accuracy: 0.9843\n",
      "Epoch: 5890 | Train Avg Loss: 0.0502  | Accuracy: 0.9782\n",
      "Epoch: 5900 | Train Avg Loss: 0.0526  | Accuracy: 0.9777\n",
      "Epoch: 5910 | Train Avg Loss: 0.0518  | Accuracy: 0.9843\n",
      "Epoch: 5920 | Train Avg Loss: 0.0494  | Accuracy: 0.9873\n",
      "Epoch: 5930 | Train Avg Loss: 0.0489  | Accuracy: 0.9827\n",
      "Epoch: 5940 | Train Avg Loss: 0.0479  | Accuracy: 0.9898\n",
      "Epoch: 5950 | Train Avg Loss: 0.0448  | Accuracy: 0.9832\n",
      "Epoch: 5960 | Train Avg Loss: 0.0407  | Accuracy: 0.9843\n",
      "Epoch: 5970 | Train Avg Loss: 0.0491  | Accuracy: 0.9817\n",
      "Epoch: 5980 | Train Avg Loss: 0.0451  | Accuracy: 0.9883\n",
      "Epoch: 5990 | Train Avg Loss: 0.0419  | Accuracy: 0.9873\n",
      "Epoch: 6000 | Train Avg Loss: 0.0362  | Accuracy: 0.9878\n",
      "Epoch: 6010 | Train Avg Loss: 0.0427  | Accuracy: 0.9878\n",
      "Epoch: 6020 | Train Avg Loss: 0.0417  | Accuracy: 0.9863\n",
      "Epoch: 6030 | Train Avg Loss: 0.0434  | Accuracy: 0.9817\n",
      "Epoch: 6040 | Train Avg Loss: 0.0385  | Accuracy: 0.9858\n",
      "Epoch: 6050 | Train Avg Loss: 0.0369  | Accuracy: 0.9843\n",
      "Epoch: 6060 | Train Avg Loss: 0.0367  | Accuracy: 0.9893\n",
      "Epoch: 6070 | Train Avg Loss: 0.0347  | Accuracy: 0.9893\n",
      "Epoch: 6080 | Train Avg Loss: 0.0402  | Accuracy: 0.9807\n",
      "Epoch: 6090 | Train Avg Loss: 0.0406  | Accuracy: 0.9853\n",
      "Epoch: 6100 | Train Avg Loss: 0.0499  | Accuracy: 0.9868\n",
      "Epoch: 6110 | Train Avg Loss: 0.0530  | Accuracy: 0.9792\n",
      "Epoch: 6120 | Train Avg Loss: 0.0431  | Accuracy: 0.9858\n",
      "Epoch: 6130 | Train Avg Loss: 0.0411  | Accuracy: 0.9883\n",
      "Epoch: 6140 | Train Avg Loss: 0.0470  | Accuracy: 0.9873\n",
      "Epoch: 6150 | Train Avg Loss: 0.0458  | Accuracy: 0.9807\n",
      "Epoch: 6160 | Train Avg Loss: 0.0517  | Accuracy: 0.9756\n",
      "Epoch: 6170 | Train Avg Loss: 0.0514  | Accuracy: 0.9792\n",
      "Epoch: 6180 | Train Avg Loss: 0.0420  | Accuracy: 0.9883\n",
      "Epoch: 6190 | Train Avg Loss: 0.0417  | Accuracy: 0.9924\n",
      "Epoch: 6200 | Train Avg Loss: 0.0410  | Accuracy: 0.9873\n",
      "Epoch: 6210 | Train Avg Loss: 0.0361  | Accuracy: 0.9843\n",
      "Epoch: 6220 | Train Avg Loss: 0.0370  | Accuracy: 0.9924\n",
      "Epoch: 6230 | Train Avg Loss: 0.0393  | Accuracy: 0.9919\n",
      "Epoch: 6240 | Train Avg Loss: 0.0346  | Accuracy: 0.9893\n",
      "Epoch: 6250 | Train Avg Loss: 0.0387  | Accuracy: 0.9898\n",
      "Epoch: 6260 | Train Avg Loss: 0.0419  | Accuracy: 0.9909\n",
      "Epoch: 6270 | Train Avg Loss: 0.0487  | Accuracy: 0.9863\n",
      "Epoch: 6280 | Train Avg Loss: 0.0460  | Accuracy: 0.9817\n",
      "Epoch: 6290 | Train Avg Loss: 0.0426  | Accuracy: 0.9858\n",
      "Epoch: 6300 | Train Avg Loss: 0.0433  | Accuracy: 0.9838\n",
      "Epoch: 6310 | Train Avg Loss: 0.0423  | Accuracy: 0.9868\n",
      "Epoch: 6320 | Train Avg Loss: 0.0334  | Accuracy: 0.9939\n",
      "Epoch: 6330 | Train Avg Loss: 0.0318  | Accuracy: 0.9873\n",
      "Epoch: 6340 | Train Avg Loss: 0.0356  | Accuracy: 0.9898\n",
      "Epoch: 6350 | Train Avg Loss: 0.0424  | Accuracy: 0.9853\n",
      "Epoch: 6360 | Train Avg Loss: 0.0384  | Accuracy: 0.9878\n",
      "Epoch: 6370 | Train Avg Loss: 0.0374  | Accuracy: 0.9838\n",
      "Epoch: 6380 | Train Avg Loss: 0.0394  | Accuracy: 0.9863\n",
      "Epoch: 6390 | Train Avg Loss: 0.0407  | Accuracy: 0.9858\n",
      "Epoch: 6400 | Train Avg Loss: 0.0411  | Accuracy: 0.9853\n",
      "Epoch: 6410 | Train Avg Loss: 0.0400  | Accuracy: 0.9888\n",
      "Epoch: 6420 | Train Avg Loss: 0.0380  | Accuracy: 0.9898\n",
      "Epoch: 6430 | Train Avg Loss: 0.0393  | Accuracy: 0.9873\n",
      "Epoch: 6440 | Train Avg Loss: 0.0380  | Accuracy: 0.9873\n",
      "Epoch: 6450 | Train Avg Loss: 0.0332  | Accuracy: 0.9904\n",
      "Epoch: 6460 | Train Avg Loss: 0.0379  | Accuracy: 0.9929\n",
      "Epoch: 6470 | Train Avg Loss: 0.0424  | Accuracy: 0.9919\n",
      "Epoch: 6480 | Train Avg Loss: 0.0471  | Accuracy: 0.9868\n",
      "Epoch: 6490 | Train Avg Loss: 0.0456  | Accuracy: 0.9904\n",
      "Epoch: 6500 | Train Avg Loss: 0.0521  | Accuracy: 0.9858\n",
      "Epoch: 6510 | Train Avg Loss: 0.0361  | Accuracy: 0.9898\n",
      "Epoch: 6520 | Train Avg Loss: 0.0316  | Accuracy: 0.9853\n",
      "Epoch: 6530 | Train Avg Loss: 0.0429  | Accuracy: 0.9822\n",
      "Epoch: 6540 | Train Avg Loss: 0.0415  | Accuracy: 0.9812\n",
      "Epoch: 6550 | Train Avg Loss: 0.0416  | Accuracy: 0.9838\n",
      "Epoch: 6560 | Train Avg Loss: 0.0389  | Accuracy: 0.9893\n",
      "Epoch: 6570 | Train Avg Loss: 0.0373  | Accuracy: 0.9893\n",
      "Epoch: 6580 | Train Avg Loss: 0.0405  | Accuracy: 0.9838\n",
      "Epoch: 6590 | Train Avg Loss: 0.0465  | Accuracy: 0.9858\n",
      "Epoch: 6600 | Train Avg Loss: 0.0445  | Accuracy: 0.9838\n",
      "Epoch: 6610 | Train Avg Loss: 0.0395  | Accuracy: 0.9898\n",
      "Epoch: 6620 | Train Avg Loss: 0.0350  | Accuracy: 0.9914\n",
      "Epoch: 6630 | Train Avg Loss: 0.0373  | Accuracy: 0.9868\n",
      "Epoch: 6640 | Train Avg Loss: 0.0366  | Accuracy: 0.9858\n",
      "Epoch: 6650 | Train Avg Loss: 0.0347  | Accuracy: 0.9909\n",
      "Epoch: 6660 | Train Avg Loss: 0.0445  | Accuracy: 0.9848\n",
      "Epoch: 6670 | Train Avg Loss: 0.0406  | Accuracy: 0.9868\n",
      "Epoch: 6680 | Train Avg Loss: 0.0401  | Accuracy: 0.9843\n",
      "Epoch: 6690 | Train Avg Loss: 0.0354  | Accuracy: 0.9858\n",
      "Epoch: 6700 | Train Avg Loss: 0.0392  | Accuracy: 0.9873\n",
      "Epoch: 6710 | Train Avg Loss: 0.0471  | Accuracy: 0.9853\n",
      "Epoch: 6720 | Train Avg Loss: 0.0419  | Accuracy: 0.9868\n",
      "Epoch: 6730 | Train Avg Loss: 0.0316  | Accuracy: 0.9893\n",
      "Epoch: 6740 | Train Avg Loss: 0.0348  | Accuracy: 0.9853\n",
      "Epoch: 6750 | Train Avg Loss: 0.0328  | Accuracy: 0.9919\n",
      "Epoch: 6760 | Train Avg Loss: 0.0326  | Accuracy: 0.9914\n",
      "Epoch: 6770 | Train Avg Loss: 0.0327  | Accuracy: 0.9878\n",
      "Epoch: 6780 | Train Avg Loss: 0.0416  | Accuracy: 0.9888\n",
      "Epoch: 6790 | Train Avg Loss: 0.0378  | Accuracy: 0.9868\n",
      "Epoch: 6800 | Train Avg Loss: 0.0380  | Accuracy: 0.9873\n",
      "Epoch: 6810 | Train Avg Loss: 0.0356  | Accuracy: 0.9858\n",
      "Epoch: 6820 | Train Avg Loss: 0.0314  | Accuracy: 0.9888\n",
      "Epoch: 6830 | Train Avg Loss: 0.0352  | Accuracy: 0.9883\n",
      "Epoch: 6840 | Train Avg Loss: 0.0346  | Accuracy: 0.9893\n",
      "Epoch: 6850 | Train Avg Loss: 0.0376  | Accuracy: 0.9827\n",
      "Epoch: 6860 | Train Avg Loss: 0.0398  | Accuracy: 0.9893\n",
      "Epoch: 6870 | Train Avg Loss: 0.0523  | Accuracy: 0.9838\n",
      "Epoch: 6880 | Train Avg Loss: 0.0438  | Accuracy: 0.9904\n",
      "Epoch: 6890 | Train Avg Loss: 0.0307  | Accuracy: 0.9909\n",
      "Epoch: 6900 | Train Avg Loss: 0.0297  | Accuracy: 0.9883\n",
      "Epoch: 6910 | Train Avg Loss: 0.0441  | Accuracy: 0.9853\n",
      "Epoch: 6920 | Train Avg Loss: 0.0425  | Accuracy: 0.9873\n",
      "Epoch: 6930 | Train Avg Loss: 0.0402  | Accuracy: 0.9868\n",
      "Epoch: 6940 | Train Avg Loss: 0.0447  | Accuracy: 0.9893\n",
      "Epoch: 6950 | Train Avg Loss: 0.0403  | Accuracy: 0.9868\n",
      "Epoch: 6960 | Train Avg Loss: 0.0380  | Accuracy: 0.9939\n",
      "Epoch: 6970 | Train Avg Loss: 0.0384  | Accuracy: 0.9914\n",
      "Epoch: 6980 | Train Avg Loss: 0.0339  | Accuracy: 0.9853\n",
      "Epoch: 6990 | Train Avg Loss: 0.0305  | Accuracy: 0.9888\n",
      "Epoch: 7000 | Train Avg Loss: 0.0377  | Accuracy: 0.9873\n",
      "Epoch: 7010 | Train Avg Loss: 0.0372  | Accuracy: 0.9888\n",
      "Epoch: 7020 | Train Avg Loss: 0.0384  | Accuracy: 0.9909\n",
      "Epoch: 7030 | Train Avg Loss: 0.0378  | Accuracy: 0.9888\n",
      "Epoch: 7040 | Train Avg Loss: 0.0473  | Accuracy: 0.9863\n",
      "Epoch: 7050 | Train Avg Loss: 0.0425  | Accuracy: 0.9883\n",
      "Epoch: 7060 | Train Avg Loss: 0.0351  | Accuracy: 0.9888\n",
      "Epoch: 7070 | Train Avg Loss: 0.0391  | Accuracy: 0.9883\n",
      "Epoch: 7080 | Train Avg Loss: 0.0417  | Accuracy: 0.9878\n",
      "Epoch: 7090 | Train Avg Loss: 0.0439  | Accuracy: 0.9878\n",
      "Epoch: 7100 | Train Avg Loss: 0.0475  | Accuracy: 0.9761\n",
      "Epoch: 7110 | Train Avg Loss: 0.0513  | Accuracy: 0.9868\n",
      "Epoch: 7120 | Train Avg Loss: 0.0525  | Accuracy: 0.9746\n",
      "Epoch: 7130 | Train Avg Loss: 0.0575  | Accuracy: 0.9883\n",
      "Epoch: 7140 | Train Avg Loss: 0.0568  | Accuracy: 0.9822\n",
      "Epoch: 7150 | Train Avg Loss: 0.0569  | Accuracy: 0.9832\n",
      "Epoch: 7160 | Train Avg Loss: 0.0594  | Accuracy: 0.9766\n",
      "Epoch: 7170 | Train Avg Loss: 0.0568  | Accuracy: 0.9797\n",
      "Epoch: 7180 | Train Avg Loss: 0.0458  | Accuracy: 0.9904\n",
      "Epoch: 7190 | Train Avg Loss: 0.0437  | Accuracy: 0.9838\n",
      "Epoch: 7200 | Train Avg Loss: 0.0389  | Accuracy: 0.9919\n",
      "Epoch: 7210 | Train Avg Loss: 0.0424  | Accuracy: 0.9868\n",
      "Epoch: 7220 | Train Avg Loss: 0.0396  | Accuracy: 0.9909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7230 | Train Avg Loss: 0.0419  | Accuracy: 0.9848\n",
      "Epoch: 7240 | Train Avg Loss: 0.0401  | Accuracy: 0.9863\n",
      "Epoch: 7250 | Train Avg Loss: 0.0367  | Accuracy: 0.9909\n",
      "Epoch: 7260 | Train Avg Loss: 0.0366  | Accuracy: 0.9914\n",
      "Epoch: 7270 | Train Avg Loss: 0.0316  | Accuracy: 0.9893\n",
      "Epoch: 7280 | Train Avg Loss: 0.0325  | Accuracy: 0.9929\n",
      "Epoch: 7290 | Train Avg Loss: 0.0368  | Accuracy: 0.9893\n",
      "Epoch: 7300 | Train Avg Loss: 0.0360  | Accuracy: 0.9914\n",
      "Epoch: 7310 | Train Avg Loss: 0.0297  | Accuracy: 0.9883\n",
      "Epoch: 7320 | Train Avg Loss: 0.0389  | Accuracy: 0.9909\n",
      "Epoch: 7330 | Train Avg Loss: 0.0377  | Accuracy: 0.9878\n",
      "Epoch: 7340 | Train Avg Loss: 0.0325  | Accuracy: 0.9914\n",
      "Epoch: 7350 | Train Avg Loss: 0.0347  | Accuracy: 0.9909\n",
      "Epoch: 7360 | Train Avg Loss: 0.0403  | Accuracy: 0.9873\n",
      "Epoch: 7370 | Train Avg Loss: 0.0310  | Accuracy: 0.9878\n",
      "Epoch: 7380 | Train Avg Loss: 0.0417  | Accuracy: 0.9858\n",
      "Epoch: 7390 | Train Avg Loss: 0.0282  | Accuracy: 0.9939\n",
      "Epoch: 7400 | Train Avg Loss: 0.0275  | Accuracy: 0.9904\n",
      "Epoch: 7410 | Train Avg Loss: 0.0363  | Accuracy: 0.9863\n",
      "Epoch: 7420 | Train Avg Loss: 0.0441  | Accuracy: 0.9858\n",
      "Epoch: 7430 | Train Avg Loss: 0.0355  | Accuracy: 0.9934\n",
      "Epoch: 7440 | Train Avg Loss: 0.0349  | Accuracy: 0.9858\n",
      "Epoch: 7450 | Train Avg Loss: 0.0430  | Accuracy: 0.9883\n",
      "Epoch: 7460 | Train Avg Loss: 0.0479  | Accuracy: 0.9797\n",
      "Epoch: 7470 | Train Avg Loss: 0.0423  | Accuracy: 0.9904\n",
      "Epoch: 7480 | Train Avg Loss: 0.0361  | Accuracy: 0.9878\n",
      "Epoch: 7490 | Train Avg Loss: 0.0302  | Accuracy: 0.9904\n",
      "Epoch: 7500 | Train Avg Loss: 0.0315  | Accuracy: 0.9863\n",
      "Epoch: 7510 | Train Avg Loss: 0.0368  | Accuracy: 0.9853\n",
      "Epoch: 7520 | Train Avg Loss: 0.0364  | Accuracy: 0.9863\n",
      "Epoch: 7530 | Train Avg Loss: 0.0321  | Accuracy: 0.9893\n",
      "Epoch: 7540 | Train Avg Loss: 0.0382  | Accuracy: 0.9893\n",
      "Epoch: 7550 | Train Avg Loss: 0.0336  | Accuracy: 0.9863\n",
      "Epoch: 7560 | Train Avg Loss: 0.0374  | Accuracy: 0.9909\n",
      "Epoch: 7570 | Train Avg Loss: 0.0406  | Accuracy: 0.9909\n",
      "Epoch: 7580 | Train Avg Loss: 0.0368  | Accuracy: 0.9827\n",
      "Epoch: 7590 | Train Avg Loss: 0.0553  | Accuracy: 0.9888\n",
      "Epoch: 7600 | Train Avg Loss: 0.0588  | Accuracy: 0.9873\n",
      "Epoch: 7610 | Train Avg Loss: 0.0427  | Accuracy: 0.9863\n",
      "Epoch: 7620 | Train Avg Loss: 0.0396  | Accuracy: 0.9898\n",
      "Epoch: 7630 | Train Avg Loss: 0.0395  | Accuracy: 0.9832\n",
      "Epoch: 7640 | Train Avg Loss: 0.0440  | Accuracy: 0.9843\n",
      "Epoch: 7650 | Train Avg Loss: 0.0442  | Accuracy: 0.9863\n",
      "Epoch: 7660 | Train Avg Loss: 0.0397  | Accuracy: 0.9863\n",
      "Epoch: 7670 | Train Avg Loss: 0.0469  | Accuracy: 0.9797\n",
      "Epoch: 7680 | Train Avg Loss: 0.0443  | Accuracy: 0.9888\n",
      "Epoch: 7690 | Train Avg Loss: 0.0431  | Accuracy: 0.9878\n",
      "Epoch: 7700 | Train Avg Loss: 0.0416  | Accuracy: 0.9868\n",
      "Epoch: 7710 | Train Avg Loss: 0.0353  | Accuracy: 0.9838\n",
      "Epoch: 7720 | Train Avg Loss: 0.0392  | Accuracy: 0.9848\n",
      "Epoch: 7730 | Train Avg Loss: 0.0508  | Accuracy: 0.9873\n",
      "Epoch: 7740 | Train Avg Loss: 0.0454  | Accuracy: 0.9843\n",
      "Epoch: 7750 | Train Avg Loss: 0.0445  | Accuracy: 0.9873\n",
      "Epoch: 7760 | Train Avg Loss: 0.0446  | Accuracy: 0.9898\n",
      "Epoch: 7770 | Train Avg Loss: 0.0366  | Accuracy: 0.9853\n",
      "Epoch: 7780 | Train Avg Loss: 0.0344  | Accuracy: 0.9919\n",
      "Epoch: 7790 | Train Avg Loss: 0.0355  | Accuracy: 0.9878\n",
      "Epoch: 7800 | Train Avg Loss: 0.0352  | Accuracy: 0.9888\n",
      "Epoch: 7810 | Train Avg Loss: 0.0332  | Accuracy: 0.9904\n",
      "Epoch: 7820 | Train Avg Loss: 0.0288  | Accuracy: 0.9909\n",
      "Epoch: 7830 | Train Avg Loss: 0.0310  | Accuracy: 0.9929\n",
      "Epoch: 7840 | Train Avg Loss: 0.0338  | Accuracy: 0.9934\n",
      "Epoch: 7850 | Train Avg Loss: 0.0342  | Accuracy: 0.9893\n",
      "Epoch: 7860 | Train Avg Loss: 0.0381  | Accuracy: 0.9898\n",
      "Epoch: 7870 | Train Avg Loss: 0.0373  | Accuracy: 0.9868\n",
      "Epoch: 7880 | Train Avg Loss: 0.0549  | Accuracy: 0.9716\n",
      "Epoch: 7890 | Train Avg Loss: 0.0733  | Accuracy: 0.9782\n",
      "Epoch: 7900 | Train Avg Loss: 0.0546  | Accuracy: 0.9741\n",
      "Epoch: 7910 | Train Avg Loss: 0.0481  | Accuracy: 0.9843\n",
      "Epoch: 7920 | Train Avg Loss: 0.0464  | Accuracy: 0.9848\n",
      "Epoch: 7930 | Train Avg Loss: 0.0439  | Accuracy: 0.9863\n",
      "Epoch: 7940 | Train Avg Loss: 0.0366  | Accuracy: 0.9853\n",
      "Epoch: 7950 | Train Avg Loss: 0.0453  | Accuracy: 0.9868\n",
      "Epoch: 7960 | Train Avg Loss: 0.0369  | Accuracy: 0.9868\n",
      "Epoch: 7970 | Train Avg Loss: 0.0408  | Accuracy: 0.9873\n",
      "Epoch: 7980 | Train Avg Loss: 0.0374  | Accuracy: 0.9868\n",
      "Epoch: 7990 | Train Avg Loss: 0.0340  | Accuracy: 0.9868\n",
      "Epoch: 8000 | Train Avg Loss: 0.0291  | Accuracy: 0.9904\n",
      "Epoch: 8010 | Train Avg Loss: 0.0378  | Accuracy: 0.9898\n",
      "Epoch: 8020 | Train Avg Loss: 0.0333  | Accuracy: 0.9863\n",
      "Epoch: 8030 | Train Avg Loss: 0.0334  | Accuracy: 0.9904\n",
      "Epoch: 8040 | Train Avg Loss: 0.0344  | Accuracy: 0.9909\n",
      "Epoch: 8050 | Train Avg Loss: 0.0415  | Accuracy: 0.9904\n",
      "Epoch: 8060 | Train Avg Loss: 0.0341  | Accuracy: 0.9929\n",
      "Epoch: 8070 | Train Avg Loss: 0.0343  | Accuracy: 0.9873\n",
      "Epoch: 8080 | Train Avg Loss: 0.0313  | Accuracy: 0.9848\n",
      "Epoch: 8090 | Train Avg Loss: 0.0342  | Accuracy: 0.9858\n",
      "Epoch: 8100 | Train Avg Loss: 0.0341  | Accuracy: 0.9898\n",
      "Epoch: 8110 | Train Avg Loss: 0.0344  | Accuracy: 0.9868\n",
      "Epoch: 8120 | Train Avg Loss: 0.0347  | Accuracy: 0.9858\n",
      "Epoch: 8130 | Train Avg Loss: 0.0341  | Accuracy: 0.9888\n",
      "Epoch: 8140 | Train Avg Loss: 0.0375  | Accuracy: 0.9888\n",
      "Epoch: 8150 | Train Avg Loss: 0.0468  | Accuracy: 0.9843\n",
      "Epoch: 8160 | Train Avg Loss: 0.0380  | Accuracy: 0.9934\n",
      "Epoch: 8170 | Train Avg Loss: 0.0329  | Accuracy: 0.9878\n",
      "Epoch: 8180 | Train Avg Loss: 0.0327  | Accuracy: 0.9883\n",
      "Epoch: 8190 | Train Avg Loss: 0.0359  | Accuracy: 0.9893\n",
      "Epoch: 8200 | Train Avg Loss: 0.0326  | Accuracy: 0.9919\n",
      "Epoch: 8210 | Train Avg Loss: 0.0329  | Accuracy: 0.9888\n",
      "Epoch: 8220 | Train Avg Loss: 0.0328  | Accuracy: 0.9893\n",
      "Epoch: 8230 | Train Avg Loss: 0.0325  | Accuracy: 0.9868\n",
      "Epoch: 8240 | Train Avg Loss: 0.0376  | Accuracy: 0.9883\n",
      "Epoch: 8250 | Train Avg Loss: 0.0366  | Accuracy: 0.9878\n",
      "Epoch: 8260 | Train Avg Loss: 0.0440  | Accuracy: 0.9822\n",
      "Epoch: 8270 | Train Avg Loss: 0.0598  | Accuracy: 0.9812\n",
      "Epoch: 8280 | Train Avg Loss: 0.0465  | Accuracy: 0.9853\n",
      "Epoch: 8290 | Train Avg Loss: 0.0422  | Accuracy: 0.9893\n",
      "Epoch: 8300 | Train Avg Loss: 0.0419  | Accuracy: 0.9914\n",
      "Epoch: 8310 | Train Avg Loss: 0.0420  | Accuracy: 0.9858\n",
      "Epoch: 8320 | Train Avg Loss: 0.0464  | Accuracy: 0.9822\n",
      "Epoch: 8330 | Train Avg Loss: 0.0427  | Accuracy: 0.9878\n",
      "Epoch: 8340 | Train Avg Loss: 0.0442  | Accuracy: 0.9873\n",
      "Epoch: 8350 | Train Avg Loss: 0.0479  | Accuracy: 0.9883\n",
      "Epoch: 8360 | Train Avg Loss: 0.0465  | Accuracy: 0.9838\n",
      "Epoch: 8370 | Train Avg Loss: 0.0457  | Accuracy: 0.9858\n",
      "Epoch: 8380 | Train Avg Loss: 0.0453  | Accuracy: 0.9898\n",
      "Epoch: 8390 | Train Avg Loss: 0.0388  | Accuracy: 0.9838\n",
      "Epoch: 8400 | Train Avg Loss: 0.0373  | Accuracy: 0.9832\n",
      "Epoch: 8410 | Train Avg Loss: 0.0351  | Accuracy: 0.9919\n",
      "Epoch: 8420 | Train Avg Loss: 0.0445  | Accuracy: 0.9853\n",
      "Epoch: 8430 | Train Avg Loss: 0.0592  | Accuracy: 0.9792\n",
      "Epoch: 8440 | Train Avg Loss: 0.0469  | Accuracy: 0.9888\n",
      "Epoch: 8450 | Train Avg Loss: 0.0400  | Accuracy: 0.9863\n",
      "Epoch: 8460 | Train Avg Loss: 0.0377  | Accuracy: 0.9919\n",
      "Epoch: 8470 | Train Avg Loss: 0.0404  | Accuracy: 0.9863\n",
      "Epoch: 8480 | Train Avg Loss: 0.0403  | Accuracy: 0.9863\n",
      "Epoch: 8490 | Train Avg Loss: 0.0544  | Accuracy: 0.9807\n",
      "Epoch: 8500 | Train Avg Loss: 0.0568  | Accuracy: 0.9888\n",
      "Epoch: 8510 | Train Avg Loss: 0.0402  | Accuracy: 0.9868\n",
      "Epoch: 8520 | Train Avg Loss: 0.0423  | Accuracy: 0.9843\n",
      "Epoch: 8530 | Train Avg Loss: 0.0473  | Accuracy: 0.9827\n",
      "Epoch: 8540 | Train Avg Loss: 0.0417  | Accuracy: 0.9878\n",
      "Epoch: 8550 | Train Avg Loss: 0.0365  | Accuracy: 0.9848\n",
      "Epoch: 8560 | Train Avg Loss: 0.0365  | Accuracy: 0.9909\n",
      "Epoch: 8570 | Train Avg Loss: 0.0341  | Accuracy: 0.9888\n",
      "Epoch: 8580 | Train Avg Loss: 0.0383  | Accuracy: 0.9914\n",
      "Epoch: 8590 | Train Avg Loss: 0.0412  | Accuracy: 0.9883\n",
      "Epoch: 8600 | Train Avg Loss: 0.0510  | Accuracy: 0.9868\n",
      "Epoch: 8610 | Train Avg Loss: 0.0431  | Accuracy: 0.9843\n",
      "Epoch: 8620 | Train Avg Loss: 0.0368  | Accuracy: 0.9858\n",
      "Epoch: 8630 | Train Avg Loss: 0.0416  | Accuracy: 0.9822\n",
      "Epoch: 8640 | Train Avg Loss: 0.0461  | Accuracy: 0.9817\n",
      "Epoch: 8650 | Train Avg Loss: 0.0520  | Accuracy: 0.9797\n",
      "Epoch: 8660 | Train Avg Loss: 0.0535  | Accuracy: 0.9893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8670 | Train Avg Loss: 0.0406  | Accuracy: 0.9909\n",
      "Epoch: 8680 | Train Avg Loss: 0.0408  | Accuracy: 0.9878\n",
      "Epoch: 8690 | Train Avg Loss: 0.0371  | Accuracy: 0.9883\n",
      "Epoch: 8700 | Train Avg Loss: 0.0333  | Accuracy: 0.9898\n",
      "Epoch: 8710 | Train Avg Loss: 0.0339  | Accuracy: 0.9914\n",
      "Epoch: 8720 | Train Avg Loss: 0.0339  | Accuracy: 0.9853\n",
      "Epoch: 8730 | Train Avg Loss: 0.0368  | Accuracy: 0.9919\n",
      "Epoch: 8740 | Train Avg Loss: 0.0363  | Accuracy: 0.9883\n",
      "Epoch: 8750 | Train Avg Loss: 0.0382  | Accuracy: 0.9858\n",
      "Epoch: 8760 | Train Avg Loss: 0.0324  | Accuracy: 0.9868\n",
      "Epoch: 8770 | Train Avg Loss: 0.0399  | Accuracy: 0.9873\n",
      "Epoch: 8780 | Train Avg Loss: 0.0386  | Accuracy: 0.9878\n",
      "Epoch: 8790 | Train Avg Loss: 0.0298  | Accuracy: 0.9914\n",
      "Epoch: 8800 | Train Avg Loss: 0.0335  | Accuracy: 0.9878\n",
      "Epoch: 8810 | Train Avg Loss: 0.0328  | Accuracy: 0.9898\n",
      "Epoch: 8820 | Train Avg Loss: 0.0367  | Accuracy: 0.9934\n",
      "Epoch: 8830 | Train Avg Loss: 0.0348  | Accuracy: 0.9898\n",
      "Epoch: 8840 | Train Avg Loss: 0.0412  | Accuracy: 0.9832\n",
      "Epoch: 8850 | Train Avg Loss: 0.0421  | Accuracy: 0.9909\n",
      "Epoch: 8860 | Train Avg Loss: 0.0406  | Accuracy: 0.9883\n",
      "Epoch: 8870 | Train Avg Loss: 0.0358  | Accuracy: 0.9868\n",
      "Epoch: 8880 | Train Avg Loss: 0.0362  | Accuracy: 0.9888\n",
      "Epoch: 8890 | Train Avg Loss: 0.0347  | Accuracy: 0.9898\n",
      "Epoch: 8900 | Train Avg Loss: 0.0386  | Accuracy: 0.9893\n",
      "Epoch: 8910 | Train Avg Loss: 0.0421  | Accuracy: 0.9838\n",
      "Epoch: 8920 | Train Avg Loss: 0.0337  | Accuracy: 0.9843\n",
      "Epoch: 8930 | Train Avg Loss: 0.0426  | Accuracy: 0.9832\n",
      "Epoch: 8940 | Train Avg Loss: 0.0437  | Accuracy: 0.9883\n",
      "Epoch: 8950 | Train Avg Loss: 0.0353  | Accuracy: 0.9883\n",
      "Epoch: 8960 | Train Avg Loss: 0.0361  | Accuracy: 0.9924\n",
      "Epoch: 8970 | Train Avg Loss: 0.0337  | Accuracy: 0.9858\n",
      "Epoch: 8980 | Train Avg Loss: 0.0373  | Accuracy: 0.9883\n",
      "Epoch: 8990 | Train Avg Loss: 0.0305  | Accuracy: 0.9858\n",
      "Epoch: 9000 | Train Avg Loss: 0.0358  | Accuracy: 0.9919\n",
      "Epoch: 9010 | Train Avg Loss: 0.0349  | Accuracy: 0.9898\n",
      "Epoch: 9020 | Train Avg Loss: 0.0355  | Accuracy: 0.9904\n",
      "Epoch: 9030 | Train Avg Loss: 0.0491  | Accuracy: 0.9812\n",
      "Epoch: 9040 | Train Avg Loss: 0.0521  | Accuracy: 0.9863\n",
      "Epoch: 9050 | Train Avg Loss: 0.0374  | Accuracy: 0.9873\n",
      "Epoch: 9060 | Train Avg Loss: 0.0426  | Accuracy: 0.9822\n",
      "Epoch: 9070 | Train Avg Loss: 0.0387  | Accuracy: 0.9919\n",
      "Epoch: 9080 | Train Avg Loss: 0.0404  | Accuracy: 0.9858\n",
      "Epoch: 9090 | Train Avg Loss: 0.0406  | Accuracy: 0.9868\n",
      "Epoch: 9100 | Train Avg Loss: 0.0390  | Accuracy: 0.9904\n",
      "Epoch: 9110 | Train Avg Loss: 0.0330  | Accuracy: 0.9904\n",
      "Epoch: 9120 | Train Avg Loss: 0.0341  | Accuracy: 0.9929\n",
      "Epoch: 9130 | Train Avg Loss: 0.0375  | Accuracy: 0.9924\n",
      "Epoch: 9140 | Train Avg Loss: 0.0328  | Accuracy: 0.9848\n",
      "Epoch: 9150 | Train Avg Loss: 0.0336  | Accuracy: 0.9893\n",
      "Epoch: 9160 | Train Avg Loss: 0.0355  | Accuracy: 0.9873\n",
      "Epoch: 9170 | Train Avg Loss: 0.0375  | Accuracy: 0.9838\n",
      "Epoch: 9180 | Train Avg Loss: 0.0318  | Accuracy: 0.9888\n",
      "Epoch: 9190 | Train Avg Loss: 0.0324  | Accuracy: 0.9883\n",
      "Epoch: 9200 | Train Avg Loss: 0.0310  | Accuracy: 0.9914\n",
      "Epoch: 9210 | Train Avg Loss: 0.0312  | Accuracy: 0.9924\n",
      "Epoch: 9220 | Train Avg Loss: 0.0287  | Accuracy: 0.9878\n",
      "Epoch: 9230 | Train Avg Loss: 0.0301  | Accuracy: 0.9919\n",
      "Epoch: 9240 | Train Avg Loss: 0.0299  | Accuracy: 0.9858\n",
      "Epoch: 9250 | Train Avg Loss: 0.0338  | Accuracy: 0.9893\n",
      "Epoch: 9260 | Train Avg Loss: 0.0329  | Accuracy: 0.9924\n",
      "Epoch: 9270 | Train Avg Loss: 0.0380  | Accuracy: 0.9863\n",
      "Epoch: 9280 | Train Avg Loss: 0.0357  | Accuracy: 0.9883\n",
      "Epoch: 9290 | Train Avg Loss: 0.0416  | Accuracy: 0.9914\n",
      "Epoch: 9300 | Train Avg Loss: 0.0461  | Accuracy: 0.9878\n",
      "Epoch: 9310 | Train Avg Loss: 0.0435  | Accuracy: 0.9807\n",
      "Epoch: 9320 | Train Avg Loss: 0.0355  | Accuracy: 0.9934\n",
      "Epoch: 9330 | Train Avg Loss: 0.0445  | Accuracy: 0.9848\n",
      "Epoch: 9340 | Train Avg Loss: 0.0395  | Accuracy: 0.9868\n",
      "Epoch: 9350 | Train Avg Loss: 0.0415  | Accuracy: 0.9878\n",
      "Epoch: 9360 | Train Avg Loss: 0.0328  | Accuracy: 0.9893\n",
      "Epoch: 9370 | Train Avg Loss: 0.0358  | Accuracy: 0.9888\n",
      "Epoch: 9380 | Train Avg Loss: 0.0342  | Accuracy: 0.9878\n",
      "Epoch: 9390 | Train Avg Loss: 0.0277  | Accuracy: 0.9868\n",
      "Epoch: 9400 | Train Avg Loss: 0.0334  | Accuracy: 0.9878\n",
      "Epoch: 9410 | Train Avg Loss: 0.0331  | Accuracy: 0.9883\n",
      "Epoch: 9420 | Train Avg Loss: 0.0325  | Accuracy: 0.9909\n",
      "Epoch: 9430 | Train Avg Loss: 0.0298  | Accuracy: 0.9924\n",
      "Epoch: 9440 | Train Avg Loss: 0.0275  | Accuracy: 0.9919\n",
      "Epoch: 9450 | Train Avg Loss: 0.0334  | Accuracy: 0.9863\n",
      "Epoch: 9460 | Train Avg Loss: 0.0401  | Accuracy: 0.9843\n",
      "Epoch: 9470 | Train Avg Loss: 0.0345  | Accuracy: 0.9868\n",
      "Epoch: 9480 | Train Avg Loss: 0.0415  | Accuracy: 0.9919\n",
      "Epoch: 9490 | Train Avg Loss: 0.0369  | Accuracy: 0.9822\n",
      "Epoch: 9500 | Train Avg Loss: 0.0349  | Accuracy: 0.9838\n",
      "Epoch: 9510 | Train Avg Loss: 0.0362  | Accuracy: 0.9909\n",
      "Epoch: 9520 | Train Avg Loss: 0.0341  | Accuracy: 0.9893\n",
      "Epoch: 9530 | Train Avg Loss: 0.0407  | Accuracy: 0.9893\n",
      "Epoch: 9540 | Train Avg Loss: 0.0353  | Accuracy: 0.9888\n",
      "Epoch: 9550 | Train Avg Loss: 0.0314  | Accuracy: 0.9888\n",
      "Epoch: 9560 | Train Avg Loss: 0.0342  | Accuracy: 0.9858\n",
      "Epoch: 9570 | Train Avg Loss: 0.0339  | Accuracy: 0.9873\n",
      "Epoch: 9580 | Train Avg Loss: 0.0320  | Accuracy: 0.9909\n",
      "Epoch: 9590 | Train Avg Loss: 0.0299  | Accuracy: 0.9893\n",
      "Epoch: 9600 | Train Avg Loss: 0.0351  | Accuracy: 0.9888\n",
      "Epoch: 9610 | Train Avg Loss: 0.0367  | Accuracy: 0.9873\n",
      "Epoch: 9620 | Train Avg Loss: 0.0378  | Accuracy: 0.9848\n",
      "Epoch: 9630 | Train Avg Loss: 0.0349  | Accuracy: 0.9883\n",
      "Epoch: 9640 | Train Avg Loss: 0.0323  | Accuracy: 0.9893\n",
      "Epoch: 9650 | Train Avg Loss: 0.0303  | Accuracy: 0.9863\n",
      "Epoch: 9660 | Train Avg Loss: 0.0351  | Accuracy: 0.9868\n",
      "Epoch: 9670 | Train Avg Loss: 0.0331  | Accuracy: 0.9888\n",
      "Epoch: 9680 | Train Avg Loss: 0.0301  | Accuracy: 0.9883\n",
      "Epoch: 9690 | Train Avg Loss: 0.0323  | Accuracy: 0.9944\n",
      "Epoch: 9700 | Train Avg Loss: 0.0367  | Accuracy: 0.9873\n",
      "Epoch: 9710 | Train Avg Loss: 0.0337  | Accuracy: 0.9904\n",
      "Epoch: 9720 | Train Avg Loss: 0.0354  | Accuracy: 0.9924\n",
      "Epoch: 9730 | Train Avg Loss: 0.0398  | Accuracy: 0.9878\n",
      "Epoch: 9740 | Train Avg Loss: 0.0382  | Accuracy: 0.9893\n",
      "Epoch: 9750 | Train Avg Loss: 0.0377  | Accuracy: 0.9959\n",
      "Epoch: 9760 | Train Avg Loss: 0.0611  | Accuracy: 0.9721\n",
      "Epoch: 9770 | Train Avg Loss: 0.0581  | Accuracy: 0.9827\n",
      "Epoch: 9780 | Train Avg Loss: 0.0429  | Accuracy: 0.9898\n",
      "Epoch: 9790 | Train Avg Loss: 0.0463  | Accuracy: 0.9848\n",
      "Epoch: 9800 | Train Avg Loss: 0.0413  | Accuracy: 0.9888\n",
      "Epoch: 9810 | Train Avg Loss: 0.0372  | Accuracy: 0.9888\n",
      "Epoch: 9820 | Train Avg Loss: 0.0324  | Accuracy: 0.9883\n",
      "Epoch: 9830 | Train Avg Loss: 0.0299  | Accuracy: 0.9888\n",
      "Epoch: 9840 | Train Avg Loss: 0.0319  | Accuracy: 0.9909\n",
      "Epoch: 9850 | Train Avg Loss: 0.0354  | Accuracy: 0.9873\n",
      "Epoch: 9860 | Train Avg Loss: 0.0345  | Accuracy: 0.9883\n",
      "Epoch: 9870 | Train Avg Loss: 0.0401  | Accuracy: 0.9863\n",
      "Epoch: 9880 | Train Avg Loss: 0.0400  | Accuracy: 0.9863\n",
      "Epoch: 9890 | Train Avg Loss: 0.0452  | Accuracy: 0.9822\n",
      "Epoch: 9900 | Train Avg Loss: 0.0399  | Accuracy: 0.9832\n",
      "Epoch: 9910 | Train Avg Loss: 0.0343  | Accuracy: 0.9883\n",
      "Epoch: 9920 | Train Avg Loss: 0.0327  | Accuracy: 0.9914\n",
      "Epoch: 9930 | Train Avg Loss: 0.0373  | Accuracy: 0.9873\n",
      "Epoch: 9940 | Train Avg Loss: 0.0301  | Accuracy: 0.9878\n",
      "Epoch: 9950 | Train Avg Loss: 0.0407  | Accuracy: 0.9893\n",
      "Epoch: 9960 | Train Avg Loss: 0.0346  | Accuracy: 0.9883\n",
      "Epoch: 9970 | Train Avg Loss: 0.0418  | Accuracy: 0.9878\n",
      "Epoch: 9980 | Train Avg Loss: 0.0371  | Accuracy: 0.9848\n",
      "Epoch: 9990 | Train Avg Loss: 0.0310  | Accuracy: 0.9919\n",
      "Epoch: 10000 | Train Avg Loss: 0.0299  | Accuracy: 0.9914\n"
     ]
    }
   ],
   "source": [
    "LOSS = []\n",
    "ACC = []\n",
    "loss_total = 0\n",
    "t = labels.numpy()\n",
    "for epoch in range(EPOCH):\n",
    "    inputs = Variable(features)\n",
    "    target = Variable(labels)\n",
    "    output = model(inputs)\n",
    "    loss = loss_func(output,target)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_total = loss_total + loss\n",
    "    if((epoch+1)%10 == 0):\n",
    "        avg = loss_total / 10\n",
    "        LOSS.append(avg.tolist())\n",
    "        pred_y = torch.max(output, 1)[1].data.numpy()\n",
    "        accuracy = float((pred_y == t).astype(int).sum()) / float(t.size)\n",
    "        ACC.append(accuracy)\n",
    "        print(\"Epoch: %d | Train Avg Loss: %.4f  | Accuracy: %.4f\"%(epoch+1,avg,accuracy))\n",
    "        loss_total = 0\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model(features[:10].view(-1,TIME_STEP,INPUT_SIZE))\n",
    "predicted = torch.max(predicted, 1)[1].data.numpy()\n",
    "test = t[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  real  predicted\n",
      "  rise    rise\n",
      "  rise    rise\n",
      "  rise    rise\n",
      "  rise    rise\n",
      "  rise    rise\n",
      "  fall    fall\n",
      "  rise    rise\n",
      "  rise    rise\n",
      "  fall    fall\n",
      "  rise    rise\n"
     ]
    }
   ],
   "source": [
    "print(\"%6s  %6s\"%(\"real\",\"predicted\"))\n",
    "for i in range(len(predicted)):\n",
    "    if(test[i] == 0):\n",
    "        print(\"%6s  \"%(\"fall\"),end = \"\");\n",
    "    elif(test[i]==1):\n",
    "        print(\"%6s  \"%(\"flat\"),end = \"\");\n",
    "    elif(test[i]==2):\n",
    "        print(\"%6s  \"%(\"rise\"),end = \"\");\n",
    "    \n",
    "    if(predicted[i] == 0):\n",
    "        print(\"%6s\"%(\"fall\"));\n",
    "    elif(predicted[i]==1):\n",
    "        print(\"%6s\"%(\"flat\"));\n",
    "    elif(predicted[i]==2):\n",
    "        print(\"%6s\"%(\"rise\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109.06454868428409\n",
      "109.03464842028916\n",
      "109.03464842028916\n",
      "109.00360310822725\n",
      "109.00360310822725\n",
      "108.96648044884205\n",
      "108.96648044884205\n",
      "108.92471406236291\n",
      "108.92471406236291\n",
      "108.89012726768851\n",
      "108.89012726768851\n",
      "108.84944272041321\n",
      "108.84944272041321\n",
      "108.81938806176186\n",
      "108.81938806176186\n",
      "108.78211938217282\n",
      "108.78211938217282\n",
      "108.74946470186114\n",
      "108.74946470186114\n",
      "108.71512937918305\n",
      "108.71512937918305\n",
      "108.67527703940868\n",
      "108.67527703940868\n",
      "108.63011842221022\n",
      "108.63011842221022\n",
      "108.59014423191547\n",
      "108.59014423191547\n",
      "108.5500182248652\n",
      "108.5500182248652\n",
      "108.51555364206433\n",
      "108.51555364206433\n",
      "108.48011520132422\n",
      "108.48011520132422\n",
      "108.44816774874926\n",
      "108.44816774874926\n",
      "108.41830179467797\n",
      "108.41830179467797\n",
      "108.38589387759566\n",
      "108.38589387759566\n",
      "108.34867987781763\n",
      "108.34867987781763\n",
      "108.30734550207853\n",
      "108.30734550207853\n",
      "108.26104447245598\n",
      "108.26104447245598\n",
      "108.21812351420522\n",
      "108.21812351420522\n",
      "108.1600268855691\n",
      "108.1600268855691\n",
      "108.09888081625104\n",
      "108.09888081625104\n",
      "108.06115111708641\n",
      "108.06115111708641\n",
      "108.02297441661358\n",
      "108.02297441661358\n",
      "107.98319913074374\n",
      "107.98319913074374\n",
      "107.94780253618956\n",
      "107.94780253618956\n",
      "107.91409254446626\n",
      "107.91409254446626\n",
      "107.87740468606353\n",
      "107.87740468606353\n",
      "107.84509614855051\n",
      "107.84509614855051\n",
      "107.8149673063308\n",
      "107.8149673063308\n",
      "107.78186749853194\n",
      "107.78186749853194\n",
      "107.7468163240701\n",
      "107.7468163240701\n",
      "107.71650197915733\n",
      "107.71650197915733\n",
      "107.68422628380358\n",
      "107.68422628380358\n",
      "107.64929832331836\n",
      "107.64929832331836\n",
      "107.61148975975811\n",
      "107.61148975975811\n",
      "107.57474538125098\n",
      "107.57474538125098\n",
      "107.53969037719071\n",
      "107.53969037719071\n",
      "107.5098346080631\n",
      "107.5098346080631\n",
      "107.4778205435723\n",
      "107.4778205435723\n",
      "107.44392724148929\n",
      "107.44392724148929\n",
      "107.40972395054996\n",
      "107.40972395054996\n",
      "107.37829199619591\n",
      "107.37829199619591\n",
      "107.34294954501092\n",
      "107.34294954501092\n",
      "107.30225005187094\n",
      "107.30225005187094\n",
      "107.26812146045268\n",
      "107.26812146045268\n",
      "107.2319490853697\n",
      "107.2319490853697\n",
      "107.1970729958266\n",
      "107.1970729958266\n",
      "107.16019136272371\n",
      "107.16019136272371\n",
      "107.11865090020001\n",
      "107.11865090020001\n",
      "107.08411655761302\n",
      "107.08411655761302\n",
      "107.04403259418905\n",
      "107.04403259418905\n",
      "107.01067229919136\n",
      "107.01067229919136\n",
      "106.98320737294853\n",
      "106.98320737294853\n",
      "106.95339515246451\n",
      "106.95339515246451\n",
      "106.92089797370136\n",
      "106.92089797370136\n",
      "106.88781162165105\n",
      "106.88781162165105\n",
      "106.85440966673195\n",
      "106.85440966673195\n",
      "106.82668882794678\n",
      "106.82668882794678\n",
      "106.79245521686971\n",
      "106.79245521686971\n",
      "106.75665658153594\n",
      "106.75665658153594\n",
      "106.72380946017802\n",
      "106.72380946017802\n",
      "106.68235439248383\n",
      "106.68235439248383\n",
      "106.64285439439118\n",
      "106.64285439439118\n",
      "106.59831071086228\n",
      "106.59831071086228\n",
      "106.5628479924053\n",
      "106.5628479924053\n",
      "106.51935058273375\n",
      "106.51935058273375\n",
      "106.47320078127086\n",
      "106.47320078127086\n",
      "106.43164557777345\n",
      "106.43164557777345\n",
      "106.39592528156936\n",
      "106.39592528156936\n",
      "106.35795901156962\n",
      "106.35795901156962\n",
      "106.3250944558531\n",
      "106.3250944558531\n",
      "106.29128705151379\n",
      "106.29128705151379\n",
      "106.2613550554961\n",
      "106.2613550554961\n",
      "106.23126269690692\n",
      "106.23126269690692\n",
      "106.20258516818285\n",
      "106.20258516818285\n",
      "106.17136730067432\n",
      "106.17136730067432\n",
      "106.14033784717321\n",
      "106.14033784717321\n",
      "106.10788832977414\n",
      "106.10788832977414\n",
      "106.07607943937182\n",
      "106.07607943937182\n",
      "106.03855173662305\n",
      "106.03855173662305\n",
      "106.00309394299984\n",
      "106.00309394299984\n",
      "105.96954040974379\n",
      "105.96954040974379\n",
      "105.9367348253727\n",
      "105.9367348253727\n",
      "105.89927147701383\n",
      "105.89927147701383\n",
      "105.8651719391346\n",
      "105.8651719391346\n",
      "105.83215961232781\n",
      "105.83215961232781\n",
      "105.793203830719\n",
      "105.793203830719\n",
      "105.75258814543486\n",
      "105.75258814543486\n",
      "105.71218429505825\n",
      "105.71218429505825\n",
      "105.67351370304823\n",
      "105.67351370304823\n",
      "105.63090215623379\n",
      "105.63090215623379\n",
      "105.59354773908854\n",
      "105.59354773908854\n",
      "105.54142986238003\n",
      "105.54142986238003\n",
      "105.49234188348055\n",
      "105.49234188348055\n",
      "105.45683828368783\n",
      "105.45683828368783\n",
      "105.42196716368198\n",
      "105.42196716368198\n",
      "105.38617962226272\n",
      "105.38617962226272\n",
      "105.35568790137768\n",
      "105.35568790137768\n",
      "105.31840920448303\n",
      "105.31840920448303\n",
      "105.28467793017626\n",
      "105.28467793017626\n",
      "105.2485946752131\n",
      "105.2485946752131\n",
      "105.21325236186385\n",
      "105.21325236186385\n",
      "105.16952911019325\n",
      "105.16952911019325\n",
      "105.12689659371972\n",
      "105.12689659371972\n",
      "105.09318530187011\n",
      "105.09318530187011\n",
      "105.05110379308462\n",
      "105.05110379308462\n",
      "105.01255239546299\n",
      "105.01255239546299\n",
      "104.97785416990519\n",
      "104.97785416990519\n",
      "104.94163277745247\n",
      "104.94163277745247\n",
      "104.90588180348277\n",
      "104.90588180348277\n",
      "104.86523442342877\n",
      "104.86523442342877\n",
      "104.82312703877687\n",
      "104.82312703877687\n",
      "104.78196322917938\n",
      "104.78196322917938\n",
      "104.74713387340307\n",
      "104.74713387340307\n",
      "104.71045081317425\n",
      "104.71045081317425\n",
      "104.67769489437342\n",
      "104.67769489437342\n",
      "104.64423562958837\n",
      "104.64423562958837\n",
      "104.61442881636322\n",
      "104.61442881636322\n",
      "104.57582195661962\n",
      "104.57582195661962\n",
      "104.53591607324779\n",
      "104.53591607324779\n",
      "104.50347617454827\n",
      "104.50347617454827\n",
      "104.46525806374848\n",
      "104.46525806374848\n",
      "104.42899872921407\n",
      "104.42899872921407\n",
      "104.39221285842359\n",
      "104.39221285842359\n",
      "104.3582856785506\n",
      "104.3582856785506\n",
      "104.32438709400594\n",
      "104.32438709400594\n",
      "104.291084298864\n",
      "104.291084298864\n",
      "104.2539400588721\n",
      "104.2539400588721\n",
      "104.2131167743355\n",
      "104.2131167743355\n",
      "104.17247747443616\n",
      "104.17247747443616\n",
      "104.11895804665983\n",
      "104.11895804665983\n",
      "104.06695146672428\n",
      "104.06695146672428\n",
      "104.0208437051624\n",
      "104.0208437051624\n",
      "103.97924305312335\n",
      "103.97924305312335\n",
      "103.94239878468215\n",
      "103.94239878468215\n",
      "103.89931110106409\n",
      "103.89931110106409\n",
      "103.84835242666304\n",
      "103.84835242666304\n",
      "103.80718780867755\n",
      "103.80718780867755\n",
      "103.76892696134746\n",
      "103.76892696134746\n",
      "103.73483737744391\n",
      "103.73483737744391\n",
      "103.69837989099324\n",
      "103.69837989099324\n",
      "103.66191200353205\n",
      "103.66191200353205\n",
      "103.62021109648049\n",
      "103.62021109648049\n",
      "103.57292324490845\n",
      "103.57292324490845\n",
      "103.53066874854267\n",
      "103.53066874854267\n",
      "103.49047872982919\n",
      "103.49047872982919\n",
      "103.43368451483548\n",
      "103.43368451483548\n",
      "103.37926960550249\n",
      "103.37926960550249\n",
      "103.33896437473595\n",
      "103.33896437473595\n",
      "103.29852701537311\n",
      "103.29852701537311\n",
      "103.26080010272563\n",
      "103.26080010272563\n",
      "103.22077696211636\n",
      "103.22077696211636\n",
      "103.17385886050761\n",
      "103.17385886050761\n",
      "103.11470851488411\n",
      "103.11470851488411\n",
      "103.07020626403391\n",
      "103.07020626403391\n",
      "103.03513923473656\n",
      "103.03513923473656\n",
      "102.99782986007631\n",
      "102.99782986007631\n",
      "102.95904573611915\n",
      "102.95904573611915\n",
      "102.913697803393\n",
      "102.913697803393\n",
      "102.86795047111809\n",
      "102.86795047111809\n",
      "102.82140156067908\n",
      "102.82140156067908\n",
      "102.77349082194269\n",
      "102.77349082194269\n",
      "102.72928733937442\n",
      "102.72928733937442\n",
      "102.68659100495279\n",
      "102.68659100495279\n",
      "102.64023251645267\n",
      "102.64023251645267\n",
      "102.59819266758859\n",
      "102.59819266758859\n",
      "102.55631619505584\n",
      "102.55631619505584\n",
      "102.51409240625799\n",
      "102.51409240625799\n",
      "102.46761581487954\n",
      "102.46761581487954\n",
      "102.40778940357268\n",
      "102.40778940357268\n",
      "102.36379607208073\n",
      "102.36379607208073\n",
      "102.32716044224799\n",
      "102.32716044224799\n",
      "102.2895934600383\n",
      "102.2895934600383\n",
      "102.25710250250995\n",
      "102.25710250250995\n",
      "102.22434974648058\n",
      "102.22434974648058\n",
      "102.19146476499736\n",
      "102.19146476499736\n",
      "102.15890867076814\n",
      "102.15890867076814\n",
      "102.12300981394947\n",
      "102.12300981394947\n",
      "102.09034997783601\n",
      "102.09034997783601\n",
      "102.05743199028075\n",
      "102.05743199028075\n",
      "102.01946477405727\n",
      "102.01946477405727\n",
      "101.97265879996121\n",
      "101.97265879996121\n",
      "101.93516815267503\n",
      "101.93516815267503\n",
      "101.90109226666391\n",
      "101.90109226666391\n",
      "101.86634503491223\n",
      "101.86634503491223\n",
      "101.83199272491038\n",
      "101.83199272491038\n",
      "101.79792841337621\n",
      "101.79792841337621\n",
      "101.7636806126684\n",
      "101.7636806126684\n",
      "101.73234083689749\n",
      "101.73234083689749\n",
      "101.6980035547167\n",
      "101.6980035547167\n",
      "101.66392842493951\n",
      "101.66392842493951\n",
      "101.62241670303047\n",
      "101.62241670303047\n",
      "101.58802023343742\n",
      "101.58802023343742\n",
      "101.55458209104836\n",
      "101.55458209104836\n",
      "101.52128094993532\n",
      "101.52128094993532\n",
      "101.48347700946033\n",
      "101.48347700946033\n",
      "101.45434648171067\n",
      "101.45434648171067\n",
      "101.42033049464226\n",
      "101.42033049464226\n",
      "101.38288883119822\n",
      "101.38288883119822\n",
      "101.34203970432281\n",
      "101.34203970432281\n",
      "101.30513253062963\n",
      "101.30513253062963\n",
      "101.25981515645981\n",
      "101.25981515645981\n",
      "101.22322707623243\n",
      "101.22322707623243\n",
      "101.17935768142343\n",
      "101.17935768142343\n",
      "101.13294951990247\n",
      "101.13294951990247\n",
      "101.08486826345325\n",
      "101.08486826345325\n",
      "101.03028502315283\n",
      "101.03028502315283\n",
      "100.95699918270111\n",
      "100.95699918270111\n",
      "100.90205895900726\n",
      "100.90205895900726\n",
      "100.86478643119335\n",
      "100.86478643119335\n",
      "100.82664850726724\n",
      "100.82664850726724\n",
      "100.79244098812342\n",
      "100.79244098812342\n",
      "100.75866558030248\n",
      "100.75866558030248\n",
      "100.7276974003762\n",
      "100.7276974003762\n",
      "100.69891370087862\n",
      "100.69891370087862\n",
      "100.665672916919\n",
      "100.665672916919\n",
      "100.63048042729497\n",
      "100.63048042729497\n",
      "100.59499446675181\n",
      "100.59499446675181\n",
      "100.56058067828417\n",
      "100.56058067828417\n",
      "100.52400350570679\n",
      "100.52400350570679\n",
      "100.47941094264388\n",
      "100.47941094264388\n",
      "100.43493941053748\n",
      "100.43493941053748\n",
      "100.38951236754656\n",
      "100.38951236754656\n",
      "100.33871594071388\n",
      "100.33871594071388\n",
      "100.29948691651225\n",
      "100.29948691651225\n",
      "100.26421762630343\n",
      "100.26421762630343\n",
      "100.22263322398067\n",
      "100.22263322398067\n",
      "100.17950697988272\n",
      "100.17950697988272\n",
      "100.135194581002\n",
      "100.135194581002\n",
      "100.08826842159033\n",
      "100.08826842159033\n",
      "100.04854146391153\n",
      "100.04854146391153\n",
      "100.0042941197753\n",
      "100.0042941197753\n",
      "99.96024526655674\n",
      "99.96024526655674\n",
      "99.9207651913166\n",
      "99.9207651913166\n",
      "99.8812107257545\n",
      "99.8812107257545\n",
      "99.83851014077663\n",
      "99.83851014077663\n",
      "99.77972608059645\n",
      "99.77972608059645\n",
      "99.72444806620479\n",
      "99.72444806620479\n",
      "99.68761682510376\n",
      "99.68761682510376\n",
      "99.64706302806735\n",
      "99.64706302806735\n",
      "99.60969763249159\n",
      "99.60969763249159\n",
      "99.57610343024135\n",
      "99.57610343024135\n",
      "99.53790519014001\n",
      "99.53790519014001\n",
      "99.50579497590661\n",
      "99.50579497590661\n",
      "99.46943863853812\n",
      "99.46943863853812\n",
      "99.43260016292334\n",
      "99.43260016292334\n",
      "99.40111763775349\n",
      "99.40111763775349\n",
      "99.37096556648612\n",
      "99.37096556648612\n",
      "99.33484967425466\n",
      "99.33484967425466\n",
      "99.29254139587283\n",
      "99.29254139587283\n",
      "99.24460240453482\n",
      "99.24460240453482\n",
      "99.20162363350391\n",
      "99.20162363350391\n",
      "99.16672019660473\n",
      "99.16672019660473\n",
      "99.13117729872465\n",
      "99.13117729872465\n",
      "99.08707169815898\n",
      "99.08707169815898\n",
      "99.05078819021583\n",
      "99.05078819021583\n",
      "99.02328532002866\n",
      "99.02328532002866\n",
      "98.99505315348506\n",
      "98.99505315348506\n",
      "98.95339402928948\n",
      "98.95339402928948\n",
      "98.92236073315144\n",
      "98.92236073315144\n",
      "98.88207568973303\n",
      "98.88207568973303\n",
      "98.84740083664656\n",
      "98.84740083664656\n",
      "98.8148630708456\n",
      "98.8148630708456\n",
      "98.77716884762049\n",
      "98.77716884762049\n",
      "98.73827439919114\n",
      "98.73827439919114\n",
      "98.70860277861357\n",
      "98.70860277861357\n",
      "98.67255407944322\n",
      "98.67255407944322\n",
      "98.6357284784317\n",
      "98.6357284784317\n",
      "98.60325895994902\n",
      "98.60325895994902\n",
      "98.57165252417326\n",
      "98.57165252417326\n",
      "98.53507090732455\n",
      "98.53507090732455\n",
      "98.49837832897902\n",
      "98.49837832897902\n",
      "98.45830476284027\n",
      "98.45830476284027\n",
      "98.41638832911849\n",
      "98.41638832911849\n",
      "98.376803137362\n",
      "98.376803137362\n",
      "98.33440634608269\n",
      "98.33440634608269\n",
      "98.29546616971493\n",
      "98.29546616971493\n",
      "98.25176989287138\n",
      "98.25176989287138\n",
      "98.2060063406825\n",
      "98.2060063406825\n",
      "98.14919135347009\n",
      "98.14919135347009\n",
      "98.08977108821273\n",
      "98.08977108821273\n",
      "98.03288377076387\n",
      "98.03288377076387\n",
      "97.97607432305813\n",
      "97.97607432305813\n",
      "97.9185643158853\n",
      "97.9185643158853\n",
      "97.86610363796353\n",
      "97.86610363796353\n",
      "97.81478499248624\n",
      "97.81478499248624\n",
      "97.76727138459682\n",
      "97.76727138459682\n",
      "97.72337439283729\n",
      "97.72337439283729\n",
      "97.68172299489379\n",
      "97.68172299489379\n",
      "97.64265890419483\n",
      "97.64265890419483\n",
      "97.60755752772093\n",
      "97.60755752772093\n",
      "97.56504797190428\n",
      "97.56504797190428\n",
      "97.51772874966264\n",
      "97.51772874966264\n",
      "97.4798920340836\n",
      "97.4798920340836\n",
      "97.44147385284305\n",
      "97.44147385284305\n",
      "97.40426388382912\n",
      "97.40426388382912\n",
      "97.36651741713285\n",
      "97.36651741713285\n",
      "97.33599931187928\n",
      "97.33599931187928\n",
      "97.30209719575942\n",
      "97.30209719575942\n",
      "97.26368642412126\n",
      "97.26368642412126\n",
      "97.22566523216665\n",
      "97.22566523216665\n",
      "97.18537291698158\n",
      "97.18537291698158\n",
      "97.14068801887333\n",
      "97.14068801887333\n",
      "97.10044851340353\n",
      "97.10044851340353\n",
      "97.0579603780061\n",
      "97.0579603780061\n",
      "97.0138410013169\n",
      "97.0138410013169\n",
      "96.98413823917508\n",
      "96.98413823917508\n",
      "96.95348193496466\n",
      "96.95348193496466\n",
      "96.90966423973441\n",
      "96.90966423973441\n",
      "96.85733561590314\n",
      "96.85733561590314\n",
      "96.81750785931945\n",
      "96.81750785931945\n",
      "96.77989238500595\n",
      "96.77989238500595\n",
      "96.74532789736986\n",
      "96.74532789736986\n",
      "96.71014912053943\n",
      "96.71014912053943\n",
      "96.67877872660756\n",
      "96.67877872660756\n",
      "96.64317262545228\n",
      "96.64317262545228\n",
      "96.60517009720206\n",
      "96.60517009720206\n",
      "96.56740489974618\n",
      "96.56740489974618\n",
      "96.52580299600959\n",
      "96.52580299600959\n",
      "96.49308643117547\n",
      "96.49308643117547\n",
      "96.460455134511\n",
      "96.460455134511\n",
      "96.42766178026795\n",
      "96.42766178026795\n",
      "96.39287668839097\n",
      "96.39287668839097\n",
      "96.36129578575492\n",
      "96.36129578575492\n",
      "96.31937754154205\n",
      "96.31937754154205\n",
      "96.27223598957062\n",
      "96.27223598957062\n",
      "96.23304592818022\n",
      "96.23304592818022\n",
      "96.19760922342539\n",
      "96.19760922342539\n",
      "96.15749049931765\n",
      "96.15749049931765\n",
      "96.11685845255852\n",
      "96.11685845255852\n",
      "96.07236295193434\n",
      "96.07236295193434\n",
      "96.03762243315578\n",
      "96.03762243315578\n",
      "96.00100726634264\n",
      "96.00100726634264\n",
      "95.96370258927345\n",
      "95.96370258927345\n",
      "95.92869484052062\n",
      "95.92869484052062\n",
      "95.88920621946454\n",
      "95.88920621946454\n",
      "95.84470618143678\n",
      "95.84470618143678\n",
      "95.79821010679007\n",
      "95.79821010679007\n",
      "95.75773537531495\n",
      "95.75773537531495\n",
      "95.72042465209961\n",
      "95.72042465209961\n",
      "95.68148794397712\n",
      "95.68148794397712\n",
      "95.63992477580905\n",
      "95.63992477580905\n",
      "95.59839922562242\n",
      "95.59839922562242\n",
      "95.55553963035345\n",
      "95.55553963035345\n",
      "95.52395316958427\n",
      "95.52395316958427\n",
      "95.48786171153188\n",
      "95.48786171153188\n",
      "95.43571701645851\n",
      "95.43571701645851\n",
      "95.3901241645217\n",
      "95.3901241645217\n",
      "95.34298767149448\n",
      "95.34298767149448\n",
      "95.30057523399591\n",
      "95.30057523399591\n",
      "95.26272490993142\n",
      "95.26272490993142\n",
      "95.22950897365808\n",
      "95.22950897365808\n",
      "95.19151972979307\n",
      "95.19151972979307\n",
      "95.15222815796733\n",
      "95.15222815796733\n",
      "95.11423539370298\n",
      "95.11423539370298\n",
      "95.07426577806473\n",
      "95.07426577806473\n",
      "95.03314362838864\n",
      "95.03314362838864\n",
      "94.99240110814571\n",
      "94.99240110814571\n",
      "94.95301570743322\n",
      "94.95301570743322\n",
      "94.915611397475\n",
      "94.915611397475\n",
      "94.87726022675633\n",
      "94.87726022675633\n",
      "94.83488060161471\n",
      "94.83488060161471\n",
      "94.79925714060664\n",
      "94.79925714060664\n",
      "94.76750283688307\n",
      "94.76750283688307\n",
      "94.73415119200945\n",
      "94.73415119200945\n",
      "94.69182732701302\n",
      "94.69182732701302\n",
      "94.64852750301361\n",
      "94.64852750301361\n",
      "94.60589564964175\n",
      "94.60589564964175\n",
      "94.55991150811315\n",
      "94.55991150811315\n",
      "94.5112250521779\n",
      "94.5112250521779\n",
      "94.46934037655592\n",
      "94.46934037655592\n",
      "94.43059963360429\n",
      "94.43059963360429\n",
      "94.39602863788605\n",
      "94.39602863788605\n",
      "94.35668874531984\n",
      "94.35668874531984\n",
      "94.31968938559294\n",
      "94.31968938559294\n",
      "94.2836167961359\n",
      "94.2836167961359\n",
      "94.24265801906586\n",
      "94.24265801906586\n",
      "94.20099626109004\n",
      "94.20099626109004\n",
      "94.15897411480546\n",
      "94.15897411480546\n",
      "94.10761378705502\n",
      "94.10761378705502\n",
      "94.055888928473\n",
      "94.055888928473\n",
      "94.01010391116142\n",
      "94.01010391116142\n",
      "93.96313992887735\n",
      "93.96313992887735\n",
      "93.92203721404076\n",
      "93.92203721404076\n",
      "93.87897267192602\n",
      "93.87897267192602\n",
      "93.82600393146276\n",
      "93.82600393146276\n",
      "93.77614338696003\n",
      "93.77614338696003\n",
      "93.73552442342043\n",
      "93.73552442342043\n",
      "93.69534432888031\n",
      "93.69534432888031\n",
      "93.66059723123908\n",
      "93.66059723123908\n",
      "93.62391892820597\n",
      "93.62391892820597\n",
      "93.58701631426811\n",
      "93.58701631426811\n",
      "93.54854774475098\n",
      "93.54854774475098\n",
      "93.50511419028044\n",
      "93.50511419028044\n",
      "93.46345950290561\n",
      "93.46345950290561\n",
      "93.42079771310091\n",
      "93.42079771310091\n",
      "93.3846062719822\n",
      "93.3846062719822\n",
      "93.3426951020956\n",
      "93.3426951020956\n",
      "93.2975487858057\n",
      "93.2975487858057\n",
      "93.24846225604415\n",
      "93.24846225604415\n",
      "93.20779702439904\n",
      "93.20779702439904\n",
      "93.16304228827357\n",
      "93.16304228827357\n",
      "93.1151600368321\n",
      "93.1151600368321\n",
      "93.0662592947483\n",
      "93.0662592947483\n",
      "93.01688880845904\n",
      "93.01688880845904\n",
      "92.96506199613214\n",
      "92.96506199613214\n",
      "92.91244910657406\n",
      "92.91244910657406\n",
      "92.86225297302008\n",
      "92.86225297302008\n",
      "92.81145712733269\n",
      "92.81145712733269\n",
      "92.75068236142397\n",
      "92.75068236142397\n",
      "92.70639395713806\n",
      "92.70639395713806\n",
      "92.6601561717689\n",
      "92.6601561717689\n",
      "92.61591385677457\n",
      "92.61591385677457\n",
      "92.56281770020723\n",
      "92.56281770020723\n",
      "92.51992719247937\n",
      "92.51992719247937\n",
      "92.47920940443873\n",
      "92.47920940443873\n",
      "92.43709545210004\n",
      "92.43709545210004\n",
      "92.39394798502326\n",
      "92.39394798502326\n",
      "92.3493307903409\n",
      "92.3493307903409\n",
      "92.30652349442244\n",
      "92.30652349442244\n",
      "92.26155184209347\n",
      "92.26155184209347\n",
      "92.22499068081379\n",
      "92.22499068081379\n",
      "92.18508966639638\n",
      "92.18508966639638\n",
      "92.14980808272958\n",
      "92.14980808272958\n",
      "92.11147752404213\n",
      "92.11147752404213\n",
      "92.07400255650282\n",
      "92.07400255650282\n",
      "92.0284606218338\n",
      "92.0284606218338\n",
      "91.99229392781854\n",
      "91.99229392781854\n",
      "91.95068612322211\n",
      "91.95068612322211\n",
      "91.90576714277267\n",
      "91.90576714277267\n",
      "91.86419877037406\n",
      "91.86419877037406\n",
      "91.81987940147519\n",
      "91.81987940147519\n",
      "91.77669598907232\n",
      "91.77669598907232\n",
      "91.73615011945367\n",
      "91.73615011945367\n",
      "91.70465863868594\n",
      "91.70465863868594\n",
      "91.66456914693117\n",
      "91.66456914693117\n",
      "91.62452092766762\n",
      "91.62452092766762\n",
      "91.58974255993962\n",
      "91.58974255993962\n",
      "91.55476545915008\n",
      "91.55476545915008\n",
      "91.51517771929502\n",
      "91.51517771929502\n",
      "91.46763223409653\n",
      "91.46763223409653\n",
      "91.42401685938239\n",
      "91.42401685938239\n",
      "91.38210986927152\n",
      "91.38210986927152\n",
      "91.34000129625201\n",
      "91.34000129625201\n",
      "91.2941868826747\n",
      "91.2941868826747\n",
      "91.24912268295884\n",
      "91.24912268295884\n",
      "91.20360315591097\n",
      "91.20360315591097\n",
      "91.15810598433018\n",
      "91.15810598433018\n",
      "91.11490893736482\n",
      "91.11490893736482\n",
      "91.07289954647422\n",
      "91.07289954647422\n",
      "91.02384738996625\n",
      "91.02384738996625\n",
      "90.98672337457538\n",
      "90.98672337457538\n",
      "90.95094112679362\n",
      "90.95094112679362\n",
      "90.90663947537541\n",
      "90.90663947537541\n",
      "90.86396021023393\n",
      "90.86396021023393\n",
      "90.82532046362758\n",
      "90.82532046362758\n",
      "90.78180281817913\n",
      "90.78180281817913\n",
      "90.73362054303288\n",
      "90.73362054303288\n",
      "90.68286871537566\n",
      "90.68286871537566\n",
      "90.64262728765607\n",
      "90.64262728765607\n",
      "90.60491818934679\n",
      "90.60491818934679\n",
      "90.55761895701289\n",
      "90.55761895701289\n",
      "90.50872372835875\n",
      "90.50872372835875\n",
      "90.45170529931784\n",
      "90.45170529931784\n",
      "90.39628636837006\n",
      "90.39628636837006\n",
      "90.34081007167697\n",
      "90.34081007167697\n",
      "90.29786862805486\n",
      "90.29786862805486\n",
      "90.25189949199557\n",
      "90.25189949199557\n",
      "90.2014482729137\n",
      "90.2014482729137\n",
      "90.15339194610715\n",
      "90.15339194610715\n",
      "90.10826192423701\n",
      "90.10826192423701\n",
      "90.06258994713426\n",
      "90.06258994713426\n",
      "90.02407226711512\n",
      "90.02407226711512\n",
      "89.98008151352406\n",
      "89.98008151352406\n",
      "89.93228840082884\n",
      "89.93228840082884\n",
      "89.88225544989109\n",
      "89.88225544989109\n",
      "89.82649815455079\n",
      "89.82649815455079\n",
      "89.77321780845523\n",
      "89.77321780845523\n",
      "89.72695106640458\n",
      "89.72695106640458\n",
      "89.6783112064004\n",
      "89.6783112064004\n",
      "89.61657425388694\n",
      "89.61657425388694\n",
      "89.56292755901814\n",
      "89.56292755901814\n",
      "89.51208015531301\n",
      "89.51208015531301\n",
      "89.46388553082943\n",
      "89.46388553082943\n",
      "89.42446545511484\n",
      "89.42446545511484\n",
      "89.37726089730859\n",
      "89.37726089730859\n",
      "89.32368345558643\n",
      "89.32368345558643\n",
      "89.27470248565078\n",
      "89.27470248565078\n",
      "89.2196353264153\n",
      "89.2196353264153\n",
      "89.17200992628932\n",
      "89.17200992628932\n",
      "89.11770933121443\n",
      "89.11770933121443\n",
      "89.05034659057856\n",
      "89.05034659057856\n",
      "88.98502629250288\n",
      "88.98502629250288\n",
      "88.92561418190598\n",
      "88.92561418190598\n",
      "88.8713503330946\n",
      "88.8713503330946\n",
      "88.82448987290263\n",
      "88.82448987290263\n",
      "88.77239146828651\n",
      "88.77239146828651\n",
      "88.70519222319126\n",
      "88.70519222319126\n",
      "88.646683935076\n",
      "88.646683935076\n",
      "88.6006095148623\n",
      "88.6006095148623\n",
      "88.55486635491252\n",
      "88.55486635491252\n",
      "88.49705305695534\n",
      "88.49705305695534\n",
      "88.4307361766696\n",
      "88.4307361766696\n",
      "88.36738312244415\n",
      "88.36738312244415\n",
      "88.30882750824094\n",
      "88.30882750824094\n",
      "88.25476299598813\n",
      "88.25476299598813\n",
      "88.20182353258133\n",
      "88.20182353258133\n",
      "88.14138143509626\n",
      "88.14138143509626\n",
      "88.07807943969965\n",
      "88.07807943969965\n",
      "88.0295536108315\n",
      "88.0295536108315\n",
      "87.98499497771263\n",
      "87.98499497771263\n",
      "87.943673633039\n",
      "87.943673633039\n",
      "87.90931054204702\n",
      "87.90931054204702\n",
      "87.8655374571681\n",
      "87.8655374571681\n",
      "87.81470523402095\n",
      "87.81470523402095\n",
      "87.75871124118567\n",
      "87.75871124118567\n",
      "87.70193519443274\n",
      "87.70193519443274\n",
      "87.6546259559691\n",
      "87.6546259559691\n",
      "87.61062842234969\n",
      "87.61062842234969\n",
      "87.56645318120718\n",
      "87.56645318120718\n",
      "87.52548673003912\n",
      "87.52548673003912\n",
      "87.48173278570175\n",
      "87.48173278570175\n",
      "87.4322343878448\n",
      "87.4322343878448\n",
      "87.38497741892934\n",
      "87.38497741892934\n",
      "87.33824317529798\n",
      "87.33824317529798\n",
      "87.29229779541492\n",
      "87.29229779541492\n",
      "87.24217438325286\n",
      "87.24217438325286\n",
      "87.19526609033346\n",
      "87.19526609033346\n",
      "87.13981880247593\n",
      "87.13981880247593\n",
      "87.09137757867575\n",
      "87.09137757867575\n",
      "87.03769827261567\n",
      "87.03769827261567\n",
      "86.9874094389379\n",
      "86.9874094389379\n",
      "86.93817984312773\n",
      "86.93817984312773\n",
      "86.89169796183705\n",
      "86.89169796183705\n",
      "86.84078145772219\n",
      "86.84078145772219\n",
      "86.79028584435582\n",
      "86.79028584435582\n",
      "86.7348836325109\n",
      "86.7348836325109\n",
      "86.68530303612351\n",
      "86.68530303612351\n",
      "86.62716525420547\n",
      "86.62716525420547\n",
      "86.57032497227192\n",
      "86.57032497227192\n",
      "86.52894510701299\n",
      "86.52894510701299\n",
      "86.48186216130853\n",
      "86.48186216130853\n",
      "86.43331017717719\n",
      "86.43331017717719\n",
      "86.384945910424\n",
      "86.384945910424\n",
      "86.33899318054318\n",
      "86.33899318054318\n",
      "86.29714937135577\n",
      "86.29714937135577\n",
      "86.25267599895597\n",
      "86.25267599895597\n",
      "86.20264819264412\n",
      "86.20264819264412\n",
      "86.15954433009028\n",
      "86.15954433009028\n",
      "86.11685535311699\n",
      "86.11685535311699\n",
      "86.07397135719657\n",
      "86.07397135719657\n",
      "86.03643487021327\n",
      "86.03643487021327\n",
      "85.98827411234379\n",
      "85.98827411234379\n",
      "85.94377062097192\n",
      "85.94377062097192\n",
      "85.8985008560121\n",
      "85.8985008560121\n",
      "85.85101378709078\n",
      "85.85101378709078\n",
      "85.80130584537983\n",
      "85.80130584537983\n",
      "85.75404613092542\n",
      "85.75404613092542\n",
      "85.69846867397428\n",
      "85.69846867397428\n",
      "85.64758132770658\n",
      "85.64758132770658\n",
      "85.60604288056493\n",
      "85.60604288056493\n",
      "85.55685073509812\n",
      "85.55685073509812\n",
      "85.50492623820901\n",
      "85.50492623820901\n",
      "85.45782398805022\n",
      "85.45782398805022\n",
      "85.41057557240129\n",
      "85.41057557240129\n",
      "85.36356520280242\n",
      "85.36356520280242\n",
      "85.32039550319314\n",
      "85.32039550319314\n",
      "85.27848636731505\n",
      "85.27848636731505\n",
      "85.2352637462318\n",
      "85.2352637462318\n",
      "85.18944692984223\n",
      "85.18944692984223\n",
      "85.1394490711391\n",
      "85.1394490711391\n",
      "85.08733082190156\n",
      "85.08733082190156\n",
      "85.03658505901694\n",
      "85.03658505901694\n",
      "84.97440443187952\n",
      "84.97440443187952\n",
      "84.92367008328438\n",
      "84.92367008328438\n",
      "84.86851622536778\n",
      "84.86851622536778\n",
      "84.81806810572743\n",
      "84.81806810572743\n",
      "84.77657155320048\n",
      "84.77657155320048\n",
      "84.72675213590264\n",
      "84.72675213590264\n",
      "84.66490396112204\n",
      "84.66490396112204\n",
      "84.6107473410666\n",
      "84.6107473410666\n",
      "84.57090921700001\n",
      "84.57090921700001\n",
      "84.52282857522368\n",
      "84.52282857522368\n",
      "84.4725142903626\n",
      "84.4725142903626\n",
      "84.42529037222266\n",
      "84.42529037222266\n",
      "84.37256998196244\n",
      "84.37256998196244\n",
      "84.31912890449166\n",
      "84.31912890449166\n",
      "84.2698633223772\n",
      "84.2698633223772\n",
      "84.22095514461398\n",
      "84.22095514461398\n",
      "84.16854839399457\n",
      "84.16854839399457\n",
      "84.12398969009519\n",
      "84.12398969009519\n",
      "84.07307922840118\n",
      "84.07307922840118\n",
      "84.02310382574797\n",
      "84.02310382574797\n",
      "83.9771304950118\n",
      "83.9771304950118\n",
      "83.92276755347848\n",
      "83.92276755347848\n",
      "83.87625942751765\n",
      "83.87625942751765\n",
      "83.82793005555868\n",
      "83.82793005555868\n",
      "83.78136698529124\n",
      "83.78136698529124\n",
      "83.73199153319001\n",
      "83.73199153319001\n",
      "83.67942913621664\n",
      "83.67942913621664\n",
      "83.62040042132139\n",
      "83.62040042132139\n",
      "83.56597117707133\n",
      "83.56597117707133\n",
      "83.5155981965363\n",
      "83.5155981965363\n",
      "83.46072835847735\n",
      "83.46072835847735\n",
      "83.40791264548898\n",
      "83.40791264548898\n",
      "83.35098375380039\n",
      "83.35098375380039\n",
      "83.30300684273243\n",
      "83.30300684273243\n",
      "83.25199759379029\n",
      "83.25199759379029\n",
      "83.19206328690052\n",
      "83.19206328690052\n",
      "83.13256448879838\n",
      "83.13256448879838\n",
      "83.0747232362628\n",
      "83.0747232362628\n",
      "82.99875342100859\n",
      "82.99875342100859\n",
      "82.92077346146107\n",
      "82.92077346146107\n",
      "82.86216845735908\n",
      "82.86216845735908\n",
      "82.8005410283804\n",
      "82.8005410283804\n",
      "82.71646296977997\n",
      "82.71646296977997\n",
      "82.63495931774378\n",
      "82.63495931774378\n",
      "82.58211161196232\n",
      "82.58211161196232\n",
      "82.52697403728962\n",
      "82.52697403728962\n",
      "82.47571628913283\n",
      "82.47571628913283\n",
      "82.42479303851724\n",
      "82.42479303851724\n",
      "82.37001492828131\n",
      "82.37001492828131\n",
      "82.31247391551733\n",
      "82.31247391551733\n",
      "82.25755408778787\n",
      "82.25755408778787\n",
      "82.20605817809701\n",
      "82.20605817809701\n",
      "82.16004410013556\n",
      "82.16004410013556\n",
      "82.11122746020555\n",
      "82.11122746020555\n",
      "82.05157351121306\n",
      "82.05157351121306\n",
      "81.99586680158973\n",
      "81.99586680158973\n",
      "81.9447575956583\n",
      "81.9447575956583\n",
      "81.88761111721396\n",
      "81.88761111721396\n",
      "81.83606822788715\n",
      "81.83606822788715\n",
      "81.78695062920451\n",
      "81.78695062920451\n",
      "81.73737949505448\n",
      "81.73737949505448\n",
      "81.69210957735777\n",
      "81.69210957735777\n",
      "81.63726291060448\n",
      "81.63726291060448\n",
      "81.57457546144724\n",
      "81.57457546144724\n",
      "81.5214649811387\n",
      "81.5214649811387\n",
      "81.472162052989\n",
      "81.472162052989\n",
      "81.42056412994862\n",
      "81.42056412994862\n",
      "81.36906600743532\n",
      "81.36906600743532\n",
      "81.31200839579105\n",
      "81.31200839579105\n",
      "81.25806614011526\n",
      "81.25806614011526\n",
      "81.20217936486006\n",
      "81.20217936486006\n",
      "81.15398089960217\n",
      "81.15398089960217\n",
      "81.10514290630817\n",
      "81.10514290630817\n",
      "81.0572799667716\n",
      "81.0572799667716\n",
      "81.01083046197891\n",
      "81.01083046197891\n",
      "80.96031625941396\n",
      "80.96031625941396\n",
      "80.90939567238092\n",
      "80.90939567238092\n",
      "80.85759531334043\n",
      "80.85759531334043\n",
      "80.807721670717\n",
      "80.807721670717\n",
      "80.75442082434893\n",
      "80.75442082434893\n",
      "80.70211989432573\n",
      "80.70211989432573\n",
      "80.65058275684714\n",
      "80.65058275684714\n",
      "80.59772403538227\n",
      "80.59772403538227\n",
      "80.54345973953605\n",
      "80.54345973953605\n",
      "80.48496905341744\n",
      "80.48496905341744\n",
      "80.43419113010168\n",
      "80.43419113010168\n",
      "80.38051940128207\n",
      "80.38051940128207\n",
      "80.31684657558799\n",
      "80.31684657558799\n",
      "80.25842644274235\n",
      "80.25842644274235\n",
      "80.19784540683031\n",
      "80.19784540683031\n",
      "80.14203221350908\n",
      "80.14203221350908\n",
      "80.07799552381039\n",
      "80.07799552381039\n",
      "80.01141414046288\n",
      "80.01141414046288\n",
      "79.95475452393293\n",
      "79.95475452393293\n",
      "79.89882426708937\n",
      "79.89882426708937\n",
      "79.84585102647543\n",
      "79.84585102647543\n",
      "79.78834178298712\n",
      "79.78834178298712\n",
      "79.7271160595119\n",
      "79.7271160595119\n",
      "79.67189698293805\n",
      "79.67189698293805\n",
      "79.61526281386614\n",
      "79.61526281386614\n",
      "79.56195674836636\n",
      "79.56195674836636\n",
      "79.50931326299906\n",
      "79.50931326299906\n",
      "79.45772670209408\n",
      "79.45772670209408\n",
      "79.40192676335573\n",
      "79.40192676335573\n",
      "79.34552498534322\n",
      "79.34552498534322\n",
      "79.28781008720398\n",
      "79.28781008720398\n",
      "79.23182407021523\n",
      "79.23182407021523\n",
      "79.17220998555422\n",
      "79.17220998555422\n",
      "79.11409145221114\n",
      "79.11409145221114\n",
      "79.0531342998147\n",
      "79.0531342998147\n",
      "78.99821742251515\n",
      "78.99821742251515\n",
      "78.946210231632\n",
      "78.946210231632\n",
      "78.89016953483224\n",
      "78.89016953483224\n",
      "78.82373316958547\n",
      "78.82373316958547\n",
      "78.75702721253037\n",
      "78.75702721253037\n",
      "78.69497942179441\n",
      "78.69497942179441\n",
      "78.64401837438345\n",
      "78.64401837438345\n",
      "78.5948531255126\n",
      "78.5948531255126\n",
      "78.54007401317358\n",
      "78.54007401317358\n",
      "78.48701022192836\n",
      "78.48701022192836\n",
      "78.42274885997176\n",
      "78.42274885997176\n",
      "78.36164405569434\n",
      "78.36164405569434\n",
      "78.30348188430071\n",
      "78.30348188430071\n",
      "78.24500391632318\n",
      "78.24500391632318\n",
      "78.1813147738576\n",
      "78.1813147738576\n",
      "78.11841174960136\n",
      "78.11841174960136\n",
      "78.05391782522202\n",
      "78.05391782522202\n",
      "77.99114076793194\n",
      "77.99114076793194\n",
      "77.93104424700141\n",
      "77.93104424700141\n",
      "77.86976492777467\n",
      "77.86976492777467\n",
      "77.81645910441875\n",
      "77.81645910441875\n",
      "77.75904313102365\n",
      "77.75904313102365\n",
      "77.69446979090571\n",
      "77.69446979090571\n",
      "77.63271022215486\n",
      "77.63271022215486\n",
      "77.578384116292\n",
      "77.578384116292\n",
      "77.52571885287762\n",
      "77.52571885287762\n",
      "77.46121448278427\n",
      "77.46121448278427\n",
      "77.39439290761948\n",
      "77.39439290761948\n",
      "77.33430143073201\n",
      "77.33430143073201\n",
      "77.2717732526362\n",
      "77.2717732526362\n",
      "77.20565630868077\n",
      "77.20565630868077\n",
      "77.13233641162515\n",
      "77.13233641162515\n",
      "77.07264993712306\n",
      "77.07264993712306\n",
      "77.01739178225398\n",
      "77.01739178225398\n",
      "76.95891452208161\n",
      "76.95891452208161\n",
      "76.89419976249337\n",
      "76.89419976249337\n",
      "76.8404111713171\n",
      "76.8404111713171\n",
      "76.77936843410134\n",
      "76.77936843410134\n",
      "76.71606159582734\n",
      "76.71606159582734\n",
      "76.6562559120357\n",
      "76.6562559120357\n",
      "76.59847312420607\n",
      "76.59847312420607\n",
      "76.53514675050974\n",
      "76.53514675050974\n",
      "76.47015630453825\n",
      "76.47015630453825\n",
      "76.40885536000133\n",
      "76.40885536000133\n",
      "76.34941815584898\n",
      "76.34941815584898\n",
      "76.28816096484661\n",
      "76.28816096484661\n",
      "76.2151183784008\n",
      "76.2151183784008\n",
      "76.14317508041859\n",
      "76.14317508041859\n",
      "76.07596593350172\n",
      "76.07596593350172\n",
      "76.00926757603884\n",
      "76.00926757603884\n",
      "75.94613299518824\n",
      "75.94613299518824\n",
      "75.88178643584251\n",
      "75.88178643584251\n",
      "75.81157702207565\n",
      "75.81157702207565\n",
      "75.74364666640759\n",
      "75.74364666640759\n",
      "75.67287147045135\n",
      "75.67287147045135\n",
      "75.60742644965649\n",
      "75.60742644965649\n",
      "75.54305964708328\n",
      "75.54305964708328\n",
      "75.47318460047245\n",
      "75.47318460047245\n",
      "75.40610850602388\n",
      "75.40610850602388\n",
      "75.33583704382181\n",
      "75.33583704382181\n",
      "75.26455878466368\n",
      "75.26455878466368\n",
      "75.19087823480368\n",
      "75.19087823480368\n",
      "75.12421534210443\n",
      "75.12421534210443\n",
      "75.04447254538536\n",
      "75.04447254538536\n",
      "74.97478175163269\n",
      "74.97478175163269\n",
      "74.89458353817463\n",
      "74.89458353817463\n",
      "74.80602846294641\n",
      "74.80602846294641\n",
      "74.72412844747305\n",
      "74.72412844747305\n",
      "74.65545359998941\n",
      "74.65545359998941\n",
      "74.59168165177107\n",
      "74.59168165177107\n",
      "74.51311841607094\n",
      "74.51311841607094\n",
      "74.44482386857271\n",
      "74.44482386857271\n",
      "74.37148480862379\n",
      "74.37148480862379\n",
      "74.2977622821927\n",
      "74.2977622821927\n",
      "74.22796138375998\n",
      "74.22796138375998\n",
      "74.15145971626043\n",
      "74.15145971626043\n",
      "74.08341988921165\n",
      "74.08341988921165\n",
      "74.00944381207228\n",
      "74.00944381207228\n",
      "73.93343794345856\n",
      "73.93343794345856\n",
      "73.8571605309844\n",
      "73.8571605309844\n",
      "73.77831730991602\n",
      "73.77831730991602\n",
      "73.71276201307774\n",
      "73.71276201307774\n",
      "73.63670055568218\n",
      "73.63670055568218\n",
      "73.55132991820574\n",
      "73.55132991820574\n",
      "73.47151949256659\n",
      "73.47151949256659\n",
      "73.396410189569\n",
      "73.396410189569\n",
      "73.31626255065203\n",
      "73.31626255065203\n",
      "73.2306483015418\n",
      "73.2306483015418\n",
      "73.15778318792582\n",
      "73.15778318792582\n",
      "73.08284575492144\n",
      "73.08284575492144\n",
      "73.00355791300535\n",
      "73.00355791300535\n",
      "72.93222554773092\n",
      "72.93222554773092\n",
      "72.85812883079052\n",
      "72.85812883079052\n",
      "72.78340110182762\n",
      "72.78340110182762\n",
      "72.69445855170488\n",
      "72.69445855170488\n",
      "72.61804116517305\n",
      "72.61804116517305\n",
      "72.53095503896475\n",
      "72.53095503896475\n",
      "72.45152585208416\n",
      "72.45152585208416\n",
      "72.37022469192743\n",
      "72.37022469192743\n",
      "72.28809078037739\n",
      "72.28809078037739\n",
      "72.20048094540834\n",
      "72.20048094540834\n",
      "72.11549465358257\n",
      "72.11549465358257\n",
      "72.02701960504055\n",
      "72.02701960504055\n",
      "71.93398389965296\n",
      "71.93398389965296\n",
      "71.84226885437965\n",
      "71.84226885437965\n",
      "71.75694973021746\n",
      "71.75694973021746\n",
      "71.66874596476555\n",
      "71.66874596476555\n",
      "71.58522926270962\n",
      "71.58522926270962\n",
      "71.4938982129097\n",
      "71.4938982129097\n",
      "71.40303365886211\n",
      "71.40303365886211\n",
      "71.32008109241724\n",
      "71.32008109241724\n",
      "71.23818135261536\n",
      "71.23818135261536\n",
      "71.14990405738354\n",
      "71.14990405738354\n",
      "71.0601327419281\n",
      "71.0601327419281\n",
      "70.96703043580055\n",
      "70.96703043580055\n",
      "70.87957195937634\n",
      "70.87957195937634\n",
      "70.79035423696041\n",
      "70.79035423696041\n",
      "70.69544684886932\n",
      "70.69544684886932\n",
      "70.60701487958431\n",
      "70.60701487958431\n",
      "70.51082896441221\n",
      "70.51082896441221\n",
      "70.41492009162903\n",
      "70.41492009162903\n",
      "70.32063288986683\n",
      "70.32063288986683\n",
      "70.21735608577728\n",
      "70.21735608577728\n",
      "70.12262178957462\n",
      "70.12262178957462\n",
      "70.0266415476799\n",
      "70.0266415476799\n",
      "69.92280683666468\n",
      "69.92280683666468\n",
      "69.8279886469245\n",
      "69.8279886469245\n",
      "69.72362769395113\n",
      "69.72362769395113\n",
      "69.62889286875725\n",
      "69.62889286875725\n",
      "69.53435441106558\n",
      "69.53435441106558\n",
      "69.44391256570816\n",
      "69.44391256570816\n",
      "69.34769155830145\n",
      "69.34769155830145\n",
      "69.24889176338911\n",
      "69.24889176338911\n",
      "69.14697585254908\n",
      "69.14697585254908\n",
      "69.0392220839858\n",
      "69.0392220839858\n",
      "68.93299146741629\n",
      "68.93299146741629\n",
      "68.82851219177246\n",
      "68.82851219177246\n",
      "68.7227355465293\n",
      "68.7227355465293\n",
      "68.61883447319269\n",
      "68.61883447319269\n",
      "68.513443171978\n",
      "68.513443171978\n",
      "68.40519843250513\n",
      "68.40519843250513\n",
      "68.29205410927534\n",
      "68.29205410927534\n",
      "68.18533588200808\n",
      "68.18533588200808\n",
      "68.0669417232275\n",
      "68.0669417232275\n",
      "67.94434058666229\n",
      "67.94434058666229\n",
      "67.82581178098917\n",
      "67.82581178098917\n",
      "67.71335839480162\n",
      "67.71335839480162\n",
      "67.60738680511713\n",
      "67.60738680511713\n",
      "67.49485446512699\n",
      "67.49485446512699\n",
      "67.37729878723621\n",
      "67.37729878723621\n",
      "67.25745867937803\n",
      "67.25745867937803\n",
      "67.13964483886957\n",
      "67.13964483886957\n",
      "67.01308342069387\n",
      "67.01308342069387\n",
      "66.89060664921999\n",
      "66.89060664921999\n",
      "66.76671670377254\n",
      "66.76671670377254\n",
      "66.6493973582983\n",
      "66.6493973582983\n",
      "66.53436914086342\n",
      "66.53436914086342\n",
      "66.41728215664625\n",
      "66.41728215664625\n",
      "66.29520075768232\n",
      "66.29520075768232\n",
      "66.1712249815464\n",
      "66.1712249815464\n",
      "66.04171657562256\n",
      "66.04171657562256\n",
      "65.91163682937622\n",
      "65.91163682937622\n",
      "65.78709828853607\n",
      "65.78709828853607\n",
      "65.6478222310543\n",
      "65.6478222310543\n",
      "65.51683102548122\n",
      "65.51683102548122\n",
      "65.38197423517704\n",
      "65.38197423517704\n",
      "65.25380071997643\n",
      "65.25380071997643\n",
      "65.12285935878754\n",
      "65.12285935878754\n",
      "64.98653504252434\n",
      "64.98653504252434\n",
      "64.84502616524696\n",
      "64.84502616524696\n",
      "64.7016484439373\n",
      "64.7016484439373\n",
      "64.56952652335167\n",
      "64.56952652335167\n",
      "64.43264049291611\n",
      "64.43264049291611\n",
      "64.30384613573551\n",
      "64.30384613573551\n",
      "64.16147178411484\n",
      "64.16147178411484\n",
      "64.01211287081242\n",
      "64.01211287081242\n",
      "63.85919341444969\n",
      "63.85919341444969\n",
      "63.71336051821709\n",
      "63.71336051821709\n",
      "63.56042402982712\n",
      "63.56042402982712\n",
      "63.4044653326273\n",
      "63.4044653326273\n",
      "63.256163254380226\n",
      "63.256163254380226\n",
      "63.103134736418724\n",
      "63.103134736418724\n",
      "62.94565637409687\n",
      "62.94565637409687\n",
      "62.776435405015945\n",
      "62.776435405015945\n",
      "62.60738426446915\n",
      "62.60738426446915\n",
      "62.44465991854668\n",
      "62.44465991854668\n",
      "62.29321198165417\n",
      "62.29321198165417\n",
      "62.14127899706364\n",
      "62.14127899706364\n",
      "61.98675186932087\n",
      "61.98675186932087\n",
      "61.83278977870941\n",
      "61.83278977870941\n",
      "61.671113669872284\n",
      "61.671113669872284\n",
      "61.494780868291855\n",
      "61.494780868291855\n",
      "61.31351113319397\n",
      "61.31351113319397\n",
      "61.13213975727558\n",
      "61.13213975727558\n",
      "60.95908471941948\n",
      "60.95908471941948\n",
      "60.791790187358856\n",
      "60.791790187358856\n",
      "60.61435690522194\n",
      "60.61435690522194\n",
      "60.42311434447765\n",
      "60.42311434447765\n",
      "60.244211331009865\n",
      "60.244211331009865\n",
      "60.057205855846405\n",
      "60.057205855846405\n",
      "59.87397614121437\n",
      "59.87397614121437\n",
      "59.67523095011711\n",
      "59.67523095011711\n",
      "59.47498182952404\n",
      "59.47498182952404\n",
      "59.28044919669628\n",
      "59.28044919669628\n",
      "59.086488887667656\n",
      "59.086488887667656\n",
      "58.891219809651375\n",
      "58.891219809651375\n",
      "58.684569865465164\n",
      "58.684569865465164\n",
      "58.48524326086044\n",
      "58.48524326086044\n",
      "58.27253960072994\n",
      "58.27253960072994\n",
      "58.06680849194527\n",
      "58.06680849194527\n",
      "57.84843085706234\n",
      "57.84843085706234\n",
      "57.6345172226429\n",
      "57.6345172226429\n",
      "57.41435235738754\n",
      "57.41435235738754\n",
      "57.19106176495552\n",
      "57.19106176495552\n",
      "56.96591503918171\n",
      "56.96591503918171\n",
      "56.73524284362793\n",
      "56.73524284362793\n",
      "56.49713762104511\n",
      "56.49713762104511\n",
      "56.25635711848736\n",
      "56.25635711848736\n",
      "56.01326562464237\n",
      "56.01326562464237\n",
      "55.776890620589256\n",
      "55.776890620589256\n",
      "55.53220635652542\n",
      "55.53220635652542\n",
      "55.28294053673744\n",
      "55.28294053673744\n",
      "55.02133101224899\n",
      "55.02133101224899\n",
      "54.749826818704605\n",
      "54.749826818704605\n",
      "54.49026018381119\n",
      "54.49026018381119\n",
      "54.20232391357422\n",
      "54.20232391357422\n",
      "53.91705700755119\n",
      "53.91705700755119\n",
      "53.641014724969864\n",
      "53.641014724969864\n",
      "53.36163231730461\n",
      "53.36163231730461\n",
      "53.07864397764206\n",
      "53.07864397764206\n",
      "52.786328077316284\n",
      "52.786328077316284\n",
      "52.48611444234848\n",
      "52.48611444234848\n",
      "52.18377423286438\n",
      "52.18377423286438\n",
      "51.88634464144707\n",
      "51.88634464144707\n",
      "51.56959393620491\n",
      "51.56959393620491\n",
      "51.24338519573212\n",
      "51.24338519573212\n",
      "50.92311066389084\n",
      "50.92311066389084\n",
      "50.586712181568146\n",
      "50.586712181568146\n",
      "50.24941313266754\n",
      "50.24941313266754\n",
      "49.895131796598434\n",
      "49.895131796598434\n",
      "49.52893152832985\n",
      "49.52893152832985\n",
      "49.17354875802994\n",
      "49.17354875802994\n",
      "48.81917414069176\n",
      "48.81917414069176\n",
      "48.44331434369087\n",
      "48.44331434369087\n",
      "48.057533234357834\n",
      "48.057533234357834\n",
      "47.677560120821\n",
      "47.677560120821\n",
      "47.292416244745255\n",
      "47.292416244745255\n",
      "46.887000888586044\n",
      "46.887000888586044\n",
      "46.47070473432541\n",
      "46.47070473432541\n",
      "46.03709000349045\n",
      "46.03709000349045\n",
      "45.610437989234924\n",
      "45.610437989234924\n",
      "45.19003218412399\n",
      "45.19003218412399\n",
      "44.73751500248909\n",
      "44.73751500248909\n",
      "44.277033895254135\n",
      "44.277033895254135\n",
      "43.817595183849335\n",
      "43.817595183849335\n",
      "43.34448283910751\n",
      "43.34448283910751\n",
      "42.875782668590546\n",
      "42.875782668590546\n",
      "42.374116361141205\n",
      "42.374116361141205\n",
      "41.86647409200668\n",
      "41.86647409200668\n",
      "41.346258759498596\n",
      "41.346258759498596\n",
      "40.81244373321533\n",
      "40.81244373321533\n",
      "40.2628059387207\n",
      "40.2628059387207\n",
      "39.69810575246811\n",
      "39.69810575246811\n",
      "39.13439750671387\n",
      "39.13439750671387\n",
      "38.553116142749786\n",
      "38.553116142749786\n",
      "37.962227523326874\n",
      "37.962227523326874\n",
      "37.35837560892105\n",
      "37.35837560892105\n",
      "36.72713142633438\n",
      "36.72713142633438\n",
      "36.087030947208405\n",
      "36.087030947208405\n",
      "35.4322025179863\n",
      "35.4322025179863\n",
      "34.78095072507858\n",
      "34.78095072507858\n",
      "34.107652485370636\n",
      "34.107652485370636\n",
      "33.417373061180115\n",
      "33.417373061180115\n",
      "32.722677409648895\n",
      "32.722677409648895\n",
      "32.01337254047394\n",
      "32.01337254047394\n",
      "31.292192220687866\n",
      "31.292192220687866\n",
      "30.5615416765213\n",
      "30.5615416765213\n",
      "29.814519226551056\n",
      "29.814519226551056\n",
      "29.05996721982956\n",
      "29.05996721982956\n",
      "28.3017458319664\n",
      "28.3017458319664\n",
      "27.53360205888748\n",
      "27.53360205888748\n",
      "26.750968635082245\n",
      "26.750968635082245\n",
      "25.958885550498962\n",
      "25.958885550498962\n",
      "25.164976835250854\n",
      "25.164976835250854\n",
      "24.361727595329285\n",
      "24.361727595329285\n",
      "23.551195800304413\n",
      "23.551195800304413\n",
      "22.730651676654816\n",
      "22.730651676654816\n",
      "21.905864238739014\n",
      "21.905864238739014\n",
      "21.072282671928406\n",
      "21.072282671928406\n",
      "20.230656147003174\n",
      "20.230656147003174\n",
      "19.389130473136902\n",
      "19.389130473136902\n",
      "18.540539622306824\n",
      "18.540539622306824\n",
      "17.68402737379074\n",
      "17.68402737379074\n",
      "16.825800716876984\n",
      "16.825800716876984\n",
      "15.964259266853333\n",
      "15.964259266853333\n",
      "15.099478960037231\n",
      "15.099478960037231\n",
      "14.226511359214783\n",
      "14.226511359214783\n",
      "13.352694392204285\n",
      "13.352694392204285\n",
      "12.477583646774292\n",
      "12.477583646774292\n",
      "11.599838376045227\n",
      "11.599838376045227\n",
      "10.720822274684906\n",
      "10.720822274684906\n",
      "9.837912321090698\n",
      "9.837912321090698\n",
      "8.95267927646637\n",
      "8.95267927646637\n",
      "8.063977003097534\n",
      "8.063977003097534\n",
      "7.173194468021393\n",
      "7.173194468021393\n",
      "6.280701041221619\n",
      "6.280701041221619\n",
      "5.386591613292694\n",
      "5.386591613292694\n",
      "4.49114465713501\n",
      "4.49114465713501\n",
      "3.5946157574653625\n",
      "3.5946157574653625\n",
      "2.696867287158966\n",
      "2.696867287158966\n",
      "1.7987594604492188\n",
      "1.7987594604492188\n",
      "0.8997742533683777\n",
      "0.8997742533683777\n",
      "0.029900263994932175\n"
     ]
    }
   ],
   "source": [
    "for i in range(999,-1,-1):\n",
    "    print(LOSS[i])\n",
    "    print(LOSS[i-1])\n",
    "    LOSS[i] = LOSS[i] - LOSS[i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(1,10000,1000,dtype = \"int\")\n",
    "y = np.array(LOSS)\n",
    "plt.plot(x,y)\n",
    "plt.xlabel(\"EPOCH\")\n",
    "plt.ylabel(\"LOSS\")\n",
    "plt.title(\"Predict rise / fall LOSS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 30 at dim 1 (got 29)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-186-06eff11f7fd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"K value\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"D value\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"William\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"MACD\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"market_Change(%)\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Beta_7D\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtest_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtest_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: expected sequence of length 30 at dim 1 (got 29)"
     ]
    }
   ],
   "source": [
    "test_features = []\n",
    "for i in range(30,2000):\n",
    "    x = test_set[i-30:i][[\"K value\",\"D value\",\"William\",\"MACD\",\"market_Change(%)\",\"Beta_7D\"]].values\n",
    "    test_features.append(x.tolist())\n",
    "test_features = torch.FloatTensor(test_features)\n",
    "\n",
    "test_labels = []\n",
    "for i in range(31,2001):\n",
    "    x = test_set[i-1:i][\"Close r/f\"]\n",
    "    test_labels.append(x.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
